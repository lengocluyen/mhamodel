{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tjb12oMM6jXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e0e0bd-3573-433c-f9cc-10324bf16c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/utc_working/medes/')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/utc_working/medes/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy2-DzmVDtvh",
        "outputId": "0768f8b7-fabf-44a0-8499-5c47f015cf43"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250_final_ml100k_user_context_criteria.csv  mha_model.py\n",
            "427_final_ml1m_user_context_criteria.csv    ml-1m\n",
            "427_ml1m_statistics_summary.csv\t\t    ml1m_statistics_summary.csv\n",
            "575_final_ml1m_user_context_criteria.csv    ml_processing.py\n",
            "575_grouped_ml1m_context_criteria.csv\t    mvl_110_plot.pdf\n",
            "575_ml1m_statistics_summary.csv\t\t    mvl_plot.pdf\n",
            "average_time.pdf\t\t\t    outputs\n",
            "final_ml100k_user_context_criteria.csv\t    __pycache__\n",
            "final_ml1m_user_context_criteria.csv\t    requirements.txt\n",
            "grouped_ml1m_context_criteria.csv\t    run.ipynb\n",
            "imha_model.py\t\t\t\t    run_movielen_100k.py\n",
            "imt_110_plot.pdf\t\t\t    run_mvdb.py\n",
            "imt_plot.pdf\t\t\t\t    run_mv.sh\n",
            "ITM-Rec\t\t\t\t\t    run.sh\n",
            "main.py\t\t\t\t\t    visualization.py\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Collecting deepctr-torch (from -r requirements.txt (line 5))\n",
            "  Downloading deepctr_torch-0.2.9-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepctr-torch->-r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from deepctr-torch->-r requirements.txt (line 5)) (2.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->deepctr-torch->-r requirements.txt (line 5)) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepctr_torch-0.2.9-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, deepctr-torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed deepctr-torch-0.2.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!lscpu\n",
        "!cat /proc/meminfo | grep Mem\n",
        "!nvidia-smi --query-gpu=name --format=csv,noheader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MdJE8ZthdBk",
        "outputId": "e1cf0fb1-9c1f-4314-df8b-5780879cd963"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   8\n",
            "  On-line CPU(s) list:    0-7\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:           6\n",
            "    Model:                79\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   4\n",
            "    Socket(s):            1\n",
            "    Stepping:             0\n",
            "    BogoMIPS:             4399.99\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
            "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
            "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
            "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
            "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
            "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
            "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
            "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm r\n",
            "                          dseed adx smap xsaveopt arat md_clear arch_capabilitie\n",
            "                          s\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    128 KiB (4 instances)\n",
            "  L1i:                    128 KiB (4 instances)\n",
            "  L2:                     1 MiB (4 instances)\n",
            "  L3:                     55 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0-7\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
            "                          arriers only; no swapgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
            "                          RS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n",
            "MemTotal:       53469676 kB\n",
            "MemFree:        31044672 kB\n",
            "MemAvailable:   51826912 kB\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Summary**"
      ],
      "metadata": {
        "id": "tEdtd4Tvh91i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import time\n",
        "import psutil\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from deepctr_torch.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr_torch.models.basemodel import BaseModel\n",
        "from deepctr_torch.layers import PredictionLayer\n",
        "from deepctr_torch.models import (\n",
        "    AFM,\n",
        "    AutoInt,\n",
        "    CCPM,\n",
        "    DCN,\n",
        "    DeepFM,\n",
        "    DIFM,\n",
        "    FiBiNET,\n",
        "    NFM,\n",
        "    ONN,\n",
        "    PNN,\n",
        "    WDL,\n",
        "    xDeepFM,\n",
        "    IFM,\n",
        "    MLR\n",
        ")\n",
        "from mha_model import *\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Step 1: Load and Merge Data\n",
        "# ----------------------------\n",
        "def run(dense_features, sparse_features):\n",
        "  # Load Data\n",
        "  df_ratings = pd.read_csv(\"./250_final_ml100k_user_context_criteria.csv\")\n",
        "\n",
        "  print(\"df_rating: \", df_ratings.head())\n",
        "\n",
        "  print(\"Rows with NaN values in df_ratings:\")\n",
        "  print(df_ratings[df_ratings.isnull().any(axis=1)])\n",
        "  df_ratings = df_ratings.dropna()\n",
        "  print(\"Rows with NaN values in df_ratings:\")\n",
        "  print(df_ratings[df_ratings.isnull().any(axis=1)])\n",
        "\n",
        "  ## Ensure there is at least one argument (excluding script name)\n",
        "\n",
        "  #if len(sys.argv) < 3:\n",
        "  #    print(\"Usage: python main.py <case_number> <log_file>\")\n",
        "  #    sys.exit(1)  # Exit if no argument is provided\n",
        "\n",
        "  ## Get the argument value and convert it to an integer\n",
        "  #try:\n",
        "  #    case = int(sys.argv[1])  # Convert the first argument to an integer\n",
        "  #    log_file = sys.argv[2]\n",
        "  #except ValueError:\n",
        "  #    print(\"Error: case_number must be an integer.\")\n",
        "  #    sys.exit(1)\n",
        "  # Redirect stdout and stderr to the log file\n",
        "  #sys.stdout = open(\"./outputs/mv_case_1\", 'a')\n",
        "  #sys.stderr = sys.stdout  # Optional: capture errors too\n",
        "\n",
        "\n",
        "  # ----------------------------\n",
        "  # Step 2: Feature Engineering\n",
        "  # ----------------------------\n",
        "\n",
        "  # Initialize LabelEncoders\n",
        "  label_encoders = {}\n",
        "\n",
        "  # Initialize and fit LabelEncoders\n",
        "  print(\"sparse_features\", sparse_features)\n",
        "  for feat in sparse_features:\n",
        "      print(\"feat: \", feat)\n",
        "      le = LabelEncoder()\n",
        "      df_ratings[feat] = le.fit_transform(df_ratings[feat].astype(str))\n",
        "      label_encoders[feat] = le\n",
        "\n",
        "\n",
        "  # Initialize MinMaxScaler\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  # Fit and transform the dense features\n",
        "  df_ratings[dense_features] = scaler.fit_transform(df_ratings[dense_features])\n",
        "\n",
        "  # Define target variables\n",
        "  #target = ['GroupRating', 'GroupApp', 'GroupData', 'GroupEase']\n",
        "  target = ['GroupRating']\n",
        "  # ----------------------------\n",
        "  # Step 3: Prepare Data for Modeling\n",
        "  # ----------------------------\n",
        "\n",
        "  # Split the data\n",
        "  train_data, test_data = train_test_split(df_ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Define feature columns\n",
        "  # Define feature columns\n",
        "  sparse_feature_columns = [SparseFeat(feat, vocabulary_size=df_ratings[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
        "  dense_feature_columns = [DenseFeat(feat, 1) for feat in dense_features]\n",
        "\n",
        "  feature_columns = sparse_feature_columns + dense_feature_columns\n",
        "\n",
        "  print(\"feature columns: \", feature_columns)\n",
        "  # Get feature names\n",
        "  feature_names = get_feature_names(feature_columns)\n",
        "\n",
        "  # Generate input data for model\n",
        "  train_model_input = {name: train_data[name].values for name in feature_names}\n",
        "  test_model_input = {name: test_data[name].values for name in feature_names}\n",
        "\n",
        "  # Ensure data types are correct\n",
        "  for name in feature_names:\n",
        "      if name in sparse_features:\n",
        "          train_model_input[name] = train_model_input[name].astype(int)\n",
        "          test_model_input[name] = test_model_input[name].astype(int)\n",
        "      else:\n",
        "          train_model_input[name] = train_model_input[name].astype(float)\n",
        "          test_model_input[name] = test_model_input[name].astype(float)\n",
        "\n",
        "\n",
        "\n",
        "  # Update the models dictionary\n",
        "  linear_feature_columns = feature_columns\n",
        "  dnn_feature_columns =  feature_columns\n",
        "  num_heads = 4\n",
        "  dnn_hidden_units = (256, 128, 64, 32, 16, 8)\n",
        "  l2_reg_dnn = 1e-5\n",
        "  dnn_dropout = 0.42\n",
        "\n",
        "  model = MultiHeadAttentionModel(\n",
        "      linear_feature_columns=linear_feature_columns,\n",
        "      dnn_feature_columns=dnn_feature_columns,\n",
        "      num_heads=num_heads,\n",
        "      dnn_hidden_units=dnn_hidden_units,\n",
        "      dnn_dropout=dnn_dropout,\n",
        "      l2_reg_dnn=l2_reg_dnn,\n",
        "      device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  )\n",
        "\n",
        "  print(model)\n",
        "  print(summary(model))\n",
        "sparse_features = [\n",
        "          'UserID',            # unique user\n",
        "          'GroupID',           # assigned via KMeans\n",
        "          'MovieID',           # unique movie\n",
        "          'Title',             # optional (high-cardinality), usually omit or hash\n",
        "          'UserOccupation',    # categorical occupation\n",
        "          'TimeOfDay',         # ['Morning', 'Afternoon', etc.]\n",
        "          'DayType',           # ['Weekday', 'Weekend']\n",
        "          'Season'             # ['Spring', 'Summer', etc.]\n",
        "      ]\n",
        "dense_features = [\n",
        "          'UserAge',           # continuous age\n",
        "          'Storyline',         # simulated multi-criteria\n",
        "          'Visuals',           # simulated multi-criteria\n",
        "          'Emotion'           # simulated multi-criteria\n",
        "      ]\n",
        "run(dense_features, sparse_features)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I62-5EbAh07V",
        "outputId": "1e7bc209-04c0-47ff-ad91-5f8b76aa6fd5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_rating:     UserID  GroupID  MovieID                    Title                  Genres  \\\n",
            "0     196       21      242             Kolya (1996)                  Comedy   \n",
            "1     196       21      393    Mrs. Doubtfire (1993)                  Comedy   \n",
            "2     196       21      381  Muriel's Wedding (1994)          Comedy|Romance   \n",
            "3     196       21      251   Shall We Dance? (1996)                  Comedy   \n",
            "4     196       21      655       Stand by Me (1986)  Adventure|Comedy|Drama   \n",
            "\n",
            "   UserAge  UserOccupation  TimeOfDay  DayType  Season  Storyline   Visuals  \\\n",
            "0       49              20  Afternoon  Weekday  Winter   4.986857  5.000000   \n",
            "1       49              20  Afternoon  Weekday  Winter   3.446943  1.000000   \n",
            "2       49              20  Afternoon  Weekday  Winter   5.000000  5.000000   \n",
            "3       49              20  Afternoon  Weekday  Winter   5.000000  1.000000   \n",
            "4       49              20  Afternoon  Weekday  Winter   4.063386  3.690389   \n",
            "\n",
            "    Emotion  OverallRating  \n",
            "0  5.000000              3  \n",
            "1  3.623087              4  \n",
            "2  1.000000              4  \n",
            "3  1.000000              3  \n",
            "4  3.629397              5  \n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "sparse_features ['UserID', 'GroupID', 'MovieID', 'Title', 'UserOccupation', 'TimeOfDay', 'DayType', 'Season']\n",
            "feat:  UserID\n",
            "feat:  GroupID\n",
            "feat:  MovieID\n",
            "feat:  Title\n",
            "feat:  UserOccupation\n",
            "feat:  TimeOfDay\n",
            "feat:  DayType\n",
            "feat:  Season\n",
            "feature columns:  [SparseFeat(name='UserID', vocabulary_size=943, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserID', group_name='default_group'), SparseFeat(name='GroupID', vocabulary_size=250, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='GroupID', group_name='default_group'), SparseFeat(name='MovieID', vocabulary_size=1682, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='MovieID', group_name='default_group'), SparseFeat(name='Title', vocabulary_size=1664, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Title', group_name='default_group'), SparseFeat(name='UserOccupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserOccupation', group_name='default_group'), SparseFeat(name='TimeOfDay', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='TimeOfDay', group_name='default_group'), SparseFeat(name='DayType', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='DayType', group_name='default_group'), SparseFeat(name='Season', vocabulary_size=3, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Season', group_name='default_group'), DenseFeat(name='UserAge', dimension=1, dtype='float32'), DenseFeat(name='Storyline', dimension=1, dtype='float32'), DenseFeat(name='Visuals', dimension=1, dtype='float32'), DenseFeat(name='Emotion', dimension=1, dtype='float32')]\n",
            "MultiHeadAttentionModel(\n",
            "  (embedding_dict): ModuleDict(\n",
            "    (UserID): Embedding(943, 4)\n",
            "    (GroupID): Embedding(250, 4)\n",
            "    (MovieID): Embedding(1682, 4)\n",
            "    (Title): Embedding(1664, 4)\n",
            "    (UserOccupation): Embedding(21, 4)\n",
            "    (TimeOfDay): Embedding(4, 4)\n",
            "    (DayType): Embedding(2, 4)\n",
            "    (Season): Embedding(3, 4)\n",
            "  )\n",
            "  (linear_model): Linear(\n",
            "    (embedding_dict): ModuleDict(\n",
            "      (UserID): Embedding(943, 1)\n",
            "      (GroupID): Embedding(250, 1)\n",
            "      (MovieID): Embedding(1682, 1)\n",
            "      (Title): Embedding(1664, 1)\n",
            "      (UserOccupation): Embedding(21, 1)\n",
            "      (TimeOfDay): Embedding(4, 1)\n",
            "      (DayType): Embedding(2, 1)\n",
            "      (Season): Embedding(3, 1)\n",
            "    )\n",
            "  )\n",
            "  (out): PredictionLayer()\n",
            "  (pos_enc): PositionalEncoding()\n",
            "  (attn1): MultiHeadSelfAttention(\n",
            "    (attn): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
            "    )\n",
            "    (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
            "    (ffn): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
            "      (1): GELU(approximate='none')\n",
            "      (2): Dropout(p=0.42, inplace=False)\n",
            "      (3): Linear(in_features=16, out_features=4, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.42, inplace=False)\n",
            "  )\n",
            "  (attn2): MultiHeadSelfAttention(\n",
            "    (attn): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
            "    )\n",
            "    (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
            "    (ffn): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
            "      (1): GELU(approximate='none')\n",
            "      (2): Dropout(p=0.42, inplace=False)\n",
            "      (3): Linear(in_features=16, out_features=4, bias=True)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.42, inplace=False)\n",
            "  )\n",
            "  (cross_attn): MultiheadAttention(\n",
            "    (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
            "  )\n",
            "  (cross_norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
            "  (dense_proj): Linear(in_features=4, out_features=16, bias=True)\n",
            "  (cross_net): CrossNetwork(\n",
            "    (weights): ModuleList(\n",
            "      (0-1): 2 x Linear(in_features=4, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (dnn): Sequential(\n",
            "    (linear0): Linear(in_features=4, out_features=256, bias=True)\n",
            "    (norm0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    (act0): ReLU()\n",
            "    (drop0): Dropout(p=0.42, inplace=False)\n",
            "    (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "    (act1): ReLU()\n",
            "    (drop1): Dropout(p=0.42, inplace=False)\n",
            "    (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (act2): ReLU()\n",
            "    (drop2): Dropout(p=0.42, inplace=False)\n",
            "    (linear3): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    (act3): ReLU()\n",
            "    (drop3): Dropout(p=0.42, inplace=False)\n",
            "    (linear4): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (norm4): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "    (act4): ReLU()\n",
            "    (drop4): Dropout(p=0.42, inplace=False)\n",
            "    (linear5): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (norm5): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
            "    (act5): ReLU()\n",
            "    (drop5): Dropout(p=0.42, inplace=False)\n",
            "  )\n",
            "  (dnn_out): Linear(in_features=8, out_features=1, bias=True)\n",
            "  (prediction): PredictionLayer()\n",
            ")\n",
            "================================================================================\n",
            "Layer (type:depth-idx)                                  Param #\n",
            "================================================================================\n",
            "MultiHeadAttentionModel                                 4\n",
            "├─ModuleDict: 1-1                                       --\n",
            "│    └─Embedding: 2-1                                   3,772\n",
            "│    └─Embedding: 2-2                                   1,000\n",
            "│    └─Embedding: 2-3                                   6,728\n",
            "│    └─Embedding: 2-4                                   6,656\n",
            "│    └─Embedding: 2-5                                   84\n",
            "│    └─Embedding: 2-6                                   16\n",
            "│    └─Embedding: 2-7                                   8\n",
            "│    └─Embedding: 2-8                                   12\n",
            "├─Linear: 1-2                                           4\n",
            "│    └─ModuleDict: 2-9                                  --\n",
            "│    │    └─Embedding: 3-1                              943\n",
            "│    │    └─Embedding: 3-2                              250\n",
            "│    │    └─Embedding: 3-3                              1,682\n",
            "│    │    └─Embedding: 3-4                              1,664\n",
            "│    │    └─Embedding: 3-5                              21\n",
            "│    │    └─Embedding: 3-6                              4\n",
            "│    │    └─Embedding: 3-7                              2\n",
            "│    │    └─Embedding: 3-8                              3\n",
            "├─PredictionLayer: 1-3                                  1\n",
            "├─PositionalEncoding: 1-4                               52\n",
            "├─MultiHeadSelfAttention: 1-5                           --\n",
            "│    └─MultiheadAttention: 2-10                         60\n",
            "│    │    └─NonDynamicallyQuantizableLinear: 3-9        20\n",
            "│    └─LayerNorm: 2-11                                  8\n",
            "│    └─LayerNorm: 2-12                                  8\n",
            "│    └─Sequential: 2-13                                 --\n",
            "│    │    └─Linear: 3-10                                80\n",
            "│    │    └─GELU: 3-11                                  --\n",
            "│    │    └─Dropout: 3-12                               --\n",
            "│    │    └─Linear: 3-13                                68\n",
            "│    └─Dropout: 2-14                                    --\n",
            "├─MultiHeadSelfAttention: 1-6                           --\n",
            "│    └─MultiheadAttention: 2-15                         60\n",
            "│    │    └─NonDynamicallyQuantizableLinear: 3-14       20\n",
            "│    └─LayerNorm: 2-16                                  8\n",
            "│    └─LayerNorm: 2-17                                  8\n",
            "│    └─Sequential: 2-18                                 --\n",
            "│    │    └─Linear: 3-15                                80\n",
            "│    │    └─GELU: 3-16                                  --\n",
            "│    │    └─Dropout: 3-17                               --\n",
            "│    │    └─Linear: 3-18                                68\n",
            "│    └─Dropout: 2-19                                    --\n",
            "├─MultiheadAttention: 1-7                               60\n",
            "│    └─NonDynamicallyQuantizableLinear: 2-20            20\n",
            "├─LayerNorm: 1-8                                        8\n",
            "├─Linear: 1-9                                           80\n",
            "├─CrossNetwork: 1-10                                    --\n",
            "│    └─ModuleList: 2-21                                 --\n",
            "│    │    └─Linear: 3-19                                5\n",
            "│    │    └─Linear: 3-20                                5\n",
            "├─Sequential: 1-11                                      --\n",
            "│    └─Linear: 2-22                                     1,280\n",
            "│    └─LayerNorm: 2-23                                  512\n",
            "│    └─ReLU: 2-24                                       --\n",
            "│    └─Dropout: 2-25                                    --\n",
            "│    └─Linear: 2-26                                     32,896\n",
            "│    └─LayerNorm: 2-27                                  256\n",
            "│    └─ReLU: 2-28                                       --\n",
            "│    └─Dropout: 2-29                                    --\n",
            "│    └─Linear: 2-30                                     8,256\n",
            "│    └─LayerNorm: 2-31                                  128\n",
            "│    └─ReLU: 2-32                                       --\n",
            "│    └─Dropout: 2-33                                    --\n",
            "│    └─Linear: 2-34                                     2,080\n",
            "│    └─LayerNorm: 2-35                                  64\n",
            "│    └─ReLU: 2-36                                       --\n",
            "│    └─Dropout: 2-37                                    --\n",
            "│    └─Linear: 2-38                                     528\n",
            "│    └─LayerNorm: 2-39                                  32\n",
            "│    └─ReLU: 2-40                                       --\n",
            "│    └─Dropout: 2-41                                    --\n",
            "│    └─Linear: 2-42                                     136\n",
            "│    └─LayerNorm: 2-43                                  16\n",
            "│    └─ReLU: 2-44                                       --\n",
            "│    └─Dropout: 2-45                                    --\n",
            "├─Linear: 1-12                                          9\n",
            "├─PredictionLayer: 1-13                                 1\n",
            "================================================================================\n",
            "Total params: 69,766\n",
            "Trainable params: 69,766\n",
            "Non-trainable params: 0\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MCGRS-MC: Running Model Training with all context and criteria**"
      ],
      "metadata": {
        "id": "juILUJBBiahO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import time\n",
        "import psutil\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from deepctr_torch.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr_torch.models.basemodel import BaseModel\n",
        "from deepctr_torch.layers import PredictionLayer\n",
        "from deepctr_torch.models import (\n",
        "    AFM,\n",
        "    AutoInt,\n",
        "    CCPM,\n",
        "    DCN,\n",
        "    DeepFM,\n",
        "    DIFM,\n",
        "    FiBiNET,\n",
        "    NFM,\n",
        "    ONN,\n",
        "    PNN,\n",
        "    WDL,\n",
        "    xDeepFM,\n",
        "    IFM,\n",
        "    MLR\n",
        ")\n",
        "from mha_model import *\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Step 1: Load and Merge Data\n",
        "# ----------------------------\n",
        "def run(dense_features, sparse_features):\n",
        "  # Load Data\n",
        "  df_ratings = pd.read_csv(\"./250_final_ml100k_user_context_criteria.csv\")\n",
        "\n",
        "  print(\"df_rating: \", df_ratings.head())\n",
        "\n",
        "  print(\"Rows with NaN values in df_ratings:\")\n",
        "  print(df_ratings[df_ratings.isnull().any(axis=1)])\n",
        "  df_ratings = df_ratings.dropna()\n",
        "  print(\"Rows with NaN values in df_ratings:\")\n",
        "  print(df_ratings[df_ratings.isnull().any(axis=1)])\n",
        "\n",
        "  ## Ensure there is at least one argument (excluding script name)\n",
        "\n",
        "  #if len(sys.argv) < 3:\n",
        "  #    print(\"Usage: python main.py <case_number> <log_file>\")\n",
        "  #    sys.exit(1)  # Exit if no argument is provided\n",
        "\n",
        "  ## Get the argument value and convert it to an integer\n",
        "  #try:\n",
        "  #    case = int(sys.argv[1])  # Convert the first argument to an integer\n",
        "  #    log_file = sys.argv[2]\n",
        "  #except ValueError:\n",
        "  #    print(\"Error: case_number must be an integer.\")\n",
        "  #    sys.exit(1)\n",
        "  # Redirect stdout and stderr to the log file\n",
        "  #sys.stdout = open(\"./outputs/mv_case_1\", 'a')\n",
        "  #sys.stderr = sys.stdout  # Optional: capture errors too\n",
        "\n",
        "\n",
        "  # ----------------------------\n",
        "  # Step 2: Feature Engineering\n",
        "  # ----------------------------\n",
        "\n",
        "  # Initialize LabelEncoders\n",
        "  label_encoders = {}\n",
        "\n",
        "  # Initialize and fit LabelEncoders\n",
        "  print(\"sparse_features\", sparse_features)\n",
        "  for feat in sparse_features:\n",
        "      print(\"feat: \", feat)\n",
        "      le = LabelEncoder()\n",
        "      df_ratings[feat] = le.fit_transform(df_ratings[feat].astype(str))\n",
        "      label_encoders[feat] = le\n",
        "\n",
        "\n",
        "  # Initialize MinMaxScaler\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  # Fit and transform the dense features\n",
        "  df_ratings[dense_features] = scaler.fit_transform(df_ratings[dense_features])\n",
        "\n",
        "  # Define target variables\n",
        "  #target = ['GroupRating', 'GroupApp', 'GroupData', 'GroupEase']\n",
        "  target = ['OverallRating']\n",
        "  # ----------------------------\n",
        "  # Step 3: Prepare Data for Modeling\n",
        "  # ----------------------------\n",
        "\n",
        "  # Split the data\n",
        "  train_data, test_data = train_test_split(df_ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Define feature columns\n",
        "  # Define feature columns\n",
        "  sparse_feature_columns = [SparseFeat(feat, vocabulary_size=df_ratings[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
        "  dense_feature_columns = [DenseFeat(feat, 1) for feat in dense_features]\n",
        "\n",
        "  feature_columns = sparse_feature_columns + dense_feature_columns\n",
        "\n",
        "  print(\"feature columns: \", feature_columns)\n",
        "  # Get feature names\n",
        "  feature_names = get_feature_names(feature_columns)\n",
        "\n",
        "  # Generate input data for model\n",
        "  train_model_input = {name: train_data[name].values for name in feature_names}\n",
        "  test_model_input = {name: test_data[name].values for name in feature_names}\n",
        "\n",
        "  # Ensure data types are correct\n",
        "  for name in feature_names:\n",
        "      if name in sparse_features:\n",
        "          train_model_input[name] = train_model_input[name].astype(int)\n",
        "          test_model_input[name] = test_model_input[name].astype(int)\n",
        "      else:\n",
        "          train_model_input[name] = train_model_input[name].astype(float)\n",
        "          test_model_input[name] = test_model_input[name].astype(float)\n",
        "\n",
        "  models = {\n",
        "            \"AFM\": (AFM, {\n",
        "          'linear_feature_columns': sparse_feature_columns + dense_feature_columns,  # AFM still uses DenseFeat here\n",
        "          'dnn_feature_columns': sparse_feature_columns,  # REMOVE DenseFeat here\n",
        "          'attention_factor': 8,\n",
        "          'l2_reg_att': 1e-5,\n",
        "          'use_attention': True,\n",
        "      }),\n",
        "      \"AutoInt\": (AutoInt, {\n",
        "          'linear_feature_columns': sparse_feature_columns + dense_feature_columns,\n",
        "          'dnn_feature_columns': sparse_feature_columns + dense_feature_columns,  # Keep both for other models\n",
        "          'att_layer_num': 3,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"CCPM\": (CCPM, {\n",
        "          'linear_feature_columns': sparse_feature_columns + dense_feature_columns,  # Keep DenseFeat in linear features\n",
        "          'dnn_feature_columns': sparse_feature_columns,  # REMOVE DenseFeat from dnn_feature_columns\n",
        "          'conv_kernel_width': (6, 5),\n",
        "          'conv_filters': (4, 4),\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"DCN\": (DCN, {\n",
        "          'linear_feature_columns': sparse_feature_columns + dense_feature_columns,\n",
        "          'dnn_feature_columns': sparse_feature_columns + dense_feature_columns,\n",
        "          'cross_num': 3,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"DeepFM\": (DeepFM, {\n",
        "          'dnn_feature_columns': feature_columns,\n",
        "      'linear_feature_columns': feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"DIFM\": (DIFM, {\n",
        "          'dnn_feature_columns': feature_columns,\n",
        "          'linear_feature_columns': feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"FiBiNET\": (FiBiNET, {\n",
        "          'linear_feature_columns': feature_columns,\n",
        "          'dnn_feature_columns': feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"NFM\": (NFM, {\n",
        "          'linear_feature_columns': feature_columns,\n",
        "          'dnn_feature_columns': feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"ONN\": (ONN, {\n",
        "          'linear_feature_columns': feature_columns,\n",
        "          'dnn_feature_columns': feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"PNN\": (PNN, {\n",
        "          'dnn_feature_columns': sparse_feature_columns + dense_feature_columns,  # Only dnn_feature_columns\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "          'use_inner': True,\n",
        "          'use_outter': False,\n",
        "      }),\n",
        "      \"WDL\": (WDL, {\n",
        "          'linear_feature_columns': feature_columns,\n",
        "          'dnn_feature_columns': feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "      \"xDeepFM\": (xDeepFM, {\n",
        "          'linear_feature_columns': feature_columns,\n",
        "        'dnn_feature_columns': feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "          'cin_layer_size': (128, 128),\n",
        "      }),\n",
        "      \"IFM\": (IFM, {\n",
        "          'linear_feature_columns': sparse_feature_columns + dense_feature_columns,\n",
        "\n",
        "          'dnn_feature_columns': sparse_feature_columns + dense_feature_columns,\n",
        "          'dnn_hidden_units': (256, 128),\n",
        "      }),\n",
        "\n",
        "      \"LS-PLM\": (MLR, {\n",
        "          'region_feature_columns': sparse_feature_columns + dense_feature_columns,\n",
        "        'base_feature_columns': sparse_feature_columns,  # Example\n",
        "        'bias_feature_columns': dense_feature_columns,  # Example\n",
        "      }),\n",
        "\n",
        "\n",
        "      \"MHA\": (MultiHeadAttentionModel, {\n",
        "        'linear_feature_columns': feature_columns,\n",
        "        'dnn_feature_columns': feature_columns,\n",
        "        'num_heads': 4,\n",
        "        'dnn_hidden_units': (256, 128, 64, 32, 16, 8),\n",
        "        'l2_reg_dnn': 1e-5,\n",
        "        'dnn_dropout': 0.42,\n",
        "      })\n",
        "  }\n",
        "\n",
        "  def ndcg_at_k(r, k):\n",
        "    r = np.asarray(r, dtype=float)[:k]\n",
        "    if r.size == 0:\n",
        "      return 0.0\n",
        "    dcg = np.sum((2 ** r - 1) / np.log2(np.arange(2, r.size + 2)))\n",
        "    ideal_r = np.sort(r)[::-1]\n",
        "    idcg = np.sum((2 ** ideal_r - 1) / np.log2(np.arange(2, ideal_r.size + 2)))\n",
        "    return dcg / idcg if idcg != 0 else 0.0\n",
        "\n",
        "\n",
        "  def precision_at_k(y_true, y_pred, k, relevance_threshold=3.7):  # Add relevance threshold\n",
        "      idx = np.argsort(y_pred)[::-1][:k]\n",
        "      return np.sum(np.array(y_true)[idx] >= relevance_threshold) / k  # Apply threshold\n",
        "\n",
        "  def recall_at_k(y_true, y_pred, k, relevance_threshold=3.7):  # Add relevance threshold\n",
        "      relevant = np.sum(np.array(y_true) >= relevance_threshold)  # Apply threshold\n",
        "      idx = np.argsort(y_pred)[::-1][:k]\n",
        "      return np.sum(np.array(y_true)[idx] >= relevance_threshold) / relevant if relevant > 0 else np.nan  # Handle zero division\n",
        "\n",
        "  def f1_at_k(precision, recall):\n",
        "      return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "  # Initialize results dictionary\n",
        "  results = {}\n",
        "\n",
        "  # Device configuration\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  # Function to measure CPU & memory usage\n",
        "  def get_resource_usage():\n",
        "      process = psutil.Process()\n",
        "      cpu_percent = psutil.cpu_percent(interval=1)  # CPU usage over 1 second\n",
        "      memory_info = process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
        "      return cpu_percent, memory_info\n",
        "\n",
        "  # Train and evaluate each model\n",
        "\n",
        "  for model_name, (model_class, model_params) in models.items():\n",
        "      print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "      # Start measuring time and resource usage\n",
        "      start_time = time.time()\n",
        "      cpu_before, memory_before = get_resource_usage()\n",
        "\n",
        "      # Define common parameters\n",
        "      common_params = {\n",
        "          'task': 'regression',\n",
        "          'device': device\n",
        "      }\n",
        "      # Update with model-specific parameters\n",
        "      common_params.update(model_params)\n",
        "\n",
        "      # Handle models that require special inputs\n",
        "      if model_name in ['AFM']:\n",
        "          common_params['use_attention'] = True\n",
        "\n",
        "      # Define the model\n",
        "      model = model_class(**common_params)\n",
        "      model.to(device)\n",
        "\n",
        "      # Compile the model\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "      model.compile(optimizer=optimizer, loss='mse', metrics=['mse','mae'])\n",
        "\n",
        "      # Define Early Stopping\n",
        "      early_stopping = EarlyStopping(monitor='val_mse', patience=5, verbose=1)\n",
        "      time.sleep(2)  # Simulate some work (replace with model training)\n",
        "      # Train the model\n",
        "      history = model.fit(\n",
        "          train_model_input,\n",
        "          train_data[target].values,\n",
        "          batch_size=256,\n",
        "          epochs=50,\n",
        "          verbose=2,\n",
        "          validation_split=0.3,\n",
        "          callbacks=[early_stopping]\n",
        "      )\n",
        "\n",
        "      # Predict on test set\n",
        "      predictions = model.predict(test_model_input, batch_size=256)\n",
        "\n",
        "      # Calculate RMSE and MAE\n",
        "      rmse = np.sqrt(mean_squared_error(test_data[target].values, predictions))\n",
        "      mae = mean_absolute_error(test_data[target].values, predictions)\n",
        "\n",
        "      k = 5\n",
        "      test_df = test_data.copy()\n",
        "      test_df[\"prediction\"] = predictions\n",
        "\n",
        "      # Compute NDCG per GroupID\n",
        "      precisions5, precisions10, recalls, f1s, ndcgs5,ndcgs10 = [], [], [], [], [], []\n",
        "      for group_id, group_df in test_df.groupby(\"GroupID\"):\n",
        "          true_ratings = group_df[target[0]].values\n",
        "          pred_scores = group_df[\"prediction\"].values\n",
        "\n",
        "          # Sort items by predicted scores\n",
        "          sorted_idx = np.argsort(pred_scores)[::-1]\n",
        "          sorted_true = true_ratings[sorted_idx]\n",
        "\n",
        "          prec5 = precision_at_k(true_ratings, pred_scores, 5)\n",
        "          prec10 = precision_at_k(true_ratings, pred_scores, 10)\n",
        "\n",
        "\n",
        "          ndcg5 = ndcg_at_k(sorted_true, 5)\n",
        "          ndcg10 = ndcg_at_k(sorted_true, 10)\n",
        "\n",
        "\n",
        "          precisions5.append(prec5)\n",
        "          precisions10.append(prec10)\n",
        "          ndcgs5.append(ndcg5)\n",
        "          ndcgs10.append(ndcg10)\n",
        "\n",
        "      avg_precision5 = np.mean(precisions5)\n",
        "      avg_precision10 = np.mean(precisions10)\n",
        "      avg_ndcg5 = np.mean(ndcgs5)\n",
        "      avg_ndcg10 = np.mean(ndcgs10)\n",
        "\n",
        "      # Convert MSE to RMSE and store both RMSE & MAE in history\n",
        "      history.history['RMSE'] = np.sqrt(history.history['mse'])  # Convert MSE to RMSE\n",
        "      history.history['val_RMSE'] = np.sqrt(history.history['val_mse'])  # Convert validation MSE to RMSE\n",
        "\n",
        "\n",
        "      # Measure execution time and resource usage\n",
        "      end_time = time.time()\n",
        "      cpu_after, memory_after = get_resource_usage()\n",
        "      execution_time = end_time - start_time\n",
        "      cpu_usage = cpu_after - cpu_before\n",
        "      memory_usage = memory_after - memory_before\n",
        "\n",
        "      # Store the results\n",
        "      results[model_name] = {\n",
        "          'RMSE': rmse,\n",
        "          'MAE': mae,\n",
        "          'NDCG@5':avg_ndcg5,\n",
        "          'NDCG@10':avg_ndcg10,\n",
        "          'Precision@5': avg_precision5,\n",
        "          'Precision@10': avg_precision10,\n",
        "          'Execution Time (s)': execution_time,\n",
        "          'CPU Usage (%)': cpu_usage,\n",
        "          'Memory Usage (MB)': memory_usage\n",
        "      }\n",
        "\n",
        "      print(f\"{model_name} Model RMSE: {rmse:.4f}\")\n",
        "      print(f\"{model_name} Model MAE: {mae:.4f}\")\n",
        "      print(f\"{model_name} Model NDCG@5: {avg_ndcg5:.4f}\")\n",
        "      print(f\"{model_name} Model NDCG@10: {avg_ndcg10:.4f}\")\n",
        "      print(f\"{model_name} Model Precision@5: {avg_precision5:.4f}\")\n",
        "      print(f\"{model_name} Model Precision@10: {avg_precision10:.4f}\")\n",
        "      print(f\"{model_name} Execution Time: {execution_time:.2f} seconds\")\n",
        "      print(f\"{model_name} CPU Usage: {cpu_usage:.2f}%\")\n",
        "      print(f\"{model_name} Memory Usage: {memory_usage:.2f} MB\")\n",
        "\n",
        "      # Save the history for MAE and RMSE after training each model\n",
        "      with open(f'./outputs/pickles/{model_name}_mvl_history.pkl', 'wb') as file_pi:\n",
        "          pickle.dump(history.history, file_pi)\n",
        "\n",
        "  # Display all results\n",
        "  print(\"\\nFinal Results:\")\n",
        "  for model_name, metrics in results.items():\n",
        "      #print(f\"{model_name} - RMSE: {metrics['RMSE']:.4f}, MAE: {metrics['MAE']:.4f}, \"\n",
        "      #      f\"Time: {metrics['Execution Time (s)']:.2f}s, CPU: {metrics['CPU Usage (%)']:.2f}%, \"\n",
        "      #      f\"Memory: {metrics['Memory Usage (MB)']:.2f}MB\")\n",
        "      print(f\"{model_name} - RMSE: {metrics['RMSE']:.4f}, MAE: {metrics['MAE']:.4f}, \",\n",
        "        f\"NDCG@5: {metrics['NDCG@5']:.4f}, \", f\"Precision@5: {metrics['Precision@5']:.4f},\",\n",
        "            f\"NDCG@10: {metrics['NDCG@10']:.4f}, \",\n",
        "            f\"Precision@10: {metrics['Precision@10']:.4f}, \",\n",
        "            f\"Time: {metrics['Execution Time (s)']:.2f}s, \",       f\"CPU: {metrics['CPU Usage (%)']:.2f}%, Memory: {metrics['Memory Usage (MB)']:.2f}MB\")\n",
        "  #sys.stdout.close()\n",
        "  #sys.stdout = sys.__stdout__\n",
        "\n",
        "  case = 1\n",
        "  # Decision based on case value\n",
        "sparse_features = [\n",
        "          'UserID',            # unique user\n",
        "          'GroupID',           # assigned via KMeans\n",
        "          'MovieID',           # unique movie\n",
        "          'Title',             # optional (high-cardinality), usually omit or hash\n",
        "          'UserOccupation',    # categorical occupation\n",
        "          'TimeOfDay',         # ['Morning', 'Afternoon', etc.]\n",
        "          'DayType',           # ['Weekday', 'Weekend']\n",
        "          'Season'             # ['Spring', 'Summer', etc.]\n",
        "      ]\n",
        "dense_features = [\n",
        "          'UserAge',           # continuous age\n",
        "          'Storyline',         # simulated multi-criteria\n",
        "          'Visuals',           # simulated multi-criteria\n",
        "          'Emotion'           # simulated multi-criteria\n",
        "      ]\n",
        "run(dense_features, sparse_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDeiztFi-wr2",
        "outputId": "23fb2312-abde-4588-ded6-daf953ffe77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_rating:     UserID  GroupID  MovieID                    Title                  Genres  \\\n",
            "0     196       21      242             Kolya (1996)                  Comedy   \n",
            "1     196       21      393    Mrs. Doubtfire (1993)                  Comedy   \n",
            "2     196       21      381  Muriel's Wedding (1994)          Comedy|Romance   \n",
            "3     196       21      251   Shall We Dance? (1996)                  Comedy   \n",
            "4     196       21      655       Stand by Me (1986)  Adventure|Comedy|Drama   \n",
            "\n",
            "   UserAge  UserOccupation  TimeOfDay  DayType  Season  Storyline   Visuals  \\\n",
            "0       49              20  Afternoon  Weekday  Winter   4.986857  5.000000   \n",
            "1       49              20  Afternoon  Weekday  Winter   3.446943  1.000000   \n",
            "2       49              20  Afternoon  Weekday  Winter   5.000000  5.000000   \n",
            "3       49              20  Afternoon  Weekday  Winter   5.000000  1.000000   \n",
            "4       49              20  Afternoon  Weekday  Winter   4.063386  3.690389   \n",
            "\n",
            "    Emotion  OverallRating  \n",
            "0  5.000000              3  \n",
            "1  3.623087              4  \n",
            "2  1.000000              4  \n",
            "3  1.000000              3  \n",
            "4  3.629397              5  \n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "sparse_features ['UserID', 'GroupID', 'MovieID', 'Title', 'UserOccupation', 'TimeOfDay', 'DayType', 'Season']\n",
            "feat:  UserID\n",
            "feat:  GroupID\n",
            "feat:  MovieID\n",
            "feat:  Title\n",
            "feat:  UserOccupation\n",
            "feat:  TimeOfDay\n",
            "feat:  DayType\n",
            "feat:  Season\n",
            "feature columns:  [SparseFeat(name='UserID', vocabulary_size=943, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserID', group_name='default_group'), SparseFeat(name='GroupID', vocabulary_size=250, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='GroupID', group_name='default_group'), SparseFeat(name='MovieID', vocabulary_size=1682, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='MovieID', group_name='default_group'), SparseFeat(name='Title', vocabulary_size=1664, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Title', group_name='default_group'), SparseFeat(name='UserOccupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserOccupation', group_name='default_group'), SparseFeat(name='TimeOfDay', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='TimeOfDay', group_name='default_group'), SparseFeat(name='DayType', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='DayType', group_name='default_group'), SparseFeat(name='Season', vocabulary_size=3, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Season', group_name='default_group'), DenseFeat(name='UserAge', dimension=1, dtype='float32'), DenseFeat(name='Storyline', dimension=1, dtype='float32'), DenseFeat(name='Visuals', dimension=1, dtype='float32'), DenseFeat(name='Emotion', dimension=1, dtype='float32')]\n",
            "\n",
            "Training and evaluating AFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  8.0794 - mse:  8.0740 - val_mse:  3.7193\n",
            "Epoch 2/50\n",
            "3s - loss:  1.6657 - mse:  1.6650 - val_mse:  1.0152\n",
            "Epoch 3/50\n",
            "2s - loss:  1.0041 - mse:  1.0040 - val_mse:  0.9561\n",
            "Epoch 4/50\n",
            "2s - loss:  0.9400 - mse:  0.9398 - val_mse:  0.9007\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8671 - mse:  0.8670 - val_mse:  0.8363\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7998 - mse:  0.7998 - val_mse:  0.8095\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7744 - mse:  0.7746 - val_mse:  0.8030\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7625 - mse:  0.7625 - val_mse:  0.7994\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7547 - mse:  0.7545 - val_mse:  0.7963\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7485 - mse:  0.7485 - val_mse:  0.7946\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7436 - mse:  0.7435 - val_mse:  0.7922\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7392 - mse:  0.7392 - val_mse:  0.7910\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7357 - mse:  0.7358 - val_mse:  0.7893\n",
            "Epoch 14/50\n",
            "3s - loss:  0.7324 - mse:  0.7325 - val_mse:  0.7890\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7298 - mse:  0.7298 - val_mse:  0.7880\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7268 - mse:  0.7268 - val_mse:  0.7869\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7242 - mse:  0.7241 - val_mse:  0.7871\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7214 - mse:  0.7214 - val_mse:  0.7870\n",
            "Epoch 19/50\n",
            "3s - loss:  0.7192 - mse:  0.7191 - val_mse:  0.7874\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7168 - mse:  0.7168 - val_mse:  0.7866\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7140 - mse:  0.7140 - val_mse:  0.7868\n",
            "Epoch 22/50\n",
            "2s - loss:  0.7117 - mse:  0.7116 - val_mse:  0.7877\n",
            "Epoch 23/50\n",
            "3s - loss:  0.7092 - mse:  0.7091 - val_mse:  0.7878\n",
            "Epoch 24/50\n",
            "2s - loss:  0.7064 - mse:  0.7064 - val_mse:  0.7887\n",
            "Epoch 25/50\n",
            "2s - loss:  0.7041 - mse:  0.7039 - val_mse:  0.7886\n",
            "Epoch 00025: early stopping\n",
            "AFM Model RMSE: 0.8915\n",
            "AFM Model MAE: 0.7039\n",
            "AFM Model NDCG@5: 0.9393\n",
            "AFM Model NDCG@10: 0.9267\n",
            "AFM Model Precision@5: 0.8600\n",
            "AFM Model Precision@10: 0.8076\n",
            "AFM Execution Time: 80.13 seconds\n",
            "AFM CPU Usage: -23.10%\n",
            "AFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating AutoInt...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.1688 - mse:  2.1672 - val_mse:  0.8147\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7879 - mse:  0.7880 - val_mse:  0.7953\n",
            "Epoch 3/50\n",
            "5s - loss:  0.7667 - mse:  0.7667 - val_mse:  0.7925\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7616 - mse:  0.7615 - val_mse:  0.7908\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7573 - mse:  0.7573 - val_mse:  0.7904\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7559 - mse:  0.7559 - val_mse:  0.7898\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7546 - mse:  0.7547 - val_mse:  0.7908\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7543 - mse:  0.7543 - val_mse:  0.7902\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7524 - mse:  0.7524 - val_mse:  0.7931\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7516 - mse:  0.7517 - val_mse:  0.7887\n",
            "Epoch 11/50\n",
            "4s - loss:  0.7491 - mse:  0.7492 - val_mse:  0.7992\n",
            "Epoch 12/50\n",
            "4s - loss:  0.7476 - mse:  0.7477 - val_mse:  0.7865\n",
            "Epoch 13/50\n",
            "5s - loss:  0.7424 - mse:  0.7424 - val_mse:  0.7866\n",
            "Epoch 14/50\n",
            "5s - loss:  0.7350 - mse:  0.7349 - val_mse:  0.7847\n",
            "Epoch 15/50\n",
            "4s - loss:  0.7280 - mse:  0.7280 - val_mse:  0.7871\n",
            "Epoch 16/50\n",
            "4s - loss:  0.7205 - mse:  0.7206 - val_mse:  0.7884\n",
            "Epoch 17/50\n",
            "4s - loss:  0.7139 - mse:  0.7138 - val_mse:  0.7871\n",
            "Epoch 18/50\n",
            "4s - loss:  0.7092 - mse:  0.7092 - val_mse:  0.7876\n",
            "Epoch 19/50\n",
            "4s - loss:  0.7025 - mse:  0.7025 - val_mse:  0.7925\n",
            "Epoch 00019: early stopping\n",
            "AutoInt Model RMSE: 0.8961\n",
            "AutoInt Model MAE: 0.7128\n",
            "AutoInt Model NDCG@5: 0.9310\n",
            "AutoInt Model NDCG@10: 0.9173\n",
            "AutoInt Model Precision@5: 0.8552\n",
            "AutoInt Model Precision@10: 0.7996\n",
            "AutoInt Execution Time: 95.37 seconds\n",
            "AutoInt CPU Usage: -0.10%\n",
            "AutoInt Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating CCPM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.0407 - mse:  2.0396 - val_mse:  1.0542\n",
            "Epoch 2/50\n",
            "4s - loss:  0.9309 - mse:  0.9308 - val_mse:  0.8598\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8162 - mse:  0.8162 - val_mse:  0.8324\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7801 - mse:  0.7801 - val_mse:  0.8194\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7533 - mse:  0.7533 - val_mse:  0.8185\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7313 - mse:  0.7312 - val_mse:  0.8079\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7125 - mse:  0.7124 - val_mse:  0.8037\n",
            "Epoch 8/50\n",
            "4s - loss:  0.6938 - mse:  0.6938 - val_mse:  0.8087\n",
            "Epoch 9/50\n",
            "4s - loss:  0.6763 - mse:  0.6764 - val_mse:  0.8182\n",
            "Epoch 10/50\n",
            "3s - loss:  0.6602 - mse:  0.6602 - val_mse:  0.8498\n",
            "Epoch 11/50\n",
            "4s - loss:  0.6489 - mse:  0.6488 - val_mse:  0.8363\n",
            "Epoch 12/50\n",
            "4s - loss:  0.6371 - mse:  0.6371 - val_mse:  0.8353\n",
            "Epoch 00012: early stopping\n",
            "CCPM Model RMSE: 0.9148\n",
            "CCPM Model MAE: 0.7231\n",
            "CCPM Model NDCG@5: 0.9270\n",
            "CCPM Model NDCG@10: 0.9174\n",
            "CCPM Model Precision@5: 0.8448\n",
            "CCPM Model Precision@10: 0.7916\n",
            "CCPM Execution Time: 52.04 seconds\n",
            "CCPM CPU Usage: 0.00%\n",
            "CCPM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DCN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.0436 - mse:  2.0422 - val_mse:  0.8089\n",
            "Epoch 2/50\n",
            "3s - loss:  0.7856 - mse:  0.7855 - val_mse:  0.7945\n",
            "Epoch 3/50\n",
            "3s - loss:  0.7672 - mse:  0.7671 - val_mse:  0.7904\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7620 - mse:  0.7619 - val_mse:  0.7910\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7570 - mse:  0.7571 - val_mse:  0.7913\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7552 - mse:  0.7554 - val_mse:  0.7924\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7543 - mse:  0.7545 - val_mse:  0.7892\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7521 - mse:  0.7521 - val_mse:  0.7920\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7531 - mse:  0.7530 - val_mse:  0.7939\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7504 - mse:  0.7506 - val_mse:  0.7907\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7487 - mse:  0.7487 - val_mse:  0.7999\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7489 - mse:  0.7490 - val_mse:  0.7906\n",
            "Epoch 00012: early stopping\n",
            "DCN Model RMSE: 0.8922\n",
            "DCN Model MAE: 0.7084\n",
            "DCN Model NDCG@5: 0.9350\n",
            "DCN Model NDCG@10: 0.9220\n",
            "DCN Model Precision@5: 0.8560\n",
            "DCN Model Precision@10: 0.8016\n",
            "DCN Execution Time: 43.60 seconds\n",
            "DCN CPU Usage: 2.10%\n",
            "DCN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.1390 - mse:  2.1376 - val_mse:  0.8136\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7888 - mse:  0.7887 - val_mse:  0.7936\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7693 - mse:  0.7694 - val_mse:  0.7924\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7632 - mse:  0.7631 - val_mse:  0.7960\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7601 - mse:  0.7600 - val_mse:  0.7944\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7573 - mse:  0.7574 - val_mse:  0.7916\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7571 - mse:  0.7571 - val_mse:  0.7937\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7551 - mse:  0.7551 - val_mse:  0.8103\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7552 - mse:  0.7553 - val_mse:  0.7949\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7535 - mse:  0.7536 - val_mse:  0.7969\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7534 - mse:  0.7536 - val_mse:  0.8001\n",
            "Epoch 00011: early stopping\n",
            "DeepFM Model RMSE: 0.8965\n",
            "DeepFM Model MAE: 0.7048\n",
            "DeepFM Model NDCG@5: 0.9307\n",
            "DeepFM Model NDCG@10: 0.9197\n",
            "DeepFM Model Precision@5: 0.8560\n",
            "DeepFM Model Precision@10: 0.8036\n",
            "DeepFM Execution Time: 35.77 seconds\n",
            "DeepFM CPU Usage: -13.70%\n",
            "DeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DIFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  3.2711 - mse:  3.2684 - val_mse:  0.8931\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8700 - mse:  0.8698 - val_mse:  0.8725\n",
            "Epoch 3/50\n",
            "4s - loss:  0.8386 - mse:  0.8385 - val_mse:  0.8569\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8160 - mse:  0.8159 - val_mse:  0.8371\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7918 - mse:  0.7919 - val_mse:  0.8348\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7731 - mse:  0.7732 - val_mse:  0.8219\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7565 - mse:  0.7565 - val_mse:  0.8167\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7397 - mse:  0.7398 - val_mse:  0.8114\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7241 - mse:  0.7240 - val_mse:  0.8036\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7088 - mse:  0.7090 - val_mse:  0.7953\n",
            "Epoch 11/50\n",
            "3s - loss:  0.6912 - mse:  0.6914 - val_mse:  0.7968\n",
            "Epoch 12/50\n",
            "4s - loss:  0.6767 - mse:  0.6767 - val_mse:  0.8033\n",
            "Epoch 13/50\n",
            "4s - loss:  0.6620 - mse:  0.6619 - val_mse:  0.8010\n",
            "Epoch 14/50\n",
            "3s - loss:  0.6496 - mse:  0.6496 - val_mse:  0.8187\n",
            "Epoch 15/50\n",
            "3s - loss:  0.6379 - mse:  0.6380 - val_mse:  0.8192\n",
            "Epoch 00015: early stopping\n",
            "DIFM Model RMSE: 0.9110\n",
            "DIFM Model MAE: 0.7124\n",
            "DIFM Model NDCG@5: 0.9370\n",
            "DIFM Model NDCG@10: 0.9220\n",
            "DIFM Model Precision@5: 0.8544\n",
            "DIFM Model Precision@10: 0.7972\n",
            "DIFM Execution Time: 62.28 seconds\n",
            "DIFM CPU Usage: 0.40%\n",
            "DIFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating FiBiNET...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "7s - loss:  2.4646 - mse:  2.4627 - val_mse:  0.8205\n",
            "Epoch 2/50\n",
            "6s - loss:  0.7918 - mse:  0.7918 - val_mse:  0.7943\n",
            "Epoch 3/50\n",
            "5s - loss:  0.7664 - mse:  0.7664 - val_mse:  0.7913\n",
            "Epoch 4/50\n",
            "5s - loss:  0.7586 - mse:  0.7585 - val_mse:  0.7905\n",
            "Epoch 5/50\n",
            "6s - loss:  0.7536 - mse:  0.7536 - val_mse:  0.7910\n",
            "Epoch 6/50\n",
            "6s - loss:  0.7476 - mse:  0.7475 - val_mse:  0.7849\n",
            "Epoch 7/50\n",
            "6s - loss:  0.7423 - mse:  0.7424 - val_mse:  0.7813\n",
            "Epoch 8/50\n",
            "5s - loss:  0.7335 - mse:  0.7335 - val_mse:  0.7807\n",
            "Epoch 9/50\n",
            "6s - loss:  0.7220 - mse:  0.7222 - val_mse:  0.7753\n",
            "Epoch 10/50\n",
            "5s - loss:  0.7100 - mse:  0.7102 - val_mse:  0.7791\n",
            "Epoch 11/50\n",
            "6s - loss:  0.6976 - mse:  0.6976 - val_mse:  0.7895\n",
            "Epoch 12/50\n",
            "5s - loss:  0.6839 - mse:  0.6840 - val_mse:  0.7889\n",
            "Epoch 13/50\n",
            "6s - loss:  0.6698 - mse:  0.6696 - val_mse:  0.7952\n",
            "Epoch 14/50\n",
            "5s - loss:  0.6571 - mse:  0.6571 - val_mse:  0.7988\n",
            "Epoch 00014: early stopping\n",
            "FiBiNET Model RMSE: 0.8970\n",
            "FiBiNET Model MAE: 0.7062\n",
            "FiBiNET Model NDCG@5: 0.9319\n",
            "FiBiNET Model NDCG@10: 0.9216\n",
            "FiBiNET Model Precision@5: 0.8592\n",
            "FiBiNET Model Precision@10: 0.8008\n",
            "FiBiNET Execution Time: 88.40 seconds\n",
            "FiBiNET CPU Usage: -4.40%\n",
            "FiBiNET Memory Usage: 1.00 MB\n",
            "\n",
            "Training and evaluating NFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  1.9852 - mse:  1.9839 - val_mse:  0.8400\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8066 - mse:  0.8066 - val_mse:  0.7995\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7732 - mse:  0.7734 - val_mse:  0.7963\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7647 - mse:  0.7647 - val_mse:  0.7944\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7595 - mse:  0.7596 - val_mse:  0.7957\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7573 - mse:  0.7572 - val_mse:  0.7938\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7557 - mse:  0.7558 - val_mse:  0.7943\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7540 - mse:  0.7541 - val_mse:  0.7942\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7520 - mse:  0.7520 - val_mse:  0.7921\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7517 - mse:  0.7516 - val_mse:  0.7931\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7491 - mse:  0.7490 - val_mse:  0.8019\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7510 - mse:  0.7510 - val_mse:  0.7938\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7482 - mse:  0.7480 - val_mse:  0.7936\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7487 - mse:  0.7488 - val_mse:  0.7997\n",
            "Epoch 00014: early stopping\n",
            "NFM Model RMSE: 0.8964\n",
            "NFM Model MAE: 0.7048\n",
            "NFM Model NDCG@5: 0.9335\n",
            "NFM Model NDCG@10: 0.9220\n",
            "NFM Model Precision@5: 0.8544\n",
            "NFM Model Precision@10: 0.8024\n",
            "NFM Execution Time: 43.87 seconds\n",
            "NFM CPU Usage: -0.20%\n",
            "NFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating ONN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "6s - loss:  2.0914 - mse:  2.0886 - val_mse:  0.8089\n",
            "Epoch 2/50\n",
            "6s - loss:  0.7429 - mse:  0.7416 - val_mse:  0.8179\n",
            "Epoch 3/50\n",
            "6s - loss:  0.6487 - mse:  0.6476 - val_mse:  0.8657\n",
            "Epoch 4/50\n",
            "6s - loss:  0.5849 - mse:  0.5837 - val_mse:  0.9187\n",
            "Epoch 5/50\n",
            "7s - loss:  0.5464 - mse:  0.5453 - val_mse:  0.9526\n",
            "Epoch 6/50\n",
            "7s - loss:  0.5194 - mse:  0.5182 - val_mse:  0.9815\n",
            "Epoch 00006: early stopping\n",
            "ONN Model RMSE: 0.9968\n",
            "ONN Model MAE: 0.7850\n",
            "ONN Model NDCG@5: 0.9045\n",
            "ONN Model NDCG@10: 0.8929\n",
            "ONN Model Precision@5: 0.8008\n",
            "ONN Model Precision@10: 0.7588\n",
            "ONN Execution Time: 44.69 seconds\n",
            "ONN CPU Usage: 8.80%\n",
            "ONN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating PNN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.4037 - mse:  2.4021 - val_mse:  0.8181\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7892 - mse:  0.7892 - val_mse:  0.7949\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7676 - mse:  0.7675 - val_mse:  0.7901\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7610 - mse:  0.7608 - val_mse:  0.7907\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7583 - mse:  0.7583 - val_mse:  0.7921\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7548 - mse:  0.7548 - val_mse:  0.7899\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7534 - mse:  0.7533 - val_mse:  0.7875\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7489 - mse:  0.7489 - val_mse:  0.7883\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7468 - mse:  0.7468 - val_mse:  0.7927\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7391 - mse:  0.7391 - val_mse:  0.7836\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7315 - mse:  0.7317 - val_mse:  0.7847\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7201 - mse:  0.7200 - val_mse:  0.7879\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7051 - mse:  0.7051 - val_mse:  0.7923\n",
            "Epoch 14/50\n",
            "2s - loss:  0.6873 - mse:  0.6873 - val_mse:  0.7982\n",
            "Epoch 15/50\n",
            "2s - loss:  0.6708 - mse:  0.6709 - val_mse:  0.8080\n",
            "Epoch 00015: early stopping\n",
            "PNN Model RMSE: 0.9005\n",
            "PNN Model MAE: 0.7083\n",
            "PNN Model NDCG@5: 0.9298\n",
            "PNN Model NDCG@10: 0.9208\n",
            "PNN Model Precision@5: 0.8624\n",
            "PNN Model Precision@10: 0.8012\n",
            "PNN Execution Time: 40.23 seconds\n",
            "PNN CPU Usage: -13.60%\n",
            "PNN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating WDL...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.1606 - mse:  2.1591 - val_mse:  0.8135\n",
            "Epoch 2/50\n",
            "3s - loss:  0.7876 - mse:  0.7875 - val_mse:  0.7924\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7674 - mse:  0.7675 - val_mse:  0.7911\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7612 - mse:  0.7611 - val_mse:  0.7947\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7580 - mse:  0.7579 - val_mse:  0.7934\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7553 - mse:  0.7554 - val_mse:  0.7907\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7551 - mse:  0.7551 - val_mse:  0.7927\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7533 - mse:  0.7533 - val_mse:  0.8100\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7535 - mse:  0.7536 - val_mse:  0.7951\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7520 - mse:  0.7521 - val_mse:  0.7955\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7521 - mse:  0.7522 - val_mse:  0.7996\n",
            "Epoch 00011: early stopping\n",
            "WDL Model RMSE: 0.8960\n",
            "WDL Model MAE: 0.7044\n",
            "WDL Model NDCG@5: 0.9322\n",
            "WDL Model NDCG@10: 0.9209\n",
            "WDL Model Precision@5: 0.8568\n",
            "WDL Model Precision@10: 0.8028\n",
            "WDL Execution Time: 34.88 seconds\n",
            "WDL CPU Usage: 13.10%\n",
            "WDL Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating xDeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  1.8725 - mse:  1.8712 - val_mse:  0.8062\n",
            "Epoch 2/50\n",
            "5s - loss:  0.7849 - mse:  0.7850 - val_mse:  0.7942\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7658 - mse:  0.7658 - val_mse:  0.7902\n",
            "Epoch 4/50\n",
            "5s - loss:  0.7604 - mse:  0.7603 - val_mse:  0.7903\n",
            "Epoch 5/50\n",
            "6s - loss:  0.7569 - mse:  0.7569 - val_mse:  0.7880\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7528 - mse:  0.7528 - val_mse:  0.7893\n",
            "Epoch 7/50\n",
            "5s - loss:  0.7509 - mse:  0.7509 - val_mse:  0.7889\n",
            "Epoch 8/50\n",
            "5s - loss:  0.7490 - mse:  0.7489 - val_mse:  0.7936\n",
            "Epoch 9/50\n",
            "5s - loss:  0.7463 - mse:  0.7463 - val_mse:  0.7871\n",
            "Epoch 10/50\n",
            "5s - loss:  0.7445 - mse:  0.7447 - val_mse:  0.7883\n",
            "Epoch 11/50\n",
            "5s - loss:  0.7405 - mse:  0.7407 - val_mse:  0.7984\n",
            "Epoch 12/50\n",
            "5s - loss:  0.7381 - mse:  0.7382 - val_mse:  0.7875\n",
            "Epoch 13/50\n",
            "5s - loss:  0.7346 - mse:  0.7346 - val_mse:  0.7906\n",
            "Epoch 14/50\n",
            "5s - loss:  0.7335 - mse:  0.7336 - val_mse:  0.7842\n",
            "Epoch 15/50\n",
            "5s - loss:  0.7303 - mse:  0.7304 - val_mse:  0.7832\n",
            "Epoch 16/50\n",
            "5s - loss:  0.7279 - mse:  0.7278 - val_mse:  0.7851\n",
            "Epoch 17/50\n",
            "5s - loss:  0.7262 - mse:  0.7263 - val_mse:  0.7931\n",
            "Epoch 18/50\n",
            "5s - loss:  0.7235 - mse:  0.7236 - val_mse:  0.7891\n",
            "Epoch 19/50\n",
            "5s - loss:  0.7218 - mse:  0.7218 - val_mse:  0.7908\n",
            "Epoch 20/50\n",
            "5s - loss:  0.7183 - mse:  0.7183 - val_mse:  0.7876\n",
            "Epoch 00020: early stopping\n",
            "xDeepFM Model RMSE: 0.8906\n",
            "xDeepFM Model MAE: 0.7074\n",
            "xDeepFM Model NDCG@5: 0.9332\n",
            "xDeepFM Model NDCG@10: 0.9238\n",
            "xDeepFM Model Precision@5: 0.8616\n",
            "xDeepFM Model Precision@10: 0.8012\n",
            "xDeepFM Execution Time: 111.10 seconds\n",
            "xDeepFM CPU Usage: -9.70%\n",
            "xDeepFM Memory Usage: 0.25 MB\n",
            "\n",
            "Training and evaluating IFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  4.4052 - mse:  4.4016 - val_mse:  1.1590\n",
            "Epoch 2/50\n",
            "3s - loss:  1.1162 - mse:  1.1158 - val_mse:  0.9062\n",
            "Epoch 3/50\n",
            "2s - loss:  0.8472 - mse:  0.8471 - val_mse:  0.8406\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8076 - mse:  0.8077 - val_mse:  0.8330\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7866 - mse:  0.7865 - val_mse:  0.8156\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7760 - mse:  0.7761 - val_mse:  0.8129\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7692 - mse:  0.7693 - val_mse:  0.8092\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7603 - mse:  0.7602 - val_mse:  0.8035\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7574 - mse:  0.7575 - val_mse:  0.7991\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7520 - mse:  0.7521 - val_mse:  0.7953\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7484 - mse:  0.7483 - val_mse:  0.7983\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7466 - mse:  0.7468 - val_mse:  0.7934\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7471 - mse:  0.7471 - val_mse:  0.7940\n",
            "Epoch 14/50\n",
            "3s - loss:  0.7438 - mse:  0.7438 - val_mse:  0.7913\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7436 - mse:  0.7435 - val_mse:  0.7917\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7420 - mse:  0.7419 - val_mse:  0.7975\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7395 - mse:  0.7397 - val_mse:  0.7925\n",
            "Epoch 18/50\n",
            "3s - loss:  0.7367 - mse:  0.7367 - val_mse:  0.7855\n",
            "Epoch 19/50\n",
            "3s - loss:  0.7357 - mse:  0.7357 - val_mse:  0.7883\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7339 - mse:  0.7339 - val_mse:  0.7866\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7306 - mse:  0.7305 - val_mse:  0.7877\n",
            "Epoch 22/50\n",
            "3s - loss:  0.7290 - mse:  0.7289 - val_mse:  0.7894\n",
            "Epoch 23/50\n",
            "3s - loss:  0.7266 - mse:  0.7267 - val_mse:  0.7867\n",
            "Epoch 00023: early stopping\n",
            "IFM Model RMSE: 0.8906\n",
            "IFM Model MAE: 0.7077\n",
            "IFM Model NDCG@5: 0.9303\n",
            "IFM Model NDCG@10: 0.9178\n",
            "IFM Model Precision@5: 0.8528\n",
            "IFM Model Precision@10: 0.8028\n",
            "IFM Execution Time: 72.74 seconds\n",
            "IFM CPU Usage: 0.00%\n",
            "IFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating LS-PLM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  10.2754 - mse:  10.2714 - val_mse:  6.7326\n",
            "Epoch 2/50\n",
            "4s - loss:  4.2170 - mse:  4.2148 - val_mse:  2.3594\n",
            "Epoch 3/50\n",
            "4s - loss:  1.6358 - mse:  1.6353 - val_mse:  1.2027\n",
            "Epoch 4/50\n",
            "4s - loss:  1.1015 - mse:  1.1014 - val_mse:  1.0281\n",
            "Epoch 5/50\n",
            "4s - loss:  1.0138 - mse:  1.0136 - val_mse:  0.9870\n",
            "Epoch 6/50\n",
            "4s - loss:  0.9753 - mse:  0.9754 - val_mse:  0.9589\n",
            "Epoch 7/50\n",
            "5s - loss:  0.9435 - mse:  0.9435 - val_mse:  0.9349\n",
            "Epoch 8/50\n",
            "4s - loss:  0.9154 - mse:  0.9154 - val_mse:  0.9137\n",
            "Epoch 9/50\n",
            "4s - loss:  0.8905 - mse:  0.8905 - val_mse:  0.8950\n",
            "Epoch 10/50\n",
            "5s - loss:  0.8683 - mse:  0.8684 - val_mse:  0.8781\n",
            "Epoch 11/50\n",
            "5s - loss:  0.8485 - mse:  0.8486 - val_mse:  0.8632\n",
            "Epoch 12/50\n",
            "5s - loss:  0.8308 - mse:  0.8308 - val_mse:  0.8502\n",
            "Epoch 13/50\n",
            "4s - loss:  0.8154 - mse:  0.8154 - val_mse:  0.8389\n",
            "Epoch 14/50\n",
            "4s - loss:  0.8020 - mse:  0.8021 - val_mse:  0.8290\n",
            "Epoch 15/50\n",
            "4s - loss:  0.7904 - mse:  0.7905 - val_mse:  0.8213\n",
            "Epoch 16/50\n",
            "4s - loss:  0.7809 - mse:  0.7809 - val_mse:  0.8147\n",
            "Epoch 17/50\n",
            "5s - loss:  0.7731 - mse:  0.7731 - val_mse:  0.8094\n",
            "Epoch 18/50\n",
            "4s - loss:  0.7667 - mse:  0.7667 - val_mse:  0.8056\n",
            "Epoch 19/50\n",
            "4s - loss:  0.7616 - mse:  0.7616 - val_mse:  0.8027\n",
            "Epoch 20/50\n",
            "5s - loss:  0.7575 - mse:  0.7575 - val_mse:  0.8007\n",
            "Epoch 21/50\n",
            "4s - loss:  0.7543 - mse:  0.7542 - val_mse:  0.7995\n",
            "Epoch 22/50\n",
            "5s - loss:  0.7518 - mse:  0.7518 - val_mse:  0.7982\n",
            "Epoch 23/50\n",
            "5s - loss:  0.7497 - mse:  0.7497 - val_mse:  0.7976\n",
            "Epoch 24/50\n",
            "4s - loss:  0.7480 - mse:  0.7481 - val_mse:  0.7973\n",
            "Epoch 25/50\n",
            "5s - loss:  0.7467 - mse:  0.7468 - val_mse:  0.7971\n",
            "Epoch 26/50\n",
            "4s - loss:  0.7454 - mse:  0.7455 - val_mse:  0.7971\n",
            "Epoch 27/50\n",
            "5s - loss:  0.7444 - mse:  0.7443 - val_mse:  0.7970\n",
            "Epoch 28/50\n",
            "4s - loss:  0.7434 - mse:  0.7434 - val_mse:  0.7971\n",
            "Epoch 29/50\n",
            "5s - loss:  0.7429 - mse:  0.7428 - val_mse:  0.7971\n",
            "Epoch 30/50\n",
            "5s - loss:  0.7420 - mse:  0.7420 - val_mse:  0.7975\n",
            "Epoch 31/50\n",
            "4s - loss:  0.7418 - mse:  0.7417 - val_mse:  0.7970\n",
            "Epoch 32/50\n",
            "5s - loss:  0.7409 - mse:  0.7408 - val_mse:  0.7972\n",
            "Epoch 33/50\n",
            "4s - loss:  0.7405 - mse:  0.7406 - val_mse:  0.7974\n",
            "Epoch 34/50\n",
            "4s - loss:  0.7399 - mse:  0.7399 - val_mse:  0.7975\n",
            "Epoch 35/50\n",
            "5s - loss:  0.7395 - mse:  0.7393 - val_mse:  0.7975\n",
            "Epoch 36/50\n",
            "4s - loss:  0.7389 - mse:  0.7389 - val_mse:  0.7974\n",
            "Epoch 00036: early stopping\n",
            "LS-PLM Model RMSE: 0.8948\n",
            "LS-PLM Model MAE: 0.7088\n",
            "LS-PLM Model NDCG@5: 0.9362\n",
            "LS-PLM Model NDCG@10: 0.9214\n",
            "LS-PLM Model Precision@5: 0.8552\n",
            "LS-PLM Model Precision@10: 0.8040\n",
            "LS-PLM Execution Time: 182.48 seconds\n",
            "LS-PLM CPU Usage: -0.30%\n",
            "LS-PLM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating MHA...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "8s - loss:  3.5287 - mse:  3.5269 - val_mse:  1.1721\n",
            "Epoch 2/50\n",
            "8s - loss:  1.0759 - mse:  1.0757 - val_mse:  1.0068\n",
            "Epoch 3/50\n",
            "7s - loss:  0.9852 - mse:  0.9852 - val_mse:  0.9420\n",
            "Epoch 4/50\n",
            "8s - loss:  0.9214 - mse:  0.9213 - val_mse:  0.8947\n",
            "Epoch 5/50\n",
            "8s - loss:  0.8740 - mse:  0.8741 - val_mse:  0.8607\n",
            "Epoch 6/50\n",
            "7s - loss:  0.8393 - mse:  0.8393 - val_mse:  0.8370\n",
            "Epoch 7/50\n",
            "8s - loss:  0.8140 - mse:  0.8142 - val_mse:  0.8206\n",
            "Epoch 8/50\n",
            "8s - loss:  0.7958 - mse:  0.7959 - val_mse:  0.8092\n",
            "Epoch 9/50\n",
            "7s - loss:  0.7824 - mse:  0.7824 - val_mse:  0.8017\n",
            "Epoch 10/50\n",
            "8s - loss:  0.7729 - mse:  0.7730 - val_mse:  0.7970\n",
            "Epoch 11/50\n",
            "8s - loss:  0.7654 - mse:  0.7654 - val_mse:  0.7937\n",
            "Epoch 12/50\n",
            "8s - loss:  0.7601 - mse:  0.7602 - val_mse:  0.7927\n",
            "Epoch 13/50\n",
            "10s - loss:  0.7557 - mse:  0.7558 - val_mse:  0.7903\n",
            "Epoch 14/50\n",
            "8s - loss:  0.7527 - mse:  0.7525 - val_mse:  0.7895\n",
            "Epoch 15/50\n",
            "8s - loss:  0.7497 - mse:  0.7498 - val_mse:  0.7884\n",
            "Epoch 16/50\n",
            "8s - loss:  0.7472 - mse:  0.7472 - val_mse:  0.7898\n",
            "Epoch 17/50\n",
            "8s - loss:  0.7457 - mse:  0.7456 - val_mse:  0.7881\n",
            "Epoch 18/50\n",
            "8s - loss:  0.7437 - mse:  0.7436 - val_mse:  0.7882\n",
            "Epoch 19/50\n",
            "8s - loss:  0.7426 - mse:  0.7427 - val_mse:  0.7878\n",
            "Epoch 20/50\n",
            "8s - loss:  0.7411 - mse:  0.7412 - val_mse:  0.7880\n",
            "Epoch 21/50\n",
            "8s - loss:  0.7401 - mse:  0.7402 - val_mse:  0.7890\n",
            "Epoch 22/50\n",
            "8s - loss:  0.7392 - mse:  0.7392 - val_mse:  0.7884\n",
            "Epoch 23/50\n",
            "8s - loss:  0.7385 - mse:  0.7385 - val_mse:  0.7883\n",
            "Epoch 24/50\n",
            "8s - loss:  0.7376 - mse:  0.7376 - val_mse:  0.7886\n",
            "Epoch 00024: early stopping\n",
            "MHA Model RMSE: 0.8899\n",
            "MHA Model MAE: 0.7058\n",
            "MHA Model NDCG@5: 0.9347\n",
            "MHA Model NDCG@10: 0.9225\n",
            "MHA Model Precision@5: 0.8576\n",
            "MHA Model Precision@10: 0.8036\n",
            "MHA Execution Time: 204.74 seconds\n",
            "MHA CPU Usage: -0.10%\n",
            "MHA Memory Usage: 0.00 MB\n",
            "\n",
            "Final Results:\n",
            "AFM - RMSE: 0.8915, MAE: 0.7039,  NDCG@5: 0.9393,  Precision@5: 0.8600, NDCG@10: 0.9267,  Precision@10: 0.8076,  Time: 80.13s,  CPU: -23.10%, Memory: 0.00MB\n",
            "AutoInt - RMSE: 0.8961, MAE: 0.7128,  NDCG@5: 0.9310,  Precision@5: 0.8552, NDCG@10: 0.9173,  Precision@10: 0.7996,  Time: 95.37s,  CPU: -0.10%, Memory: 0.00MB\n",
            "CCPM - RMSE: 0.9148, MAE: 0.7231,  NDCG@5: 0.9270,  Precision@5: 0.8448, NDCG@10: 0.9174,  Precision@10: 0.7916,  Time: 52.04s,  CPU: 0.00%, Memory: 0.00MB\n",
            "DCN - RMSE: 0.8922, MAE: 0.7084,  NDCG@5: 0.9350,  Precision@5: 0.8560, NDCG@10: 0.9220,  Precision@10: 0.8016,  Time: 43.60s,  CPU: 2.10%, Memory: 0.00MB\n",
            "DeepFM - RMSE: 0.8965, MAE: 0.7048,  NDCG@5: 0.9307,  Precision@5: 0.8560, NDCG@10: 0.9197,  Precision@10: 0.8036,  Time: 35.77s,  CPU: -13.70%, Memory: 0.00MB\n",
            "DIFM - RMSE: 0.9110, MAE: 0.7124,  NDCG@5: 0.9370,  Precision@5: 0.8544, NDCG@10: 0.9220,  Precision@10: 0.7972,  Time: 62.28s,  CPU: 0.40%, Memory: 0.00MB\n",
            "FiBiNET - RMSE: 0.8970, MAE: 0.7062,  NDCG@5: 0.9319,  Precision@5: 0.8592, NDCG@10: 0.9216,  Precision@10: 0.8008,  Time: 88.40s,  CPU: -4.40%, Memory: 1.00MB\n",
            "NFM - RMSE: 0.8964, MAE: 0.7048,  NDCG@5: 0.9335,  Precision@5: 0.8544, NDCG@10: 0.9220,  Precision@10: 0.8024,  Time: 43.87s,  CPU: -0.20%, Memory: 0.00MB\n",
            "ONN - RMSE: 0.9968, MAE: 0.7850,  NDCG@5: 0.9045,  Precision@5: 0.8008, NDCG@10: 0.8929,  Precision@10: 0.7588,  Time: 44.69s,  CPU: 8.80%, Memory: 0.00MB\n",
            "PNN - RMSE: 0.9005, MAE: 0.7083,  NDCG@5: 0.9298,  Precision@5: 0.8624, NDCG@10: 0.9208,  Precision@10: 0.8012,  Time: 40.23s,  CPU: -13.60%, Memory: 0.00MB\n",
            "WDL - RMSE: 0.8960, MAE: 0.7044,  NDCG@5: 0.9322,  Precision@5: 0.8568, NDCG@10: 0.9209,  Precision@10: 0.8028,  Time: 34.88s,  CPU: 13.10%, Memory: 0.00MB\n",
            "xDeepFM - RMSE: 0.8906, MAE: 0.7074,  NDCG@5: 0.9332,  Precision@5: 0.8616, NDCG@10: 0.9238,  Precision@10: 0.8012,  Time: 111.10s,  CPU: -9.70%, Memory: 0.25MB\n",
            "IFM - RMSE: 0.8906, MAE: 0.7077,  NDCG@5: 0.9303,  Precision@5: 0.8528, NDCG@10: 0.9178,  Precision@10: 0.8028,  Time: 72.74s,  CPU: 0.00%, Memory: 0.00MB\n",
            "LS-PLM - RMSE: 0.8948, MAE: 0.7088,  NDCG@5: 0.9362,  Precision@5: 0.8552, NDCG@10: 0.9214,  Precision@10: 0.8040,  Time: 182.48s,  CPU: -0.30%, Memory: 0.00MB\n",
            "MHA - RMSE: 0.8899, MAE: 0.7058,  NDCG@5: 0.9347,  Precision@5: 0.8576, NDCG@10: 0.9225,  Precision@10: 0.8036,  Time: 204.74s,  CPU: -0.10%, Memory: 0.00MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MCGRS: Running Prediction with criteria, without context**"
      ],
      "metadata": {
        "id": "6ax5ayNUBW43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "case = 2\n",
        "  # Decision based on case value\n",
        "sparse_features = [\n",
        "          'UserID',            # unique user\n",
        "          'GroupID',           # assigned via KMeans\n",
        "          'MovieID',           # unique movie\n",
        "          'Title',             # optional (high-cardinality), usually omit or hash\n",
        "          'UserOccupation',    # categorical occupation\n",
        "      ]\n",
        "dense_features = [\n",
        "          'UserAge',           # continuous age\n",
        "          'Storyline',         # simulated multi-criteria\n",
        "          'Visuals',           # simulated multi-criteria\n",
        "          'Emotion'           # simulated multi-criteria\n",
        "      ]\n",
        "run(dense_features, sparse_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDsQ5Q-yBWCh",
        "outputId": "2efc3690-a442-4abd-f694-0b96c1979d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_rating:     UserID  GroupID  MovieID                    Title                  Genres  \\\n",
            "0     196       21      242             Kolya (1996)                  Comedy   \n",
            "1     196       21      393    Mrs. Doubtfire (1993)                  Comedy   \n",
            "2     196       21      381  Muriel's Wedding (1994)          Comedy|Romance   \n",
            "3     196       21      251   Shall We Dance? (1996)                  Comedy   \n",
            "4     196       21      655       Stand by Me (1986)  Adventure|Comedy|Drama   \n",
            "\n",
            "   UserAge  UserOccupation  TimeOfDay  DayType  Season  Storyline   Visuals  \\\n",
            "0       49              20  Afternoon  Weekday  Winter   4.986857  5.000000   \n",
            "1       49              20  Afternoon  Weekday  Winter   3.446943  1.000000   \n",
            "2       49              20  Afternoon  Weekday  Winter   5.000000  5.000000   \n",
            "3       49              20  Afternoon  Weekday  Winter   5.000000  1.000000   \n",
            "4       49              20  Afternoon  Weekday  Winter   4.063386  3.690389   \n",
            "\n",
            "    Emotion  OverallRating  \n",
            "0  5.000000              3  \n",
            "1  3.623087              4  \n",
            "2  1.000000              4  \n",
            "3  1.000000              3  \n",
            "4  3.629397              5  \n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "sparse_features ['UserID', 'GroupID', 'MovieID', 'Title', 'UserOccupation']\n",
            "feat:  UserID\n",
            "feat:  GroupID\n",
            "feat:  MovieID\n",
            "feat:  Title\n",
            "feat:  UserOccupation\n",
            "feature columns:  [SparseFeat(name='UserID', vocabulary_size=943, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserID', group_name='default_group'), SparseFeat(name='GroupID', vocabulary_size=250, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='GroupID', group_name='default_group'), SparseFeat(name='MovieID', vocabulary_size=1682, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='MovieID', group_name='default_group'), SparseFeat(name='Title', vocabulary_size=1664, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Title', group_name='default_group'), SparseFeat(name='UserOccupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserOccupation', group_name='default_group'), DenseFeat(name='UserAge', dimension=1, dtype='float32'), DenseFeat(name='Storyline', dimension=1, dtype='float32'), DenseFeat(name='Visuals', dimension=1, dtype='float32'), DenseFeat(name='Emotion', dimension=1, dtype='float32')]\n",
            "\n",
            "Training and evaluating AFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  9.5492 - mse:  9.5452 - val_mse:  5.8395\n",
            "Epoch 2/50\n",
            "2s - loss:  2.4966 - mse:  2.4949 - val_mse:  1.0917\n",
            "Epoch 3/50\n",
            "2s - loss:  1.0248 - mse:  1.0246 - val_mse:  0.9575\n",
            "Epoch 4/50\n",
            "2s - loss:  0.9336 - mse:  0.9335 - val_mse:  0.9056\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8847 - mse:  0.8848 - val_mse:  0.8727\n",
            "Epoch 6/50\n",
            "2s - loss:  0.8507 - mse:  0.8507 - val_mse:  0.8497\n",
            "Epoch 7/50\n",
            "2s - loss:  0.8248 - mse:  0.8249 - val_mse:  0.8327\n",
            "Epoch 8/50\n",
            "2s - loss:  0.8045 - mse:  0.8045 - val_mse:  0.8200\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7882 - mse:  0.7881 - val_mse:  0.8114\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7751 - mse:  0.7751 - val_mse:  0.8040\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7641 - mse:  0.7640 - val_mse:  0.7993\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7550 - mse:  0.7549 - val_mse:  0.7964\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7470 - mse:  0.7468 - val_mse:  0.7941\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7397 - mse:  0.7397 - val_mse:  0.7925\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7335 - mse:  0.7334 - val_mse:  0.7919\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7273 - mse:  0.7273 - val_mse:  0.7918\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7218 - mse:  0.7217 - val_mse:  0.7919\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7162 - mse:  0.7161 - val_mse:  0.7930\n",
            "Epoch 19/50\n",
            "2s - loss:  0.7108 - mse:  0.7108 - val_mse:  0.7945\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7055 - mse:  0.7054 - val_mse:  0.7965\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7005 - mse:  0.7005 - val_mse:  0.7989\n",
            "Epoch 00021: early stopping\n",
            "AFM Model RMSE: 0.8948\n",
            "AFM Model MAE: 0.7105\n",
            "AFM Model NDCG@5: 0.9307\n",
            "AFM Model NDCG@10: 0.9182\n",
            "AFM Model Precision@5: 0.8520\n",
            "AFM Model Precision@10: 0.7996\n",
            "AFM Execution Time: 54.27 seconds\n",
            "AFM CPU Usage: -0.30%\n",
            "AFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating AutoInt...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.3007 - mse:  2.2991 - val_mse:  0.8132\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7886 - mse:  0.7885 - val_mse:  0.7923\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7667 - mse:  0.7668 - val_mse:  0.7929\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7598 - mse:  0.7598 - val_mse:  0.7901\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7554 - mse:  0.7552 - val_mse:  0.7900\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7505 - mse:  0.7505 - val_mse:  0.7900\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7451 - mse:  0.7451 - val_mse:  0.7909\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7394 - mse:  0.7394 - val_mse:  0.7872\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7332 - mse:  0.7332 - val_mse:  0.7925\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7240 - mse:  0.7239 - val_mse:  0.7907\n",
            "Epoch 11/50\n",
            "4s - loss:  0.7186 - mse:  0.7186 - val_mse:  0.8031\n",
            "Epoch 12/50\n",
            "4s - loss:  0.7124 - mse:  0.7123 - val_mse:  0.8115\n",
            "Epoch 13/50\n",
            "4s - loss:  0.7066 - mse:  0.7066 - val_mse:  0.7989\n",
            "Epoch 00013: early stopping\n",
            "AutoInt Model RMSE: 0.8963\n",
            "AutoInt Model MAE: 0.7062\n",
            "AutoInt Model NDCG@5: 0.9339\n",
            "AutoInt Model NDCG@10: 0.9211\n",
            "AutoInt Model Precision@5: 0.8512\n",
            "AutoInt Model Precision@10: 0.8048\n",
            "AutoInt Execution Time: 60.11 seconds\n",
            "AutoInt CPU Usage: -4.00%\n",
            "AutoInt Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating CCPM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.1929 - mse:  2.1915 - val_mse:  0.9789\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8879 - mse:  0.8879 - val_mse:  0.8576\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8158 - mse:  0.8158 - val_mse:  0.8330\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7881 - mse:  0.7879 - val_mse:  0.8190\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7668 - mse:  0.7668 - val_mse:  0.8117\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7480 - mse:  0.7481 - val_mse:  0.7987\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7338 - mse:  0.7338 - val_mse:  0.7986\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7184 - mse:  0.7185 - val_mse:  0.7939\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7038 - mse:  0.7038 - val_mse:  0.7935\n",
            "Epoch 10/50\n",
            "3s - loss:  0.6903 - mse:  0.6904 - val_mse:  0.7963\n",
            "Epoch 11/50\n",
            "3s - loss:  0.6735 - mse:  0.6736 - val_mse:  0.8093\n",
            "Epoch 12/50\n",
            "3s - loss:  0.6579 - mse:  0.6577 - val_mse:  0.8140\n",
            "Epoch 13/50\n",
            "3s - loss:  0.6411 - mse:  0.6412 - val_mse:  0.8298\n",
            "Epoch 14/50\n",
            "3s - loss:  0.6265 - mse:  0.6267 - val_mse:  0.8507\n",
            "Epoch 00014: early stopping\n",
            "CCPM Model RMSE: 0.9231\n",
            "CCPM Model MAE: 0.7237\n",
            "CCPM Model NDCG@5: 0.9227\n",
            "CCPM Model NDCG@10: 0.9121\n",
            "CCPM Model Precision@5: 0.8360\n",
            "CCPM Model Precision@10: 0.7900\n",
            "CCPM Execution Time: 51.14 seconds\n",
            "CCPM CPU Usage: 0.10%\n",
            "CCPM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DCN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  1.9554 - mse:  1.9542 - val_mse:  0.8129\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7864 - mse:  0.7864 - val_mse:  0.7942\n",
            "Epoch 3/50\n",
            "3s - loss:  0.7674 - mse:  0.7674 - val_mse:  0.7934\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7605 - mse:  0.7605 - val_mse:  0.7933\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7575 - mse:  0.7575 - val_mse:  0.7929\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7560 - mse:  0.7560 - val_mse:  0.7941\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7530 - mse:  0.7531 - val_mse:  0.7906\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7522 - mse:  0.7523 - val_mse:  0.7928\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7513 - mse:  0.7512 - val_mse:  0.7933\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7494 - mse:  0.7494 - val_mse:  0.7895\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7485 - mse:  0.7484 - val_mse:  0.7910\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7482 - mse:  0.7482 - val_mse:  0.8040\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7452 - mse:  0.7452 - val_mse:  0.7894\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7448 - mse:  0.7448 - val_mse:  0.7905\n",
            "Epoch 15/50\n",
            "3s - loss:  0.7416 - mse:  0.7416 - val_mse:  0.7941\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7407 - mse:  0.7409 - val_mse:  0.7943\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7360 - mse:  0.7361 - val_mse:  0.7852\n",
            "Epoch 18/50\n",
            "3s - loss:  0.7333 - mse:  0.7335 - val_mse:  0.7955\n",
            "Epoch 19/50\n",
            "2s - loss:  0.7317 - mse:  0.7317 - val_mse:  0.7880\n",
            "Epoch 20/50\n",
            "3s - loss:  0.7293 - mse:  0.7293 - val_mse:  0.7872\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7241 - mse:  0.7241 - val_mse:  0.7864\n",
            "Epoch 22/50\n",
            "3s - loss:  0.7212 - mse:  0.7211 - val_mse:  0.7873\n",
            "Epoch 00022: early stopping\n",
            "DCN Model RMSE: 0.8925\n",
            "DCN Model MAE: 0.7054\n",
            "DCN Model NDCG@5: 0.9283\n",
            "DCN Model NDCG@10: 0.9178\n",
            "DCN Model Precision@5: 0.8448\n",
            "DCN Model Precision@10: 0.7996\n",
            "DCN Execution Time: 75.64 seconds\n",
            "DCN CPU Usage: 0.00%\n",
            "DCN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.0329 - mse:  2.0315 - val_mse:  0.8096\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7877 - mse:  0.7877 - val_mse:  0.7950\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7681 - mse:  0.7681 - val_mse:  0.7929\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7630 - mse:  0.7630 - val_mse:  0.7897\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7594 - mse:  0.7594 - val_mse:  0.7923\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7571 - mse:  0.7571 - val_mse:  0.7913\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7562 - mse:  0.7562 - val_mse:  0.7921\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7540 - mse:  0.7540 - val_mse:  0.7934\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7540 - mse:  0.7540 - val_mse:  0.7921\n",
            "Epoch 00009: early stopping\n",
            "DeepFM Model RMSE: 0.8927\n",
            "DeepFM Model MAE: 0.7086\n",
            "DeepFM Model NDCG@5: 0.9333\n",
            "DeepFM Model NDCG@10: 0.9214\n",
            "DeepFM Model Precision@5: 0.8544\n",
            "DeepFM Model Precision@10: 0.8048\n",
            "DeepFM Execution Time: 28.04 seconds\n",
            "DeepFM CPU Usage: 27.40%\n",
            "DeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DIFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  3.6483 - mse:  3.6450 - val_mse:  0.9124\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8738 - mse:  0.8736 - val_mse:  0.8804\n",
            "Epoch 3/50\n",
            "4s - loss:  0.8341 - mse:  0.8342 - val_mse:  0.8695\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8105 - mse:  0.8105 - val_mse:  0.8558\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7864 - mse:  0.7864 - val_mse:  0.8432\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7697 - mse:  0.7698 - val_mse:  0.8337\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7520 - mse:  0.7521 - val_mse:  0.8295\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7381 - mse:  0.7379 - val_mse:  0.8255\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7250 - mse:  0.7249 - val_mse:  0.8156\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7113 - mse:  0.7113 - val_mse:  0.8155\n",
            "Epoch 11/50\n",
            "3s - loss:  0.6986 - mse:  0.6985 - val_mse:  0.8085\n",
            "Epoch 12/50\n",
            "4s - loss:  0.6837 - mse:  0.6835 - val_mse:  0.8174\n",
            "Epoch 13/50\n",
            "3s - loss:  0.6704 - mse:  0.6703 - val_mse:  0.8123\n",
            "Epoch 14/50\n",
            "3s - loss:  0.6566 - mse:  0.6567 - val_mse:  0.8098\n",
            "Epoch 15/50\n",
            "3s - loss:  0.6464 - mse:  0.6465 - val_mse:  0.8178\n",
            "Epoch 16/50\n",
            "4s - loss:  0.6350 - mse:  0.6351 - val_mse:  0.8115\n",
            "Epoch 00016: early stopping\n",
            "DIFM Model RMSE: 0.9027\n",
            "DIFM Model MAE: 0.7118\n",
            "DIFM Model NDCG@5: 0.9348\n",
            "DIFM Model NDCG@10: 0.9220\n",
            "DIFM Model Precision@5: 0.8576\n",
            "DIFM Model Precision@10: 0.7992\n",
            "DIFM Execution Time: 67.01 seconds\n",
            "DIFM CPU Usage: 0.10%\n",
            "DIFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating FiBiNET...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.2337 - mse:  2.2321 - val_mse:  0.8545\n",
            "Epoch 2/50\n",
            "4s - loss:  0.8093 - mse:  0.8093 - val_mse:  0.7929\n",
            "Epoch 3/50\n",
            "3s - loss:  0.7619 - mse:  0.7620 - val_mse:  0.7857\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7434 - mse:  0.7435 - val_mse:  0.7866\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7296 - mse:  0.7296 - val_mse:  0.7856\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7138 - mse:  0.7137 - val_mse:  0.7885\n",
            "Epoch 7/50\n",
            "3s - loss:  0.6976 - mse:  0.6975 - val_mse:  0.7876\n",
            "Epoch 8/50\n",
            "4s - loss:  0.6807 - mse:  0.6808 - val_mse:  0.8119\n",
            "Epoch 9/50\n",
            "4s - loss:  0.6683 - mse:  0.6684 - val_mse:  0.8054\n",
            "Epoch 10/50\n",
            "4s - loss:  0.6521 - mse:  0.6521 - val_mse:  0.8033\n",
            "Epoch 00010: early stopping\n",
            "FiBiNET Model RMSE: 0.9002\n",
            "FiBiNET Model MAE: 0.7106\n",
            "FiBiNET Model NDCG@5: 0.9321\n",
            "FiBiNET Model NDCG@10: 0.9196\n",
            "FiBiNET Model Precision@5: 0.8584\n",
            "FiBiNET Model Precision@10: 0.7984\n",
            "FiBiNET Execution Time: 45.10 seconds\n",
            "FiBiNET CPU Usage: 7.70%\n",
            "FiBiNET Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating NFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.2465 - mse:  2.2448 - val_mse:  0.8620\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8023 - mse:  0.8026 - val_mse:  0.8006\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7446 - mse:  0.7445 - val_mse:  0.7947\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7193 - mse:  0.7192 - val_mse:  0.7954\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7002 - mse:  0.7002 - val_mse:  0.8015\n",
            "Epoch 6/50\n",
            "2s - loss:  0.6857 - mse:  0.6856 - val_mse:  0.8039\n",
            "Epoch 7/50\n",
            "2s - loss:  0.6733 - mse:  0.6732 - val_mse:  0.8135\n",
            "Epoch 8/50\n",
            "3s - loss:  0.6635 - mse:  0.6635 - val_mse:  0.8128\n",
            "Epoch 00008: early stopping\n",
            "NFM Model RMSE: 0.9024\n",
            "NFM Model MAE: 0.7122\n",
            "NFM Model NDCG@5: 0.9333\n",
            "NFM Model NDCG@10: 0.9203\n",
            "NFM Model Precision@5: 0.8544\n",
            "NFM Model Precision@10: 0.8028\n",
            "NFM Execution Time: 25.01 seconds\n",
            "NFM CPU Usage: -8.00%\n",
            "NFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating ONN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.0520 - mse:  2.0493 - val_mse:  0.8214\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7714 - mse:  0.7702 - val_mse:  0.8114\n",
            "Epoch 3/50\n",
            "4s - loss:  0.6908 - mse:  0.6898 - val_mse:  0.8487\n",
            "Epoch 4/50\n",
            "4s - loss:  0.6399 - mse:  0.6388 - val_mse:  0.8866\n",
            "Epoch 5/50\n",
            "5s - loss:  0.6076 - mse:  0.6065 - val_mse:  0.9173\n",
            "Epoch 6/50\n",
            "4s - loss:  0.5849 - mse:  0.5837 - val_mse:  0.9427\n",
            "Epoch 7/50\n",
            "4s - loss:  0.5681 - mse:  0.5670 - val_mse:  0.9639\n",
            "Epoch 00007: early stopping\n",
            "ONN Model RMSE: 0.9865\n",
            "ONN Model MAE: 0.7771\n",
            "ONN Model NDCG@5: 0.9084\n",
            "ONN Model NDCG@10: 0.8964\n",
            "ONN Model Precision@5: 0.8016\n",
            "ONN Model Precision@10: 0.7576\n",
            "ONN Execution Time: 35.35 seconds\n",
            "ONN CPU Usage: 11.90%\n",
            "ONN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating PNN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.3597 - mse:  2.3581 - val_mse:  0.8184\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7892 - mse:  0.7893 - val_mse:  0.7925\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7636 - mse:  0.7637 - val_mse:  0.7949\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7489 - mse:  0.7487 - val_mse:  0.7815\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7314 - mse:  0.7313 - val_mse:  0.7796\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7154 - mse:  0.7152 - val_mse:  0.7845\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7016 - mse:  0.7016 - val_mse:  0.7904\n",
            "Epoch 8/50\n",
            "2s - loss:  0.6908 - mse:  0.6909 - val_mse:  0.7945\n",
            "Epoch 9/50\n",
            "2s - loss:  0.6780 - mse:  0.6779 - val_mse:  0.8024\n",
            "Epoch 10/50\n",
            "2s - loss:  0.6643 - mse:  0.6642 - val_mse:  0.8045\n",
            "Epoch 00010: early stopping\n",
            "PNN Model RMSE: 0.9011\n",
            "PNN Model MAE: 0.7101\n",
            "PNN Model NDCG@5: 0.9281\n",
            "PNN Model NDCG@10: 0.9163\n",
            "PNN Model Precision@5: 0.8512\n",
            "PNN Model Precision@10: 0.8040\n",
            "PNN Execution Time: 28.45 seconds\n",
            "PNN CPU Usage: -16.50%\n",
            "PNN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating WDL...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0332 - mse:  2.0318 - val_mse:  0.8103\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7874 - mse:  0.7874 - val_mse:  0.7943\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7667 - mse:  0.7667 - val_mse:  0.7919\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7614 - mse:  0.7615 - val_mse:  0.7892\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7580 - mse:  0.7580 - val_mse:  0.7920\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7557 - mse:  0.7558 - val_mse:  0.7902\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7550 - mse:  0.7550 - val_mse:  0.7915\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7530 - mse:  0.7531 - val_mse:  0.7930\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7532 - mse:  0.7532 - val_mse:  0.7930\n",
            "Epoch 00009: early stopping\n",
            "WDL Model RMSE: 0.8933\n",
            "WDL Model MAE: 0.7101\n",
            "WDL Model NDCG@5: 0.9336\n",
            "WDL Model NDCG@10: 0.9209\n",
            "WDL Model Precision@5: 0.8576\n",
            "WDL Model Precision@10: 0.8052\n",
            "WDL Execution Time: 28.38 seconds\n",
            "WDL CPU Usage: 5.50%\n",
            "WDL Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating xDeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "5s - loss:  1.7003 - mse:  1.6991 - val_mse:  0.7996\n",
            "Epoch 2/50\n",
            "5s - loss:  0.7833 - mse:  0.7833 - val_mse:  0.7923\n",
            "Epoch 3/50\n",
            "5s - loss:  0.7664 - mse:  0.7664 - val_mse:  0.7886\n",
            "Epoch 4/50\n",
            "5s - loss:  0.7606 - mse:  0.7606 - val_mse:  0.7912\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7572 - mse:  0.7572 - val_mse:  0.7901\n",
            "Epoch 6/50\n",
            "5s - loss:  0.7538 - mse:  0.7538 - val_mse:  0.7891\n",
            "Epoch 7/50\n",
            "6s - loss:  0.7508 - mse:  0.7508 - val_mse:  0.7914\n",
            "Epoch 8/50\n",
            "5s - loss:  0.7481 - mse:  0.7481 - val_mse:  0.7900\n",
            "Epoch 00008: early stopping\n",
            "xDeepFM Model RMSE: 0.8905\n",
            "xDeepFM Model MAE: 0.7054\n",
            "xDeepFM Model NDCG@5: 0.9309\n",
            "xDeepFM Model NDCG@10: 0.9200\n",
            "xDeepFM Model Precision@5: 0.8544\n",
            "xDeepFM Model Precision@10: 0.8036\n",
            "xDeepFM Execution Time: 46.91 seconds\n",
            "xDeepFM CPU Usage: 24.60%\n",
            "xDeepFM Memory Usage: 0.25 MB\n",
            "\n",
            "Training and evaluating IFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  7.1379 - mse:  7.1321 - val_mse:  1.9124\n",
            "Epoch 2/50\n",
            "2s - loss:  1.3230 - mse:  1.3229 - val_mse:  1.1183\n",
            "Epoch 3/50\n",
            "2s - loss:  1.0458 - mse:  1.0458 - val_mse:  0.8794\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8327 - mse:  0.8325 - val_mse:  0.8204\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7856 - mse:  0.7856 - val_mse:  0.8147\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7687 - mse:  0.7686 - val_mse:  0.8057\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7590 - mse:  0.7590 - val_mse:  0.7989\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7525 - mse:  0.7525 - val_mse:  0.7990\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7479 - mse:  0.7480 - val_mse:  0.8005\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7444 - mse:  0.7442 - val_mse:  0.7915\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7408 - mse:  0.7406 - val_mse:  0.7891\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7353 - mse:  0.7353 - val_mse:  0.7901\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7299 - mse:  0.7298 - val_mse:  0.7916\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7250 - mse:  0.7250 - val_mse:  0.7935\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7182 - mse:  0.7184 - val_mse:  0.7876\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7124 - mse:  0.7125 - val_mse:  0.7878\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7053 - mse:  0.7055 - val_mse:  0.7918\n",
            "Epoch 18/50\n",
            "3s - loss:  0.6999 - mse:  0.6999 - val_mse:  0.7857\n",
            "Epoch 19/50\n",
            "3s - loss:  0.6935 - mse:  0.6936 - val_mse:  0.7941\n",
            "Epoch 20/50\n",
            "3s - loss:  0.6895 - mse:  0.6894 - val_mse:  0.7932\n",
            "Epoch 21/50\n",
            "3s - loss:  0.6845 - mse:  0.6844 - val_mse:  0.7964\n",
            "Epoch 22/50\n",
            "2s - loss:  0.6795 - mse:  0.6795 - val_mse:  0.7886\n",
            "Epoch 23/50\n",
            "2s - loss:  0.6741 - mse:  0.6741 - val_mse:  0.7956\n",
            "Epoch 00023: early stopping\n",
            "IFM Model RMSE: 0.8942\n",
            "IFM Model MAE: 0.7062\n",
            "IFM Model NDCG@5: 0.9357\n",
            "IFM Model NDCG@10: 0.9231\n",
            "IFM Model Precision@5: 0.8560\n",
            "IFM Model Precision@10: 0.7992\n",
            "IFM Execution Time: 73.38 seconds\n",
            "IFM CPU Usage: 5.30%\n",
            "IFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating LS-PLM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  11.3735 - mse:  11.3706 - val_mse:  8.7599\n",
            "Epoch 2/50\n",
            "4s - loss:  6.4169 - mse:  6.4142 - val_mse:  4.3837\n",
            "Epoch 3/50\n",
            "4s - loss:  3.1326 - mse:  3.1318 - val_mse:  2.1869\n",
            "Epoch 4/50\n",
            "3s - loss:  1.7235 - mse:  1.7232 - val_mse:  1.3981\n",
            "Epoch 5/50\n",
            "4s - loss:  1.2657 - mse:  1.2655 - val_mse:  1.1698\n",
            "Epoch 6/50\n",
            "4s - loss:  1.1305 - mse:  1.1305 - val_mse:  1.0979\n",
            "Epoch 7/50\n",
            "3s - loss:  1.0749 - mse:  1.0751 - val_mse:  1.0598\n",
            "Epoch 8/50\n",
            "4s - loss:  1.0358 - mse:  1.0356 - val_mse:  1.0293\n",
            "Epoch 9/50\n",
            "4s - loss:  1.0011 - mse:  1.0011 - val_mse:  1.0014\n",
            "Epoch 10/50\n",
            "4s - loss:  0.9691 - mse:  0.9691 - val_mse:  0.9755\n",
            "Epoch 11/50\n",
            "4s - loss:  0.9394 - mse:  0.9394 - val_mse:  0.9512\n",
            "Epoch 12/50\n",
            "4s - loss:  0.9119 - mse:  0.9120 - val_mse:  0.9285\n",
            "Epoch 13/50\n",
            "3s - loss:  0.8867 - mse:  0.8865 - val_mse:  0.9076\n",
            "Epoch 14/50\n",
            "4s - loss:  0.8638 - mse:  0.8637 - val_mse:  0.8887\n",
            "Epoch 15/50\n",
            "4s - loss:  0.8434 - mse:  0.8434 - val_mse:  0.8720\n",
            "Epoch 16/50\n",
            "4s - loss:  0.8255 - mse:  0.8255 - val_mse:  0.8574\n",
            "Epoch 17/50\n",
            "4s - loss:  0.8099 - mse:  0.8100 - val_mse:  0.8450\n",
            "Epoch 18/50\n",
            "4s - loss:  0.7967 - mse:  0.7967 - val_mse:  0.8346\n",
            "Epoch 19/50\n",
            "4s - loss:  0.7858 - mse:  0.7859 - val_mse:  0.8261\n",
            "Epoch 20/50\n",
            "5s - loss:  0.7768 - mse:  0.7767 - val_mse:  0.8195\n",
            "Epoch 21/50\n",
            "4s - loss:  0.7696 - mse:  0.7695 - val_mse:  0.8143\n",
            "Epoch 22/50\n",
            "4s - loss:  0.7638 - mse:  0.7638 - val_mse:  0.8104\n",
            "Epoch 23/50\n",
            "4s - loss:  0.7592 - mse:  0.7591 - val_mse:  0.8075\n",
            "Epoch 24/50\n",
            "5s - loss:  0.7555 - mse:  0.7555 - val_mse:  0.8054\n",
            "Epoch 25/50\n",
            "4s - loss:  0.7527 - mse:  0.7526 - val_mse:  0.8039\n",
            "Epoch 26/50\n",
            "4s - loss:  0.7504 - mse:  0.7503 - val_mse:  0.8024\n",
            "Epoch 27/50\n",
            "4s - loss:  0.7486 - mse:  0.7484 - val_mse:  0.8018\n",
            "Epoch 28/50\n",
            "4s - loss:  0.7469 - mse:  0.7469 - val_mse:  0.8016\n",
            "Epoch 29/50\n",
            "4s - loss:  0.7458 - mse:  0.7458 - val_mse:  0.8009\n",
            "Epoch 30/50\n",
            "4s - loss:  0.7448 - mse:  0.7447 - val_mse:  0.8006\n",
            "Epoch 31/50\n",
            "4s - loss:  0.7438 - mse:  0.7437 - val_mse:  0.8003\n",
            "Epoch 32/50\n",
            "4s - loss:  0.7429 - mse:  0.7429 - val_mse:  0.8002\n",
            "Epoch 33/50\n",
            "4s - loss:  0.7421 - mse:  0.7422 - val_mse:  0.8001\n",
            "Epoch 34/50\n",
            "4s - loss:  0.7415 - mse:  0.7416 - val_mse:  0.7999\n",
            "Epoch 35/50\n",
            "5s - loss:  0.7410 - mse:  0.7410 - val_mse:  0.8000\n",
            "Epoch 36/50\n",
            "4s - loss:  0.7405 - mse:  0.7405 - val_mse:  0.8003\n",
            "Epoch 37/50\n",
            "4s - loss:  0.7398 - mse:  0.7400 - val_mse:  0.7998\n",
            "Epoch 38/50\n",
            "4s - loss:  0.7394 - mse:  0.7393 - val_mse:  0.7997\n",
            "Epoch 39/50\n",
            "4s - loss:  0.7389 - mse:  0.7389 - val_mse:  0.7997\n",
            "Epoch 40/50\n",
            "4s - loss:  0.7382 - mse:  0.7380 - val_mse:  0.7995\n",
            "Epoch 41/50\n",
            "4s - loss:  0.7375 - mse:  0.7375 - val_mse:  0.7990\n",
            "Epoch 42/50\n",
            "4s - loss:  0.7366 - mse:  0.7365 - val_mse:  0.7985\n",
            "Epoch 43/50\n",
            "4s - loss:  0.7354 - mse:  0.7354 - val_mse:  0.7979\n",
            "Epoch 44/50\n",
            "3s - loss:  0.7337 - mse:  0.7337 - val_mse:  0.7970\n",
            "Epoch 45/50\n",
            "4s - loss:  0.7319 - mse:  0.7319 - val_mse:  0.7962\n",
            "Epoch 46/50\n",
            "4s - loss:  0.7297 - mse:  0.7298 - val_mse:  0.7955\n",
            "Epoch 47/50\n",
            "4s - loss:  0.7274 - mse:  0.7275 - val_mse:  0.7950\n",
            "Epoch 48/50\n",
            "4s - loss:  0.7250 - mse:  0.7251 - val_mse:  0.7940\n",
            "Epoch 49/50\n",
            "4s - loss:  0.7227 - mse:  0.7229 - val_mse:  0.7937\n",
            "Epoch 50/50\n",
            "4s - loss:  0.7204 - mse:  0.7203 - val_mse:  0.7936\n",
            "LS-PLM Model RMSE: 0.8936\n",
            "LS-PLM Model MAE: 0.7060\n",
            "LS-PLM Model NDCG@5: 0.9321\n",
            "LS-PLM Model NDCG@10: 0.9210\n",
            "LS-PLM Model Precision@5: 0.8568\n",
            "LS-PLM Model Precision@10: 0.8036\n",
            "LS-PLM Execution Time: 225.46 seconds\n",
            "LS-PLM CPU Usage: 16.40%\n",
            "LS-PLM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating MHA...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "8s - loss:  4.5637 - mse:  4.5616 - val_mse:  1.3113\n",
            "Epoch 2/50\n",
            "8s - loss:  1.1042 - mse:  1.1042 - val_mse:  1.0158\n",
            "Epoch 3/50\n",
            "7s - loss:  0.9971 - mse:  0.9971 - val_mse:  0.9526\n",
            "Epoch 4/50\n",
            "7s - loss:  0.9340 - mse:  0.9340 - val_mse:  0.9051\n",
            "Epoch 5/50\n",
            "8s - loss:  0.8859 - mse:  0.8859 - val_mse:  0.8701\n",
            "Epoch 6/50\n",
            "8s - loss:  0.8498 - mse:  0.8497 - val_mse:  0.8446\n",
            "Epoch 7/50\n",
            "7s - loss:  0.8228 - mse:  0.8228 - val_mse:  0.8269\n",
            "Epoch 8/50\n",
            "7s - loss:  0.8029 - mse:  0.8028 - val_mse:  0.8142\n",
            "Epoch 9/50\n",
            "7s - loss:  0.7879 - mse:  0.7881 - val_mse:  0.8052\n",
            "Epoch 10/50\n",
            "7s - loss:  0.7769 - mse:  0.7770 - val_mse:  0.7991\n",
            "Epoch 11/50\n",
            "7s - loss:  0.7685 - mse:  0.7686 - val_mse:  0.7950\n",
            "Epoch 12/50\n",
            "7s - loss:  0.7622 - mse:  0.7621 - val_mse:  0.7923\n",
            "Epoch 13/50\n",
            "7s - loss:  0.7573 - mse:  0.7573 - val_mse:  0.7905\n",
            "Epoch 14/50\n",
            "7s - loss:  0.7534 - mse:  0.7533 - val_mse:  0.7891\n",
            "Epoch 15/50\n",
            "7s - loss:  0.7504 - mse:  0.7503 - val_mse:  0.7882\n",
            "Epoch 16/50\n",
            "7s - loss:  0.7480 - mse:  0.7481 - val_mse:  0.7879\n",
            "Epoch 17/50\n",
            "7s - loss:  0.7460 - mse:  0.7460 - val_mse:  0.7875\n",
            "Epoch 18/50\n",
            "7s - loss:  0.7441 - mse:  0.7441 - val_mse:  0.7874\n",
            "Epoch 19/50\n",
            "8s - loss:  0.7426 - mse:  0.7426 - val_mse:  0.7875\n",
            "Epoch 20/50\n",
            "7s - loss:  0.7415 - mse:  0.7414 - val_mse:  0.7879\n",
            "Epoch 21/50\n",
            "7s - loss:  0.7404 - mse:  0.7405 - val_mse:  0.7877\n",
            "Epoch 22/50\n",
            "7s - loss:  0.7392 - mse:  0.7392 - val_mse:  0.7880\n",
            "Epoch 23/50\n",
            "8s - loss:  0.7386 - mse:  0.7387 - val_mse:  0.7888\n",
            "Epoch 00023: early stopping\n",
            "MHA Model RMSE: 0.8895\n",
            "MHA Model MAE: 0.7038\n",
            "MHA Model NDCG@5: 0.9344\n",
            "MHA Model NDCG@10: 0.9222\n",
            "MHA Model Precision@5: 0.8584\n",
            "MHA Model Precision@10: 0.8040\n",
            "MHA Execution Time: 182.36 seconds\n",
            "MHA CPU Usage: -0.20%\n",
            "MHA Memory Usage: 0.00 MB\n",
            "\n",
            "Final Results:\n",
            "AFM - RMSE: 0.8948, MAE: 0.7105,  NDCG@5: 0.9307,  Precision@5: 0.8520, NDCG@10: 0.9182,  Precision@10: 0.7996,  Time: 54.27s,  CPU: -0.30%, Memory: 0.00MB\n",
            "AutoInt - RMSE: 0.8963, MAE: 0.7062,  NDCG@5: 0.9339,  Precision@5: 0.8512, NDCG@10: 0.9211,  Precision@10: 0.8048,  Time: 60.11s,  CPU: -4.00%, Memory: 0.00MB\n",
            "CCPM - RMSE: 0.9231, MAE: 0.7237,  NDCG@5: 0.9227,  Precision@5: 0.8360, NDCG@10: 0.9121,  Precision@10: 0.7900,  Time: 51.14s,  CPU: 0.10%, Memory: 0.00MB\n",
            "DCN - RMSE: 0.8925, MAE: 0.7054,  NDCG@5: 0.9283,  Precision@5: 0.8448, NDCG@10: 0.9178,  Precision@10: 0.7996,  Time: 75.64s,  CPU: 0.00%, Memory: 0.00MB\n",
            "DeepFM - RMSE: 0.8927, MAE: 0.7086,  NDCG@5: 0.9333,  Precision@5: 0.8544, NDCG@10: 0.9214,  Precision@10: 0.8048,  Time: 28.04s,  CPU: 27.40%, Memory: 0.00MB\n",
            "DIFM - RMSE: 0.9027, MAE: 0.7118,  NDCG@5: 0.9348,  Precision@5: 0.8576, NDCG@10: 0.9220,  Precision@10: 0.7992,  Time: 67.01s,  CPU: 0.10%, Memory: 0.00MB\n",
            "FiBiNET - RMSE: 0.9002, MAE: 0.7106,  NDCG@5: 0.9321,  Precision@5: 0.8584, NDCG@10: 0.9196,  Precision@10: 0.7984,  Time: 45.10s,  CPU: 7.70%, Memory: 0.00MB\n",
            "NFM - RMSE: 0.9024, MAE: 0.7122,  NDCG@5: 0.9333,  Precision@5: 0.8544, NDCG@10: 0.9203,  Precision@10: 0.8028,  Time: 25.01s,  CPU: -8.00%, Memory: 0.00MB\n",
            "ONN - RMSE: 0.9865, MAE: 0.7771,  NDCG@5: 0.9084,  Precision@5: 0.8016, NDCG@10: 0.8964,  Precision@10: 0.7576,  Time: 35.35s,  CPU: 11.90%, Memory: 0.00MB\n",
            "PNN - RMSE: 0.9011, MAE: 0.7101,  NDCG@5: 0.9281,  Precision@5: 0.8512, NDCG@10: 0.9163,  Precision@10: 0.8040,  Time: 28.45s,  CPU: -16.50%, Memory: 0.00MB\n",
            "WDL - RMSE: 0.8933, MAE: 0.7101,  NDCG@5: 0.9336,  Precision@5: 0.8576, NDCG@10: 0.9209,  Precision@10: 0.8052,  Time: 28.38s,  CPU: 5.50%, Memory: 0.00MB\n",
            "xDeepFM - RMSE: 0.8905, MAE: 0.7054,  NDCG@5: 0.9309,  Precision@5: 0.8544, NDCG@10: 0.9200,  Precision@10: 0.8036,  Time: 46.91s,  CPU: 24.60%, Memory: 0.25MB\n",
            "IFM - RMSE: 0.8942, MAE: 0.7062,  NDCG@5: 0.9357,  Precision@5: 0.8560, NDCG@10: 0.9231,  Precision@10: 0.7992,  Time: 73.38s,  CPU: 5.30%, Memory: 0.00MB\n",
            "LS-PLM - RMSE: 0.8936, MAE: 0.7060,  NDCG@5: 0.9321,  Precision@5: 0.8568, NDCG@10: 0.9210,  Precision@10: 0.8036,  Time: 225.46s,  CPU: 16.40%, Memory: 0.00MB\n",
            "MHA - RMSE: 0.8895, MAE: 0.7038,  NDCG@5: 0.9344,  Precision@5: 0.8584, NDCG@10: 0.9222,  Precision@10: 0.8040,  Time: 182.36s,  CPU: -0.20%, Memory: 0.00MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRS: Running Model Training without all context and criteria**"
      ],
      "metadata": {
        "id": "yGZowkPzCMiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "case = 2\n",
        "  # Decision based on case value\n",
        "sparse_features = [\n",
        "          'UserID',            # unique user\n",
        "          'GroupID',           # assigned via KMeans\n",
        "          'MovieID',           # unique movie\n",
        "          'Title',             # optional (high-cardinality), usually omit or hash\n",
        "          'UserOccupation',    # categorical occupation\n",
        "      ]\n",
        "dense_features = [\n",
        "          'UserAge',           # continuous age\n",
        "      ]\n",
        "run(dense_features, sparse_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUiHYnNUCPqX",
        "outputId": "6e927a06-e6f5-405a-8b27-74119058a049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_rating:     UserID  GroupID  MovieID                    Title                  Genres  \\\n",
            "0     196       21      242             Kolya (1996)                  Comedy   \n",
            "1     196       21      393    Mrs. Doubtfire (1993)                  Comedy   \n",
            "2     196       21      381  Muriel's Wedding (1994)          Comedy|Romance   \n",
            "3     196       21      251   Shall We Dance? (1996)                  Comedy   \n",
            "4     196       21      655       Stand by Me (1986)  Adventure|Comedy|Drama   \n",
            "\n",
            "   UserAge  UserOccupation  TimeOfDay  DayType  Season  Storyline   Visuals  \\\n",
            "0       49              20  Afternoon  Weekday  Winter   4.986857  5.000000   \n",
            "1       49              20  Afternoon  Weekday  Winter   3.446943  1.000000   \n",
            "2       49              20  Afternoon  Weekday  Winter   5.000000  5.000000   \n",
            "3       49              20  Afternoon  Weekday  Winter   5.000000  1.000000   \n",
            "4       49              20  Afternoon  Weekday  Winter   4.063386  3.690389   \n",
            "\n",
            "    Emotion  OverallRating  \n",
            "0  5.000000              3  \n",
            "1  3.623087              4  \n",
            "2  1.000000              4  \n",
            "3  1.000000              3  \n",
            "4  3.629397              5  \n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "sparse_features ['UserID', 'GroupID', 'MovieID', 'Title', 'UserOccupation']\n",
            "feat:  UserID\n",
            "feat:  GroupID\n",
            "feat:  MovieID\n",
            "feat:  Title\n",
            "feat:  UserOccupation\n",
            "feature columns:  [SparseFeat(name='UserID', vocabulary_size=943, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserID', group_name='default_group'), SparseFeat(name='GroupID', vocabulary_size=250, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='GroupID', group_name='default_group'), SparseFeat(name='MovieID', vocabulary_size=1682, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='MovieID', group_name='default_group'), SparseFeat(name='Title', vocabulary_size=1664, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Title', group_name='default_group'), SparseFeat(name='UserOccupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserOccupation', group_name='default_group'), DenseFeat(name='UserAge', dimension=1, dtype='float32')]\n",
            "\n",
            "Training and evaluating AFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  10.5241 - mse:  10.5200 - val_mse:  7.4969\n",
            "Epoch 2/50\n",
            "2s - loss:  3.4858 - mse:  3.4834 - val_mse:  1.2881\n",
            "Epoch 3/50\n",
            "2s - loss:  1.1916 - mse:  1.1916 - val_mse:  1.1054\n",
            "Epoch 4/50\n",
            "2s - loss:  1.0759 - mse:  1.0757 - val_mse:  1.0429\n",
            "Epoch 5/50\n",
            "2s - loss:  1.0189 - mse:  1.0186 - val_mse:  1.0049\n",
            "Epoch 6/50\n",
            "2s - loss:  0.9795 - mse:  0.9794 - val_mse:  0.9760\n",
            "Epoch 7/50\n",
            "2s - loss:  0.9487 - mse:  0.9488 - val_mse:  0.9550\n",
            "Epoch 8/50\n",
            "2s - loss:  0.9251 - mse:  0.9249 - val_mse:  0.9390\n",
            "Epoch 9/50\n",
            "2s - loss:  0.9057 - mse:  0.9057 - val_mse:  0.9271\n",
            "Epoch 10/50\n",
            "2s - loss:  0.8904 - mse:  0.8901 - val_mse:  0.9177\n",
            "Epoch 11/50\n",
            "2s - loss:  0.8776 - mse:  0.8774 - val_mse:  0.9106\n",
            "Epoch 12/50\n",
            "2s - loss:  0.8669 - mse:  0.8669 - val_mse:  0.9056\n",
            "Epoch 13/50\n",
            "2s - loss:  0.8581 - mse:  0.8581 - val_mse:  0.9024\n",
            "Epoch 14/50\n",
            "2s - loss:  0.8506 - mse:  0.8506 - val_mse:  0.8994\n",
            "Epoch 15/50\n",
            "2s - loss:  0.8441 - mse:  0.8441 - val_mse:  0.8971\n",
            "Epoch 16/50\n",
            "2s - loss:  0.8387 - mse:  0.8387 - val_mse:  0.8958\n",
            "Epoch 17/50\n",
            "2s - loss:  0.8330 - mse:  0.8329 - val_mse:  0.8952\n",
            "Epoch 18/50\n",
            "2s - loss:  0.8283 - mse:  0.8284 - val_mse:  0.8948\n",
            "Epoch 19/50\n",
            "2s - loss:  0.8237 - mse:  0.8237 - val_mse:  0.8945\n",
            "Epoch 20/50\n",
            "2s - loss:  0.8191 - mse:  0.8192 - val_mse:  0.8953\n",
            "Epoch 21/50\n",
            "2s - loss:  0.8146 - mse:  0.8146 - val_mse:  0.8960\n",
            "Epoch 22/50\n",
            "2s - loss:  0.8101 - mse:  0.8100 - val_mse:  0.8972\n",
            "Epoch 23/50\n",
            "2s - loss:  0.8056 - mse:  0.8054 - val_mse:  0.8985\n",
            "Epoch 24/50\n",
            "2s - loss:  0.8016 - mse:  0.8016 - val_mse:  0.9002\n",
            "Epoch 00024: early stopping\n",
            "AFM Model RMSE: 0.9485\n",
            "AFM Model MAE: 0.7500\n",
            "AFM Model NDCG@5: 0.9097\n",
            "AFM Model NDCG@10: 0.8953\n",
            "AFM Model Precision@5: 0.8128\n",
            "AFM Model Precision@10: 0.7588\n",
            "AFM Execution Time: 62.76 seconds\n",
            "AFM CPU Usage: 4.10%\n",
            "AFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating AutoInt...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.3260 - mse:  2.3243 - val_mse:  0.9152\n",
            "Epoch 2/50\n",
            "4s - loss:  0.8887 - mse:  0.8888 - val_mse:  0.8949\n",
            "Epoch 3/50\n",
            "4s - loss:  0.8668 - mse:  0.8669 - val_mse:  0.8943\n",
            "Epoch 4/50\n",
            "4s - loss:  0.8597 - mse:  0.8597 - val_mse:  0.8942\n",
            "Epoch 5/50\n",
            "4s - loss:  0.8564 - mse:  0.8563 - val_mse:  0.8973\n",
            "Epoch 6/50\n",
            "4s - loss:  0.8550 - mse:  0.8551 - val_mse:  0.8927\n",
            "Epoch 7/50\n",
            "4s - loss:  0.8531 - mse:  0.8530 - val_mse:  0.8937\n",
            "Epoch 8/50\n",
            "4s - loss:  0.8512 - mse:  0.8513 - val_mse:  0.8949\n",
            "Epoch 9/50\n",
            "4s - loss:  0.8496 - mse:  0.8496 - val_mse:  0.8946\n",
            "Epoch 10/50\n",
            "4s - loss:  0.8488 - mse:  0.8488 - val_mse:  0.8956\n",
            "Epoch 11/50\n",
            "4s - loss:  0.8481 - mse:  0.8482 - val_mse:  0.8953\n",
            "Epoch 00011: early stopping\n",
            "AutoInt Model RMSE: 0.9467\n",
            "AutoInt Model MAE: 0.7519\n",
            "AutoInt Model NDCG@5: 0.9167\n",
            "AutoInt Model NDCG@10: 0.8989\n",
            "AutoInt Model Precision@5: 0.8120\n",
            "AutoInt Model Precision@10: 0.7600\n",
            "AutoInt Execution Time: 51.49 seconds\n",
            "AutoInt CPU Usage: 0.10%\n",
            "AutoInt Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating CCPM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.1460 - mse:  2.1446 - val_mse:  1.0544\n",
            "Epoch 2/50\n",
            "3s - loss:  0.9582 - mse:  0.9580 - val_mse:  0.9131\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8772 - mse:  0.8772 - val_mse:  0.8951\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8578 - mse:  0.8578 - val_mse:  0.8905\n",
            "Epoch 5/50\n",
            "3s - loss:  0.8468 - mse:  0.8468 - val_mse:  0.8907\n",
            "Epoch 6/50\n",
            "4s - loss:  0.8424 - mse:  0.8423 - val_mse:  0.8892\n",
            "Epoch 7/50\n",
            "3s - loss:  0.8395 - mse:  0.8395 - val_mse:  0.8891\n",
            "Epoch 8/50\n",
            "3s - loss:  0.8360 - mse:  0.8359 - val_mse:  0.8893\n",
            "Epoch 9/50\n",
            "3s - loss:  0.8325 - mse:  0.8325 - val_mse:  0.8948\n",
            "Epoch 10/50\n",
            "3s - loss:  0.8301 - mse:  0.8300 - val_mse:  0.8879\n",
            "Epoch 11/50\n",
            "3s - loss:  0.8249 - mse:  0.8247 - val_mse:  0.8882\n",
            "Epoch 12/50\n",
            "3s - loss:  0.8229 - mse:  0.8227 - val_mse:  0.8871\n",
            "Epoch 13/50\n",
            "3s - loss:  0.8167 - mse:  0.8167 - val_mse:  0.8895\n",
            "Epoch 14/50\n",
            "3s - loss:  0.8120 - mse:  0.8121 - val_mse:  0.8892\n",
            "Epoch 15/50\n",
            "3s - loss:  0.8072 - mse:  0.8072 - val_mse:  0.8882\n",
            "Epoch 16/50\n",
            "3s - loss:  0.8012 - mse:  0.8011 - val_mse:  0.8933\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7916 - mse:  0.7917 - val_mse:  0.9015\n",
            "Epoch 00017: early stopping\n",
            "CCPM Model RMSE: 0.9495\n",
            "CCPM Model MAE: 0.7432\n",
            "CCPM Model NDCG@5: 0.9106\n",
            "CCPM Model NDCG@10: 0.8953\n",
            "CCPM Model Precision@5: 0.8096\n",
            "CCPM Model Precision@10: 0.7648\n",
            "CCPM Execution Time: 63.33 seconds\n",
            "CCPM CPU Usage: -0.90%\n",
            "CCPM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DCN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.4398 - mse:  2.4384 - val_mse:  0.9197\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8900 - mse:  0.8899 - val_mse:  0.8947\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8671 - mse:  0.8670 - val_mse:  0.8936\n",
            "Epoch 4/50\n",
            "2s - loss:  0.8596 - mse:  0.8597 - val_mse:  0.8926\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8561 - mse:  0.8562 - val_mse:  0.8942\n",
            "Epoch 6/50\n",
            "2s - loss:  0.8528 - mse:  0.8530 - val_mse:  0.8948\n",
            "Epoch 7/50\n",
            "3s - loss:  0.8515 - mse:  0.8515 - val_mse:  0.8963\n",
            "Epoch 8/50\n",
            "3s - loss:  0.8514 - mse:  0.8512 - val_mse:  0.8926\n",
            "Epoch 9/50\n",
            "2s - loss:  0.8508 - mse:  0.8509 - val_mse:  0.8956\n",
            "Epoch 00009: early stopping\n",
            "DCN Model RMSE: 0.9466\n",
            "DCN Model MAE: 0.7475\n",
            "DCN Model NDCG@5: 0.9136\n",
            "DCN Model NDCG@10: 0.8980\n",
            "DCN Model Precision@5: 0.8112\n",
            "DCN Model Precision@10: 0.7576\n",
            "DCN Execution Time: 30.22 seconds\n",
            "DCN CPU Usage: -0.20%\n",
            "DCN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.5624 - mse:  2.5606 - val_mse:  0.9160\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8912 - mse:  0.8911 - val_mse:  0.8977\n",
            "Epoch 3/50\n",
            "2s - loss:  0.8681 - mse:  0.8681 - val_mse:  0.8942\n",
            "Epoch 4/50\n",
            "2s - loss:  0.8612 - mse:  0.8612 - val_mse:  0.8976\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8578 - mse:  0.8579 - val_mse:  0.8928\n",
            "Epoch 6/50\n",
            "2s - loss:  0.8561 - mse:  0.8562 - val_mse:  0.9039\n",
            "Epoch 7/50\n",
            "3s - loss:  0.8547 - mse:  0.8547 - val_mse:  0.8949\n",
            "Epoch 8/50\n",
            "2s - loss:  0.8514 - mse:  0.8516 - val_mse:  0.8939\n",
            "Epoch 9/50\n",
            "2s - loss:  0.8501 - mse:  0.8501 - val_mse:  0.8952\n",
            "Epoch 10/50\n",
            "2s - loss:  0.8487 - mse:  0.8490 - val_mse:  0.8945\n",
            "Epoch 00010: early stopping\n",
            "DeepFM Model RMSE: 0.9459\n",
            "DeepFM Model MAE: 0.7474\n",
            "DeepFM Model NDCG@5: 0.9145\n",
            "DeepFM Model NDCG@10: 0.9000\n",
            "DeepFM Model Precision@5: 0.8104\n",
            "DeepFM Model Precision@10: 0.7580\n",
            "DeepFM Execution Time: 30.44 seconds\n",
            "DeepFM CPU Usage: -0.30%\n",
            "DeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DIFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  3.8110 - mse:  3.8077 - val_mse:  0.9609\n",
            "Epoch 2/50\n",
            "3s - loss:  0.9216 - mse:  0.9215 - val_mse:  0.9281\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8938 - mse:  0.8937 - val_mse:  0.9256\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8769 - mse:  0.8769 - val_mse:  0.9199\n",
            "Epoch 5/50\n",
            "4s - loss:  0.8611 - mse:  0.8610 - val_mse:  0.9202\n",
            "Epoch 6/50\n",
            "3s - loss:  0.8493 - mse:  0.8493 - val_mse:  0.9150\n",
            "Epoch 7/50\n",
            "3s - loss:  0.8388 - mse:  0.8388 - val_mse:  0.9148\n",
            "Epoch 8/50\n",
            "3s - loss:  0.8278 - mse:  0.8279 - val_mse:  0.9233\n",
            "Epoch 9/50\n",
            "3s - loss:  0.8209 - mse:  0.8208 - val_mse:  0.9176\n",
            "Epoch 10/50\n",
            "3s - loss:  0.8089 - mse:  0.8090 - val_mse:  0.9215\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7952 - mse:  0.7953 - val_mse:  0.9270\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7797 - mse:  0.7797 - val_mse:  0.9306\n",
            "Epoch 00012: early stopping\n",
            "DIFM Model RMSE: 0.9617\n",
            "DIFM Model MAE: 0.7526\n",
            "DIFM Model NDCG@5: 0.9081\n",
            "DIFM Model NDCG@10: 0.8933\n",
            "DIFM Model Precision@5: 0.8072\n",
            "DIFM Model Precision@10: 0.7584\n",
            "DIFM Execution Time: 46.42 seconds\n",
            "DIFM CPU Usage: 13.80%\n",
            "DIFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating FiBiNET...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.5365 - mse:  2.5347 - val_mse:  0.9412\n",
            "Epoch 2/50\n",
            "4s - loss:  0.9013 - mse:  0.9014 - val_mse:  0.8989\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8657 - mse:  0.8658 - val_mse:  0.8901\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8535 - mse:  0.8536 - val_mse:  0.8854\n",
            "Epoch 5/50\n",
            "3s - loss:  0.8436 - mse:  0.8434 - val_mse:  0.8863\n",
            "Epoch 6/50\n",
            "4s - loss:  0.8315 - mse:  0.8315 - val_mse:  0.8847\n",
            "Epoch 7/50\n",
            "3s - loss:  0.8174 - mse:  0.8176 - val_mse:  0.8841\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7989 - mse:  0.7991 - val_mse:  0.8893\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7802 - mse:  0.7804 - val_mse:  0.8898\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7617 - mse:  0.7616 - val_mse:  0.9069\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7446 - mse:  0.7446 - val_mse:  0.9000\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7300 - mse:  0.7300 - val_mse:  0.9022\n",
            "Epoch 00012: early stopping\n",
            "FiBiNET Model RMSE: 0.9451\n",
            "FiBiNET Model MAE: 0.7448\n",
            "FiBiNET Model NDCG@5: 0.9147\n",
            "FiBiNET Model NDCG@10: 0.9006\n",
            "FiBiNET Model Precision@5: 0.8240\n",
            "FiBiNET Model Precision@10: 0.7672\n",
            "FiBiNET Execution Time: 48.98 seconds\n",
            "FiBiNET CPU Usage: 3.70%\n",
            "FiBiNET Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating NFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0810 - mse:  2.0799 - val_mse:  0.9720\n",
            "Epoch 2/50\n",
            "2s - loss:  0.9097 - mse:  0.9096 - val_mse:  0.9105\n",
            "Epoch 3/50\n",
            "2s - loss:  0.8502 - mse:  0.8502 - val_mse:  0.9049\n",
            "Epoch 4/50\n",
            "2s - loss:  0.8245 - mse:  0.8246 - val_mse:  0.9007\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8044 - mse:  0.8044 - val_mse:  0.9040\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7879 - mse:  0.7878 - val_mse:  0.9054\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7753 - mse:  0.7752 - val_mse:  0.9105\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7622 - mse:  0.7623 - val_mse:  0.9082\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7505 - mse:  0.7506 - val_mse:  0.9138\n",
            "Epoch 00009: early stopping\n",
            "NFM Model RMSE: 0.9534\n",
            "NFM Model MAE: 0.7494\n",
            "NFM Model NDCG@5: 0.9142\n",
            "NFM Model NDCG@10: 0.8986\n",
            "NFM Model Precision@5: 0.8064\n",
            "NFM Model Precision@10: 0.7600\n",
            "NFM Execution Time: 26.18 seconds\n",
            "NFM CPU Usage: -6.40%\n",
            "NFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating ONN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.5532 - mse:  2.5500 - val_mse:  0.9309\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8715 - mse:  0.8701 - val_mse:  0.9176\n",
            "Epoch 3/50\n",
            "3s - loss:  0.7783 - mse:  0.7771 - val_mse:  0.9652\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7174 - mse:  0.7162 - val_mse:  1.0061\n",
            "Epoch 5/50\n",
            "3s - loss:  0.6802 - mse:  0.6790 - val_mse:  1.0387\n",
            "Epoch 6/50\n",
            "4s - loss:  0.6537 - mse:  0.6527 - val_mse:  1.0696\n",
            "Epoch 7/50\n",
            "4s - loss:  0.6358 - mse:  0.6347 - val_mse:  1.0929\n",
            "Epoch 00007: early stopping\n",
            "ONN Model RMSE: 1.0442\n",
            "ONN Model MAE: 0.8241\n",
            "ONN Model NDCG@5: 0.8868\n",
            "ONN Model NDCG@10: 0.8697\n",
            "ONN Model Precision@5: 0.7496\n",
            "ONN Model Precision@10: 0.7168\n",
            "ONN Execution Time: 30.89 seconds\n",
            "ONN CPU Usage: -0.20%\n",
            "ONN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating PNN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.5262 - mse:  2.5245 - val_mse:  0.9173\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8908 - mse:  0.8907 - val_mse:  0.8942\n",
            "Epoch 3/50\n",
            "2s - loss:  0.8655 - mse:  0.8656 - val_mse:  0.8961\n",
            "Epoch 4/50\n",
            "1s - loss:  0.8553 - mse:  0.8554 - val_mse:  0.8880\n",
            "Epoch 5/50\n",
            "1s - loss:  0.8441 - mse:  0.8442 - val_mse:  0.8859\n",
            "Epoch 6/50\n",
            "1s - loss:  0.8329 - mse:  0.8329 - val_mse:  0.8955\n",
            "Epoch 7/50\n",
            "2s - loss:  0.8219 - mse:  0.8218 - val_mse:  0.8882\n",
            "Epoch 8/50\n",
            "2s - loss:  0.8120 - mse:  0.8120 - val_mse:  0.9002\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7998 - mse:  0.7998 - val_mse:  0.9027\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7873 - mse:  0.7873 - val_mse:  0.9152\n",
            "Epoch 00010: early stopping\n",
            "PNN Model RMSE: 0.9587\n",
            "PNN Model MAE: 0.7488\n",
            "PNN Model NDCG@5: 0.9116\n",
            "PNN Model NDCG@10: 0.8951\n",
            "PNN Model Precision@5: 0.8112\n",
            "PNN Model Precision@10: 0.7568\n",
            "PNN Execution Time: 25.03 seconds\n",
            "PNN CPU Usage: -0.30%\n",
            "PNN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating WDL...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.5526 - mse:  2.5508 - val_mse:  0.9190\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8918 - mse:  0.8917 - val_mse:  0.8973\n",
            "Epoch 3/50\n",
            "2s - loss:  0.8671 - mse:  0.8671 - val_mse:  0.8935\n",
            "Epoch 4/50\n",
            "2s - loss:  0.8601 - mse:  0.8602 - val_mse:  0.8971\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8568 - mse:  0.8569 - val_mse:  0.8923\n",
            "Epoch 6/50\n",
            "2s - loss:  0.8555 - mse:  0.8556 - val_mse:  0.9049\n",
            "Epoch 7/50\n",
            "2s - loss:  0.8543 - mse:  0.8543 - val_mse:  0.8947\n",
            "Epoch 8/50\n",
            "2s - loss:  0.8513 - mse:  0.8515 - val_mse:  0.8941\n",
            "Epoch 9/50\n",
            "2s - loss:  0.8504 - mse:  0.8504 - val_mse:  0.8954\n",
            "Epoch 10/50\n",
            "2s - loss:  0.8494 - mse:  0.8497 - val_mse:  0.8949\n",
            "Epoch 00010: early stopping\n",
            "WDL Model RMSE: 0.9462\n",
            "WDL Model MAE: 0.7479\n",
            "WDL Model NDCG@5: 0.9156\n",
            "WDL Model NDCG@10: 0.9007\n",
            "WDL Model Precision@5: 0.8120\n",
            "WDL Model Precision@10: 0.7568\n",
            "WDL Execution Time: 27.59 seconds\n",
            "WDL CPU Usage: 7.00%\n",
            "WDL Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating xDeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.1676 - mse:  2.1661 - val_mse:  0.9146\n",
            "Epoch 2/50\n",
            "4s - loss:  0.8865 - mse:  0.8865 - val_mse:  0.8962\n",
            "Epoch 3/50\n",
            "4s - loss:  0.8669 - mse:  0.8670 - val_mse:  0.8914\n",
            "Epoch 4/50\n",
            "5s - loss:  0.8593 - mse:  0.8594 - val_mse:  0.8923\n",
            "Epoch 5/50\n",
            "4s - loss:  0.8548 - mse:  0.8548 - val_mse:  0.8914\n",
            "Epoch 6/50\n",
            "4s - loss:  0.8512 - mse:  0.8511 - val_mse:  0.8904\n",
            "Epoch 7/50\n",
            "4s - loss:  0.8476 - mse:  0.8477 - val_mse:  0.8928\n",
            "Epoch 8/50\n",
            "5s - loss:  0.8455 - mse:  0.8454 - val_mse:  0.8900\n",
            "Epoch 9/50\n",
            "4s - loss:  0.8443 - mse:  0.8443 - val_mse:  0.8908\n",
            "Epoch 10/50\n",
            "4s - loss:  0.8412 - mse:  0.8412 - val_mse:  0.9015\n",
            "Epoch 11/50\n",
            "5s - loss:  0.8367 - mse:  0.8367 - val_mse:  0.8863\n",
            "Epoch 12/50\n",
            "4s - loss:  0.8303 - mse:  0.8303 - val_mse:  0.8847\n",
            "Epoch 13/50\n",
            "4s - loss:  0.8279 - mse:  0.8280 - val_mse:  0.8850\n",
            "Epoch 14/50\n",
            "4s - loss:  0.8233 - mse:  0.8234 - val_mse:  0.8847\n",
            "Epoch 15/50\n",
            "4s - loss:  0.8200 - mse:  0.8198 - val_mse:  0.8820\n",
            "Epoch 16/50\n",
            "4s - loss:  0.8159 - mse:  0.8159 - val_mse:  0.8828\n",
            "Epoch 17/50\n",
            "5s - loss:  0.8125 - mse:  0.8125 - val_mse:  0.8878\n",
            "Epoch 18/50\n",
            "4s - loss:  0.8079 - mse:  0.8079 - val_mse:  0.8893\n",
            "Epoch 19/50\n",
            "4s - loss:  0.8030 - mse:  0.8028 - val_mse:  0.8838\n",
            "Epoch 20/50\n",
            "4s - loss:  0.7964 - mse:  0.7963 - val_mse:  0.8861\n",
            "Epoch 00020: early stopping\n",
            "xDeepFM Model RMSE: 0.9411\n",
            "xDeepFM Model MAE: 0.7392\n",
            "xDeepFM Model NDCG@5: 0.9149\n",
            "xDeepFM Model NDCG@10: 0.9025\n",
            "xDeepFM Model Precision@5: 0.8216\n",
            "xDeepFM Model Precision@10: 0.7672\n",
            "xDeepFM Execution Time: 97.59 seconds\n",
            "xDeepFM CPU Usage: -13.30%\n",
            "xDeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating IFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  7.7489 - mse:  7.7425 - val_mse:  2.4182\n",
            "Epoch 2/50\n",
            "2s - loss:  1.5759 - mse:  1.5756 - val_mse:  1.2823\n",
            "Epoch 3/50\n",
            "2s - loss:  1.2416 - mse:  1.2415 - val_mse:  1.1199\n",
            "Epoch 4/50\n",
            "2s - loss:  1.0032 - mse:  1.0032 - val_mse:  0.9596\n",
            "Epoch 5/50\n",
            "2s - loss:  0.9029 - mse:  0.9031 - val_mse:  0.9254\n",
            "Epoch 6/50\n",
            "3s - loss:  0.8734 - mse:  0.8735 - val_mse:  0.9165\n",
            "Epoch 7/50\n",
            "2s - loss:  0.8589 - mse:  0.8589 - val_mse:  0.9145\n",
            "Epoch 8/50\n",
            "2s - loss:  0.8454 - mse:  0.8457 - val_mse:  0.9103\n",
            "Epoch 9/50\n",
            "2s - loss:  0.8373 - mse:  0.8374 - val_mse:  0.9103\n",
            "Epoch 10/50\n",
            "2s - loss:  0.8320 - mse:  0.8322 - val_mse:  0.9104\n",
            "Epoch 11/50\n",
            "3s - loss:  0.8268 - mse:  0.8268 - val_mse:  0.9080\n",
            "Epoch 12/50\n",
            "2s - loss:  0.8229 - mse:  0.8229 - val_mse:  0.9045\n",
            "Epoch 13/50\n",
            "2s - loss:  0.8184 - mse:  0.8184 - val_mse:  0.9063\n",
            "Epoch 14/50\n",
            "2s - loss:  0.8126 - mse:  0.8127 - val_mse:  0.9082\n",
            "Epoch 15/50\n",
            "2s - loss:  0.8085 - mse:  0.8085 - val_mse:  0.8990\n",
            "Epoch 16/50\n",
            "2s - loss:  0.8039 - mse:  0.8039 - val_mse:  0.8994\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7979 - mse:  0.7978 - val_mse:  0.8980\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7924 - mse:  0.7924 - val_mse:  0.8989\n",
            "Epoch 19/50\n",
            "2s - loss:  0.7888 - mse:  0.7888 - val_mse:  0.8959\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7811 - mse:  0.7812 - val_mse:  0.8956\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7756 - mse:  0.7756 - val_mse:  0.8974\n",
            "Epoch 22/50\n",
            "2s - loss:  0.7723 - mse:  0.7725 - val_mse:  0.8983\n",
            "Epoch 23/50\n",
            "2s - loss:  0.7690 - mse:  0.7692 - val_mse:  0.8995\n",
            "Epoch 24/50\n",
            "2s - loss:  0.7628 - mse:  0.7628 - val_mse:  0.8957\n",
            "Epoch 25/50\n",
            "2s - loss:  0.7587 - mse:  0.7587 - val_mse:  0.8991\n",
            "Epoch 00025: early stopping\n",
            "IFM Model RMSE: 0.9429\n",
            "IFM Model MAE: 0.7456\n",
            "IFM Model NDCG@5: 0.9143\n",
            "IFM Model NDCG@10: 0.9014\n",
            "IFM Model Precision@5: 0.8352\n",
            "IFM Model Precision@10: 0.7680\n",
            "IFM Execution Time: 69.98 seconds\n",
            "IFM CPU Usage: 1.70%\n",
            "IFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating LS-PLM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  12.3570 - mse:  12.3556 - val_mse:  10.9580\n",
            "Epoch 2/50\n",
            "3s - loss:  9.6660 - mse:  9.6643 - val_mse:  8.3671\n",
            "Epoch 3/50\n",
            "3s - loss:  7.2357 - mse:  7.2344 - val_mse:  6.1315\n",
            "Epoch 4/50\n",
            "3s - loss:  5.2256 - mse:  5.2245 - val_mse:  4.3625\n",
            "Epoch 5/50\n",
            "3s - loss:  3.7034 - mse:  3.7028 - val_mse:  3.0848\n",
            "Epoch 6/50\n",
            "3s - loss:  2.6469 - mse:  2.6462 - val_mse:  2.2363\n",
            "Epoch 7/50\n",
            "3s - loss:  1.9711 - mse:  1.9709 - val_mse:  1.7161\n",
            "Epoch 8/50\n",
            "4s - loss:  1.5673 - mse:  1.5671 - val_mse:  1.4149\n",
            "Epoch 9/50\n",
            "4s - loss:  1.3355 - mse:  1.3354 - val_mse:  1.2453\n",
            "Epoch 10/50\n",
            "3s - loss:  1.2014 - mse:  1.2014 - val_mse:  1.1466\n",
            "Epoch 11/50\n",
            "3s - loss:  1.1192 - mse:  1.1192 - val_mse:  1.0857\n",
            "Epoch 12/50\n",
            "4s - loss:  1.0643 - mse:  1.0643 - val_mse:  1.0444\n",
            "Epoch 13/50\n",
            "3s - loss:  1.0245 - mse:  1.0246 - val_mse:  1.0146\n",
            "Epoch 14/50\n",
            "3s - loss:  0.9939 - mse:  0.9939 - val_mse:  0.9922\n",
            "Epoch 15/50\n",
            "3s - loss:  0.9696 - mse:  0.9698 - val_mse:  0.9747\n",
            "Epoch 16/50\n",
            "4s - loss:  0.9499 - mse:  0.9499 - val_mse:  0.9608\n",
            "Epoch 17/50\n",
            "4s - loss:  0.9337 - mse:  0.9337 - val_mse:  0.9497\n",
            "Epoch 18/50\n",
            "3s - loss:  0.9200 - mse:  0.9202 - val_mse:  0.9406\n",
            "Epoch 19/50\n",
            "4s - loss:  0.9086 - mse:  0.9086 - val_mse:  0.9331\n",
            "Epoch 20/50\n",
            "3s - loss:  0.8989 - mse:  0.8988 - val_mse:  0.9269\n",
            "Epoch 21/50\n",
            "3s - loss:  0.8906 - mse:  0.8906 - val_mse:  0.9219\n",
            "Epoch 22/50\n",
            "4s - loss:  0.8835 - mse:  0.8836 - val_mse:  0.9176\n",
            "Epoch 23/50\n",
            "5s - loss:  0.8772 - mse:  0.8773 - val_mse:  0.9141\n",
            "Epoch 24/50\n",
            "3s - loss:  0.8718 - mse:  0.8718 - val_mse:  0.9111\n",
            "Epoch 25/50\n",
            "3s - loss:  0.8672 - mse:  0.8674 - val_mse:  0.9085\n",
            "Epoch 26/50\n",
            "4s - loss:  0.8631 - mse:  0.8629 - val_mse:  0.9065\n",
            "Epoch 27/50\n",
            "3s - loss:  0.8595 - mse:  0.8594 - val_mse:  0.9047\n",
            "Epoch 28/50\n",
            "4s - loss:  0.8564 - mse:  0.8564 - val_mse:  0.9033\n",
            "Epoch 29/50\n",
            "3s - loss:  0.8535 - mse:  0.8535 - val_mse:  0.9021\n",
            "Epoch 30/50\n",
            "3s - loss:  0.8510 - mse:  0.8510 - val_mse:  0.9011\n",
            "Epoch 31/50\n",
            "4s - loss:  0.8488 - mse:  0.8487 - val_mse:  0.9003\n",
            "Epoch 32/50\n",
            "3s - loss:  0.8469 - mse:  0.8468 - val_mse:  0.8995\n",
            "Epoch 33/50\n",
            "3s - loss:  0.8451 - mse:  0.8449 - val_mse:  0.8990\n",
            "Epoch 34/50\n",
            "3s - loss:  0.8435 - mse:  0.8434 - val_mse:  0.8985\n",
            "Epoch 35/50\n",
            "4s - loss:  0.8421 - mse:  0.8420 - val_mse:  0.8980\n",
            "Epoch 36/50\n",
            "3s - loss:  0.8409 - mse:  0.8407 - val_mse:  0.8978\n",
            "Epoch 37/50\n",
            "3s - loss:  0.8396 - mse:  0.8395 - val_mse:  0.8975\n",
            "Epoch 38/50\n",
            "3s - loss:  0.8385 - mse:  0.8385 - val_mse:  0.8974\n",
            "Epoch 39/50\n",
            "3s - loss:  0.8373 - mse:  0.8374 - val_mse:  0.8971\n",
            "Epoch 40/50\n",
            "3s - loss:  0.8364 - mse:  0.8363 - val_mse:  0.8969\n",
            "Epoch 41/50\n",
            "4s - loss:  0.8354 - mse:  0.8354 - val_mse:  0.8969\n",
            "Epoch 42/50\n",
            "3s - loss:  0.8344 - mse:  0.8344 - val_mse:  0.8968\n",
            "Epoch 43/50\n",
            "3s - loss:  0.8331 - mse:  0.8333 - val_mse:  0.8965\n",
            "Epoch 44/50\n",
            "4s - loss:  0.8319 - mse:  0.8319 - val_mse:  0.8963\n",
            "Epoch 45/50\n",
            "3s - loss:  0.8305 - mse:  0.8305 - val_mse:  0.8962\n",
            "Epoch 46/50\n",
            "3s - loss:  0.8288 - mse:  0.8286 - val_mse:  0.8959\n",
            "Epoch 47/50\n",
            "3s - loss:  0.8269 - mse:  0.8269 - val_mse:  0.8956\n",
            "Epoch 48/50\n",
            "3s - loss:  0.8249 - mse:  0.8247 - val_mse:  0.8954\n",
            "Epoch 49/50\n",
            "3s - loss:  0.8227 - mse:  0.8228 - val_mse:  0.8951\n",
            "Epoch 50/50\n",
            "3s - loss:  0.8203 - mse:  0.8203 - val_mse:  0.8951\n",
            "LS-PLM Model RMSE: 0.9458\n",
            "LS-PLM Model MAE: 0.7487\n",
            "LS-PLM Model NDCG@5: 0.9165\n",
            "LS-PLM Model NDCG@10: 0.9012\n",
            "LS-PLM Model Precision@5: 0.8224\n",
            "LS-PLM Model Precision@10: 0.7716\n",
            "LS-PLM Execution Time: 199.49 seconds\n",
            "LS-PLM CPU Usage: 12.80%\n",
            "LS-PLM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating MHA...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "7s - loss:  6.9492 - mse:  6.9454 - val_mse:  2.5063\n",
            "Epoch 2/50\n",
            "6s - loss:  1.5015 - mse:  1.5014 - val_mse:  1.1452\n",
            "Epoch 3/50\n",
            "6s - loss:  1.1268 - mse:  1.1268 - val_mse:  1.0783\n",
            "Epoch 4/50\n",
            "6s - loss:  1.0641 - mse:  1.0642 - val_mse:  1.0311\n",
            "Epoch 5/50\n",
            "7s - loss:  1.0151 - mse:  1.0150 - val_mse:  0.9952\n",
            "Epoch 6/50\n",
            "6s - loss:  0.9771 - mse:  0.9770 - val_mse:  0.9684\n",
            "Epoch 7/50\n",
            "6s - loss:  0.9477 - mse:  0.9475 - val_mse:  0.9484\n",
            "Epoch 8/50\n",
            "6s - loss:  0.9249 - mse:  0.9249 - val_mse:  0.9338\n",
            "Epoch 9/50\n",
            "7s - loss:  0.9072 - mse:  0.9072 - val_mse:  0.9226\n",
            "Epoch 10/50\n",
            "6s - loss:  0.8932 - mse:  0.8931 - val_mse:  0.9144\n",
            "Epoch 11/50\n",
            "7s - loss:  0.8821 - mse:  0.8820 - val_mse:  0.9082\n",
            "Epoch 12/50\n",
            "6s - loss:  0.8730 - mse:  0.8732 - val_mse:  0.9034\n",
            "Epoch 13/50\n",
            "7s - loss:  0.8659 - mse:  0.8659 - val_mse:  0.9001\n",
            "Epoch 14/50\n",
            "6s - loss:  0.8599 - mse:  0.8600 - val_mse:  0.8971\n",
            "Epoch 15/50\n",
            "7s - loss:  0.8551 - mse:  0.8551 - val_mse:  0.8951\n",
            "Epoch 16/50\n",
            "6s - loss:  0.8510 - mse:  0.8513 - val_mse:  0.8937\n",
            "Epoch 17/50\n",
            "6s - loss:  0.8478 - mse:  0.8478 - val_mse:  0.8924\n",
            "Epoch 18/50\n",
            "6s - loss:  0.8449 - mse:  0.8449 - val_mse:  0.8916\n",
            "Epoch 19/50\n",
            "7s - loss:  0.8425 - mse:  0.8426 - val_mse:  0.8911\n",
            "Epoch 20/50\n",
            "6s - loss:  0.8404 - mse:  0.8404 - val_mse:  0.8915\n",
            "Epoch 21/50\n",
            "7s - loss:  0.8388 - mse:  0.8389 - val_mse:  0.8922\n",
            "Epoch 22/50\n",
            "6s - loss:  0.8371 - mse:  0.8371 - val_mse:  0.8905\n",
            "Epoch 23/50\n",
            "6s - loss:  0.8360 - mse:  0.8359 - val_mse:  0.8904\n",
            "Epoch 24/50\n",
            "6s - loss:  0.8349 - mse:  0.8350 - val_mse:  0.8907\n",
            "Epoch 25/50\n",
            "6s - loss:  0.8338 - mse:  0.8337 - val_mse:  0.8907\n",
            "Epoch 26/50\n",
            "6s - loss:  0.8331 - mse:  0.8330 - val_mse:  0.8919\n",
            "Epoch 27/50\n",
            "6s - loss:  0.8324 - mse:  0.8323 - val_mse:  0.8911\n",
            "Epoch 28/50\n",
            "7s - loss:  0.8317 - mse:  0.8317 - val_mse:  0.8912\n",
            "Epoch 00028: early stopping\n",
            "MHA Model RMSE: 0.9440\n",
            "MHA Model MAE: 0.7471\n",
            "MHA Model NDCG@5: 0.9143\n",
            "MHA Model NDCG@10: 0.9004\n",
            "MHA Model Precision@5: 0.8176\n",
            "MHA Model Precision@10: 0.7624\n",
            "MHA Execution Time: 197.88 seconds\n",
            "MHA CPU Usage: -13.70%\n",
            "MHA Memory Usage: 0.00 MB\n",
            "\n",
            "Final Results:\n",
            "AFM - RMSE: 0.9485, MAE: 0.7500,  NDCG@5: 0.9097,  Precision@5: 0.8128, NDCG@10: 0.8953,  Precision@10: 0.7588,  Time: 62.76s,  CPU: 4.10%, Memory: 0.00MB\n",
            "AutoInt - RMSE: 0.9467, MAE: 0.7519,  NDCG@5: 0.9167,  Precision@5: 0.8120, NDCG@10: 0.8989,  Precision@10: 0.7600,  Time: 51.49s,  CPU: 0.10%, Memory: 0.00MB\n",
            "CCPM - RMSE: 0.9495, MAE: 0.7432,  NDCG@5: 0.9106,  Precision@5: 0.8096, NDCG@10: 0.8953,  Precision@10: 0.7648,  Time: 63.33s,  CPU: -0.90%, Memory: 0.00MB\n",
            "DCN - RMSE: 0.9466, MAE: 0.7475,  NDCG@5: 0.9136,  Precision@5: 0.8112, NDCG@10: 0.8980,  Precision@10: 0.7576,  Time: 30.22s,  CPU: -0.20%, Memory: 0.00MB\n",
            "DeepFM - RMSE: 0.9459, MAE: 0.7474,  NDCG@5: 0.9145,  Precision@5: 0.8104, NDCG@10: 0.9000,  Precision@10: 0.7580,  Time: 30.44s,  CPU: -0.30%, Memory: 0.00MB\n",
            "DIFM - RMSE: 0.9617, MAE: 0.7526,  NDCG@5: 0.9081,  Precision@5: 0.8072, NDCG@10: 0.8933,  Precision@10: 0.7584,  Time: 46.42s,  CPU: 13.80%, Memory: 0.00MB\n",
            "FiBiNET - RMSE: 0.9451, MAE: 0.7448,  NDCG@5: 0.9147,  Precision@5: 0.8240, NDCG@10: 0.9006,  Precision@10: 0.7672,  Time: 48.98s,  CPU: 3.70%, Memory: 0.00MB\n",
            "NFM - RMSE: 0.9534, MAE: 0.7494,  NDCG@5: 0.9142,  Precision@5: 0.8064, NDCG@10: 0.8986,  Precision@10: 0.7600,  Time: 26.18s,  CPU: -6.40%, Memory: 0.00MB\n",
            "ONN - RMSE: 1.0442, MAE: 0.8241,  NDCG@5: 0.8868,  Precision@5: 0.7496, NDCG@10: 0.8697,  Precision@10: 0.7168,  Time: 30.89s,  CPU: -0.20%, Memory: 0.00MB\n",
            "PNN - RMSE: 0.9587, MAE: 0.7488,  NDCG@5: 0.9116,  Precision@5: 0.8112, NDCG@10: 0.8951,  Precision@10: 0.7568,  Time: 25.03s,  CPU: -0.30%, Memory: 0.00MB\n",
            "WDL - RMSE: 0.9462, MAE: 0.7479,  NDCG@5: 0.9156,  Precision@5: 0.8120, NDCG@10: 0.9007,  Precision@10: 0.7568,  Time: 27.59s,  CPU: 7.00%, Memory: 0.00MB\n",
            "xDeepFM - RMSE: 0.9411, MAE: 0.7392,  NDCG@5: 0.9149,  Precision@5: 0.8216, NDCG@10: 0.9025,  Precision@10: 0.7672,  Time: 97.59s,  CPU: -13.30%, Memory: 0.00MB\n",
            "IFM - RMSE: 0.9429, MAE: 0.7456,  NDCG@5: 0.9143,  Precision@5: 0.8352, NDCG@10: 0.9014,  Precision@10: 0.7680,  Time: 69.98s,  CPU: 1.70%, Memory: 0.00MB\n",
            "LS-PLM - RMSE: 0.9458, MAE: 0.7487,  NDCG@5: 0.9165,  Precision@5: 0.8224, NDCG@10: 0.9012,  Precision@10: 0.7716,  Time: 199.49s,  CPU: 12.80%, Memory: 0.00MB\n",
            "MHA - RMSE: 0.9440, MAE: 0.7471,  NDCG@5: 0.9143,  Precision@5: 0.8176, NDCG@10: 0.9004,  Precision@10: 0.7624,  Time: 197.88s,  CPU: -13.70%, Memory: 0.00MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MCGRS-SC-T: Running Prediction with criteria, with single context: TimeOfDay**"
      ],
      "metadata": {
        "id": "AsbcMXgzDH_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_features = [\n",
        "          'UserID',            # unique user\n",
        "          'GroupID',           # assigned via KMeans\n",
        "          'MovieID',           # unique movie\n",
        "          'Title',             # optional (high-cardinality), usually omit or hash\n",
        "          'UserOccupation',    # categorical occupation\n",
        "          'TimeOfDay'         # ['Morning', 'Afternoon', etc.]\n",
        "      ]\n",
        "dense_features = [\n",
        "          'UserAge',           # continuous age\n",
        "          'Storyline',         # simulated multi-criteria\n",
        "          'Visuals',           # simulated multi-criteria\n",
        "          'Emotion'           # simulated multi-criteria\n",
        "      ]\n",
        "run(dense_features, sparse_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYSfZTihDMzU",
        "outputId": "905a24bc-62bf-476a-f41f-6a8e697b3722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_rating:     UserID  GroupID  MovieID                    Title                  Genres  \\\n",
            "0     196       21      242             Kolya (1996)                  Comedy   \n",
            "1     196       21      393    Mrs. Doubtfire (1993)                  Comedy   \n",
            "2     196       21      381  Muriel's Wedding (1994)          Comedy|Romance   \n",
            "3     196       21      251   Shall We Dance? (1996)                  Comedy   \n",
            "4     196       21      655       Stand by Me (1986)  Adventure|Comedy|Drama   \n",
            "\n",
            "   UserAge  UserOccupation  TimeOfDay  DayType  Season  Storyline   Visuals  \\\n",
            "0       49              20  Afternoon  Weekday  Winter   4.986857  5.000000   \n",
            "1       49              20  Afternoon  Weekday  Winter   3.446943  1.000000   \n",
            "2       49              20  Afternoon  Weekday  Winter   5.000000  5.000000   \n",
            "3       49              20  Afternoon  Weekday  Winter   5.000000  1.000000   \n",
            "4       49              20  Afternoon  Weekday  Winter   4.063386  3.690389   \n",
            "\n",
            "    Emotion  OverallRating  \n",
            "0  5.000000              3  \n",
            "1  3.623087              4  \n",
            "2  1.000000              4  \n",
            "3  1.000000              3  \n",
            "4  3.629397              5  \n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "sparse_features ['UserID', 'GroupID', 'MovieID', 'Title', 'UserOccupation', 'TimeOfDay']\n",
            "feat:  UserID\n",
            "feat:  GroupID\n",
            "feat:  MovieID\n",
            "feat:  Title\n",
            "feat:  UserOccupation\n",
            "feat:  TimeOfDay\n",
            "feature columns:  [SparseFeat(name='UserID', vocabulary_size=943, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserID', group_name='default_group'), SparseFeat(name='GroupID', vocabulary_size=250, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='GroupID', group_name='default_group'), SparseFeat(name='MovieID', vocabulary_size=1682, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='MovieID', group_name='default_group'), SparseFeat(name='Title', vocabulary_size=1664, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Title', group_name='default_group'), SparseFeat(name='UserOccupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserOccupation', group_name='default_group'), SparseFeat(name='TimeOfDay', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='TimeOfDay', group_name='default_group'), DenseFeat(name='UserAge', dimension=1, dtype='float32'), DenseFeat(name='Storyline', dimension=1, dtype='float32'), DenseFeat(name='Visuals', dimension=1, dtype='float32'), DenseFeat(name='Emotion', dimension=1, dtype='float32')]\n",
            "\n",
            "Training and evaluating AFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  8.9532 - mse:  8.9484 - val_mse:  4.6020\n",
            "Epoch 2/50\n",
            "3s - loss:  1.7772 - mse:  1.7764 - val_mse:  1.0252\n",
            "Epoch 3/50\n",
            "2s - loss:  1.0083 - mse:  1.0083 - val_mse:  0.9576\n",
            "Epoch 4/50\n",
            "2s - loss:  0.9442 - mse:  0.9441 - val_mse:  0.9110\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8950 - mse:  0.8949 - val_mse:  0.8746\n",
            "Epoch 6/50\n",
            "2s - loss:  0.8571 - mse:  0.8571 - val_mse:  0.8488\n",
            "Epoch 7/50\n",
            "2s - loss:  0.8279 - mse:  0.8278 - val_mse:  0.8296\n",
            "Epoch 8/50\n",
            "2s - loss:  0.8061 - mse:  0.8061 - val_mse:  0.8161\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7893 - mse:  0.7894 - val_mse:  0.8064\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7768 - mse:  0.7769 - val_mse:  0.7994\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7671 - mse:  0.7671 - val_mse:  0.7955\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7601 - mse:  0.7600 - val_mse:  0.7925\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7545 - mse:  0.7544 - val_mse:  0.7905\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7504 - mse:  0.7504 - val_mse:  0.7892\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7469 - mse:  0.7466 - val_mse:  0.7893\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7444 - mse:  0.7442 - val_mse:  0.7887\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7420 - mse:  0.7420 - val_mse:  0.7883\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7401 - mse:  0.7399 - val_mse:  0.7890\n",
            "Epoch 19/50\n",
            "2s - loss:  0.7385 - mse:  0.7385 - val_mse:  0.7884\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7371 - mse:  0.7370 - val_mse:  0.7890\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7358 - mse:  0.7358 - val_mse:  0.7897\n",
            "Epoch 22/50\n",
            "2s - loss:  0.7347 - mse:  0.7346 - val_mse:  0.7899\n",
            "Epoch 00022: early stopping\n",
            "AFM Model RMSE: 0.8907\n",
            "AFM Model MAE: 0.7071\n",
            "AFM Model NDCG@5: 0.9334\n",
            "AFM Model NDCG@10: 0.9216\n",
            "AFM Model Precision@5: 0.8608\n",
            "AFM Model Precision@10: 0.8052\n",
            "AFM Execution Time: 62.76 seconds\n",
            "AFM CPU Usage: 0.80%\n",
            "AFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating AutoInt...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.1170 - mse:  2.1155 - val_mse:  0.8135\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7872 - mse:  0.7872 - val_mse:  0.7930\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7671 - mse:  0.7672 - val_mse:  0.7926\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7611 - mse:  0.7612 - val_mse:  0.7932\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7597 - mse:  0.7598 - val_mse:  0.7902\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7559 - mse:  0.7559 - val_mse:  0.7942\n",
            "Epoch 7/50\n",
            "5s - loss:  0.7552 - mse:  0.7552 - val_mse:  0.7937\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7559 - mse:  0.7558 - val_mse:  0.7905\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7535 - mse:  0.7534 - val_mse:  0.7918\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7511 - mse:  0.7510 - val_mse:  0.8098\n",
            "Epoch 00010: early stopping\n",
            "AutoInt Model RMSE: 0.9038\n",
            "AutoInt Model MAE: 0.7237\n",
            "AutoInt Model NDCG@5: 0.9341\n",
            "AutoInt Model NDCG@10: 0.9217\n",
            "AutoInt Model Precision@5: 0.8592\n",
            "AutoInt Model Precision@10: 0.8032\n",
            "AutoInt Execution Time: 48.74 seconds\n",
            "AutoInt CPU Usage: 0.40%\n",
            "AutoInt Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating CCPM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.1739 - mse:  2.1727 - val_mse:  1.0738\n",
            "Epoch 2/50\n",
            "4s - loss:  0.9669 - mse:  0.9667 - val_mse:  0.8930\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8481 - mse:  0.8481 - val_mse:  0.8503\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7958 - mse:  0.7958 - val_mse:  0.8296\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7555 - mse:  0.7555 - val_mse:  0.8226\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7195 - mse:  0.7195 - val_mse:  0.8263\n",
            "Epoch 7/50\n",
            "3s - loss:  0.6922 - mse:  0.6922 - val_mse:  0.8149\n",
            "Epoch 8/50\n",
            "3s - loss:  0.6639 - mse:  0.6640 - val_mse:  0.8253\n",
            "Epoch 9/50\n",
            "3s - loss:  0.6377 - mse:  0.6377 - val_mse:  0.8425\n",
            "Epoch 10/50\n",
            "3s - loss:  0.6187 - mse:  0.6188 - val_mse:  0.8538\n",
            "Epoch 11/50\n",
            "3s - loss:  0.6036 - mse:  0.6035 - val_mse:  0.8622\n",
            "Epoch 12/50\n",
            "3s - loss:  0.5904 - mse:  0.5905 - val_mse:  0.8653\n",
            "Epoch 00012: early stopping\n",
            "CCPM Model RMSE: 0.9293\n",
            "CCPM Model MAE: 0.7355\n",
            "CCPM Model NDCG@5: 0.9269\n",
            "CCPM Model NDCG@10: 0.9143\n",
            "CCPM Model Precision@5: 0.8400\n",
            "CCPM Model Precision@10: 0.7780\n",
            "CCPM Execution Time: 48.54 seconds\n",
            "CCPM CPU Usage: -0.10%\n",
            "CCPM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DCN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  1.8857 - mse:  1.8844 - val_mse:  0.8116\n",
            "Epoch 2/50\n",
            "3s - loss:  0.7893 - mse:  0.7892 - val_mse:  0.7969\n",
            "Epoch 3/50\n",
            "3s - loss:  0.7684 - mse:  0.7685 - val_mse:  0.7921\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7623 - mse:  0.7621 - val_mse:  0.7904\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7589 - mse:  0.7588 - val_mse:  0.7939\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7557 - mse:  0.7558 - val_mse:  0.7938\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7537 - mse:  0.7536 - val_mse:  0.7960\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7522 - mse:  0.7523 - val_mse:  0.7899\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7515 - mse:  0.7516 - val_mse:  0.8006\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7503 - mse:  0.7506 - val_mse:  0.7899\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7496 - mse:  0.7497 - val_mse:  0.7906\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7489 - mse:  0.7489 - val_mse:  0.7910\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7458 - mse:  0.7458 - val_mse:  0.7910\n",
            "Epoch 00013: early stopping\n",
            "DCN Model RMSE: 0.8920\n",
            "DCN Model MAE: 0.7034\n",
            "DCN Model NDCG@5: 0.9361\n",
            "DCN Model NDCG@10: 0.9224\n",
            "DCN Model Precision@5: 0.8568\n",
            "DCN Model Precision@10: 0.8012\n",
            "DCN Execution Time: 44.84 seconds\n",
            "DCN CPU Usage: -0.20%\n",
            "DCN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0304 - mse:  2.0289 - val_mse:  0.8091\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7875 - mse:  0.7876 - val_mse:  0.7939\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7687 - mse:  0.7687 - val_mse:  0.7946\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7632 - mse:  0.7631 - val_mse:  0.7927\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7593 - mse:  0.7592 - val_mse:  0.7963\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7579 - mse:  0.7579 - val_mse:  0.7904\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7561 - mse:  0.7561 - val_mse:  0.7915\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7558 - mse:  0.7558 - val_mse:  0.7924\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7544 - mse:  0.7545 - val_mse:  0.7933\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7535 - mse:  0.7535 - val_mse:  0.7920\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7515 - mse:  0.7515 - val_mse:  0.7962\n",
            "Epoch 00011: early stopping\n",
            "DeepFM Model RMSE: 0.8943\n",
            "DeepFM Model MAE: 0.7043\n",
            "DeepFM Model NDCG@5: 0.9301\n",
            "DeepFM Model NDCG@10: 0.9206\n",
            "DeepFM Model Precision@5: 0.8584\n",
            "DeepFM Model Precision@10: 0.8008\n",
            "DeepFM Execution Time: 33.82 seconds\n",
            "DeepFM CPU Usage: 0.10%\n",
            "DeepFM Memory Usage: 1.29 MB\n",
            "\n",
            "Training and evaluating DIFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  3.3943 - mse:  3.3913 - val_mse:  0.9097\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8789 - mse:  0.8788 - val_mse:  0.8763\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8506 - mse:  0.8504 - val_mse:  0.8636\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8293 - mse:  0.8295 - val_mse:  0.8449\n",
            "Epoch 5/50\n",
            "4s - loss:  0.8122 - mse:  0.8122 - val_mse:  0.8393\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7960 - mse:  0.7960 - val_mse:  0.8207\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7844 - mse:  0.7843 - val_mse:  0.8118\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7748 - mse:  0.7748 - val_mse:  0.8086\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7688 - mse:  0.7688 - val_mse:  0.8045\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7618 - mse:  0.7617 - val_mse:  0.8013\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7601 - mse:  0.7602 - val_mse:  0.8041\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7536 - mse:  0.7535 - val_mse:  0.7935\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7512 - mse:  0.7513 - val_mse:  0.7926\n",
            "Epoch 14/50\n",
            "4s - loss:  0.7462 - mse:  0.7463 - val_mse:  0.7889\n",
            "Epoch 15/50\n",
            "3s - loss:  0.7403 - mse:  0.7402 - val_mse:  0.7935\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7316 - mse:  0.7317 - val_mse:  0.7897\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7203 - mse:  0.7204 - val_mse:  0.8028\n",
            "Epoch 18/50\n",
            "3s - loss:  0.7081 - mse:  0.7081 - val_mse:  0.7977\n",
            "Epoch 19/50\n",
            "3s - loss:  0.6919 - mse:  0.6919 - val_mse:  0.8052\n",
            "Epoch 00019: early stopping\n",
            "DIFM Model RMSE: 0.9001\n",
            "DIFM Model MAE: 0.7067\n",
            "DIFM Model NDCG@5: 0.9311\n",
            "DIFM Model NDCG@10: 0.9199\n",
            "DIFM Model Precision@5: 0.8568\n",
            "DIFM Model Precision@10: 0.8044\n",
            "DIFM Execution Time: 75.47 seconds\n",
            "DIFM CPU Usage: -0.40%\n",
            "DIFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating FiBiNET...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.1799 - mse:  2.1784 - val_mse:  0.8222\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7902 - mse:  0.7902 - val_mse:  0.7953\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7655 - mse:  0.7654 - val_mse:  0.7901\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7557 - mse:  0.7559 - val_mse:  0.7831\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7456 - mse:  0.7457 - val_mse:  0.7842\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7301 - mse:  0.7301 - val_mse:  0.7760\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7150 - mse:  0.7152 - val_mse:  0.7856\n",
            "Epoch 8/50\n",
            "5s - loss:  0.7028 - mse:  0.7028 - val_mse:  0.7860\n",
            "Epoch 9/50\n",
            "4s - loss:  0.6930 - mse:  0.6929 - val_mse:  0.7865\n",
            "Epoch 10/50\n",
            "4s - loss:  0.6819 - mse:  0.6818 - val_mse:  0.7983\n",
            "Epoch 11/50\n",
            "4s - loss:  0.6713 - mse:  0.6714 - val_mse:  0.7924\n",
            "Epoch 00011: early stopping\n",
            "FiBiNET Model RMSE: 0.8913\n",
            "FiBiNET Model MAE: 0.7015\n",
            "FiBiNET Model NDCG@5: 0.9330\n",
            "FiBiNET Model NDCG@10: 0.9209\n",
            "FiBiNET Model Precision@5: 0.8576\n",
            "FiBiNET Model Precision@10: 0.8052\n",
            "FiBiNET Execution Time: 53.77 seconds\n",
            "FiBiNET CPU Usage: -0.20%\n",
            "FiBiNET Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating NFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  1.9575 - mse:  1.9562 - val_mse:  0.8372\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8055 - mse:  0.8056 - val_mse:  0.8042\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7744 - mse:  0.7744 - val_mse:  0.7974\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7652 - mse:  0.7652 - val_mse:  0.7955\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7611 - mse:  0.7611 - val_mse:  0.7964\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7587 - mse:  0.7590 - val_mse:  0.7946\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7557 - mse:  0.7557 - val_mse:  0.7975\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7549 - mse:  0.7550 - val_mse:  0.7983\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7533 - mse:  0.7534 - val_mse:  0.7946\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7514 - mse:  0.7514 - val_mse:  0.8005\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7506 - mse:  0.7505 - val_mse:  0.7936\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7487 - mse:  0.7487 - val_mse:  0.7939\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7474 - mse:  0.7474 - val_mse:  0.7966\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7464 - mse:  0.7465 - val_mse:  0.7913\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7460 - mse:  0.7461 - val_mse:  0.7931\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7461 - mse:  0.7462 - val_mse:  0.7938\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7448 - mse:  0.7448 - val_mse:  0.7976\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7432 - mse:  0.7430 - val_mse:  0.7927\n",
            "Epoch 19/50\n",
            "3s - loss:  0.7409 - mse:  0.7409 - val_mse:  0.8004\n",
            "Epoch 00019: early stopping\n",
            "NFM Model RMSE: 0.8997\n",
            "NFM Model MAE: 0.7178\n",
            "NFM Model NDCG@5: 0.9319\n",
            "NFM Model NDCG@10: 0.9204\n",
            "NFM Model Precision@5: 0.8536\n",
            "NFM Model Precision@10: 0.8028\n",
            "NFM Execution Time: 55.48 seconds\n",
            "NFM CPU Usage: 0.00%\n",
            "NFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating ONN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "5s - loss:  2.0385 - mse:  2.0358 - val_mse:  0.8145\n",
            "Epoch 2/50\n",
            "5s - loss:  0.7546 - mse:  0.7534 - val_mse:  0.8310\n",
            "Epoch 3/50\n",
            "4s - loss:  0.6699 - mse:  0.6688 - val_mse:  0.8613\n",
            "Epoch 4/50\n",
            "4s - loss:  0.6129 - mse:  0.6116 - val_mse:  0.9065\n",
            "Epoch 5/50\n",
            "4s - loss:  0.5765 - mse:  0.5752 - val_mse:  0.9423\n",
            "Epoch 6/50\n",
            "4s - loss:  0.5526 - mse:  0.5514 - val_mse:  0.9675\n",
            "Epoch 00006: early stopping\n",
            "ONN Model RMSE: 0.9843\n",
            "ONN Model MAE: 0.7779\n",
            "ONN Model NDCG@5: 0.9150\n",
            "ONN Model NDCG@10: 0.8984\n",
            "ONN Model Precision@5: 0.8216\n",
            "ONN Model Precision@10: 0.7612\n",
            "ONN Execution Time: 33.35 seconds\n",
            "ONN CPU Usage: 2.30%\n",
            "ONN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating PNN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.1589 - mse:  2.1574 - val_mse:  0.8115\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7869 - mse:  0.7868 - val_mse:  0.7918\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7629 - mse:  0.7630 - val_mse:  0.7880\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7451 - mse:  0.7452 - val_mse:  0.7809\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7273 - mse:  0.7274 - val_mse:  0.7810\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7111 - mse:  0.7111 - val_mse:  0.7875\n",
            "Epoch 7/50\n",
            "2s - loss:  0.6948 - mse:  0.6948 - val_mse:  0.7987\n",
            "Epoch 8/50\n",
            "2s - loss:  0.6796 - mse:  0.6796 - val_mse:  0.8024\n",
            "Epoch 9/50\n",
            "2s - loss:  0.6664 - mse:  0.6664 - val_mse:  0.8114\n",
            "Epoch 00009: early stopping\n",
            "PNN Model RMSE: 0.9027\n",
            "PNN Model MAE: 0.7071\n",
            "PNN Model NDCG@5: 0.9283\n",
            "PNN Model NDCG@10: 0.9189\n",
            "PNN Model Precision@5: 0.8544\n",
            "PNN Model Precision@10: 0.8072\n",
            "PNN Execution Time: 23.77 seconds\n",
            "PNN CPU Usage: -13.80%\n",
            "PNN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating WDL...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0366 - mse:  2.0351 - val_mse:  0.8088\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7864 - mse:  0.7865 - val_mse:  0.7927\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7670 - mse:  0.7671 - val_mse:  0.7936\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7614 - mse:  0.7614 - val_mse:  0.7915\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7576 - mse:  0.7575 - val_mse:  0.7955\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7563 - mse:  0.7563 - val_mse:  0.7895\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7546 - mse:  0.7546 - val_mse:  0.7909\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7544 - mse:  0.7544 - val_mse:  0.7919\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7531 - mse:  0.7531 - val_mse:  0.7927\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7526 - mse:  0.7526 - val_mse:  0.7920\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7508 - mse:  0.7509 - val_mse:  0.7969\n",
            "Epoch 00011: early stopping\n",
            "WDL Model RMSE: 0.8945\n",
            "WDL Model MAE: 0.7042\n",
            "WDL Model NDCG@5: 0.9316\n",
            "WDL Model NDCG@10: 0.9212\n",
            "WDL Model Precision@5: 0.8600\n",
            "WDL Model Precision@10: 0.8016\n",
            "WDL Execution Time: 32.02 seconds\n",
            "WDL CPU Usage: -8.10%\n",
            "WDL Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating xDeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "5s - loss:  1.8061 - mse:  1.8048 - val_mse:  0.8047\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7846 - mse:  0.7846 - val_mse:  0.7911\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7672 - mse:  0.7673 - val_mse:  0.7917\n",
            "Epoch 4/50\n",
            "5s - loss:  0.7616 - mse:  0.7615 - val_mse:  0.7885\n",
            "Epoch 5/50\n",
            "5s - loss:  0.7563 - mse:  0.7563 - val_mse:  0.7890\n",
            "Epoch 6/50\n",
            "5s - loss:  0.7538 - mse:  0.7539 - val_mse:  0.7985\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7506 - mse:  0.7507 - val_mse:  0.7901\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7479 - mse:  0.7480 - val_mse:  0.7956\n",
            "Epoch 9/50\n",
            "5s - loss:  0.7428 - mse:  0.7426 - val_mse:  0.7855\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7400 - mse:  0.7400 - val_mse:  0.7866\n",
            "Epoch 11/50\n",
            "5s - loss:  0.7371 - mse:  0.7370 - val_mse:  0.7913\n",
            "Epoch 12/50\n",
            "4s - loss:  0.7359 - mse:  0.7359 - val_mse:  0.7924\n",
            "Epoch 13/50\n",
            "4s - loss:  0.7319 - mse:  0.7319 - val_mse:  0.7858\n",
            "Epoch 14/50\n",
            "5s - loss:  0.7290 - mse:  0.7291 - val_mse:  0.7875\n",
            "Epoch 00014: early stopping\n",
            "xDeepFM Model RMSE: 0.8911\n",
            "xDeepFM Model MAE: 0.7080\n",
            "xDeepFM Model NDCG@5: 0.9331\n",
            "xDeepFM Model NDCG@10: 0.9222\n",
            "xDeepFM Model Precision@5: 0.8592\n",
            "xDeepFM Model Precision@10: 0.8112\n",
            "xDeepFM Execution Time: 74.11 seconds\n",
            "xDeepFM CPU Usage: -0.20%\n",
            "xDeepFM Memory Usage: 0.26 MB\n",
            "\n",
            "Training and evaluating IFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  5.6556 - mse:  5.6506 - val_mse:  1.1553\n",
            "Epoch 2/50\n",
            "2s - loss:  1.1616 - mse:  1.1614 - val_mse:  1.1302\n",
            "Epoch 3/50\n",
            "2s - loss:  1.1444 - mse:  1.1444 - val_mse:  1.0562\n",
            "Epoch 4/50\n",
            "2s - loss:  0.8750 - mse:  0.8749 - val_mse:  0.8233\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7940 - mse:  0.7938 - val_mse:  0.8160\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7757 - mse:  0.7756 - val_mse:  0.8141\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7680 - mse:  0.7680 - val_mse:  0.8063\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7624 - mse:  0.7624 - val_mse:  0.8011\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7564 - mse:  0.7564 - val_mse:  0.7971\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7530 - mse:  0.7530 - val_mse:  0.8024\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7491 - mse:  0.7493 - val_mse:  0.7946\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7472 - mse:  0.7472 - val_mse:  0.7971\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7462 - mse:  0.7463 - val_mse:  0.8059\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7427 - mse:  0.7428 - val_mse:  0.7951\n",
            "Epoch 15/50\n",
            "3s - loss:  0.7405 - mse:  0.7405 - val_mse:  0.7891\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7371 - mse:  0.7371 - val_mse:  0.7912\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7338 - mse:  0.7338 - val_mse:  0.7917\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7304 - mse:  0.7304 - val_mse:  0.7908\n",
            "Epoch 19/50\n",
            "2s - loss:  0.7266 - mse:  0.7265 - val_mse:  0.7907\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7240 - mse:  0.7241 - val_mse:  0.7983\n",
            "Epoch 00020: early stopping\n",
            "IFM Model RMSE: 0.8939\n",
            "IFM Model MAE: 0.7027\n",
            "IFM Model NDCG@5: 0.9349\n",
            "IFM Model NDCG@10: 0.9208\n",
            "IFM Model Precision@5: 0.8560\n",
            "IFM Model Precision@10: 0.8012\n",
            "IFM Execution Time: 61.17 seconds\n",
            "IFM CPU Usage: 11.00%\n",
            "IFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating LS-PLM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  10.9904 - mse:  10.9876 - val_mse:  8.0273\n",
            "Epoch 2/50\n",
            "4s - loss:  5.5603 - mse:  5.5583 - val_mse:  3.5292\n",
            "Epoch 3/50\n",
            "4s - loss:  2.4388 - mse:  2.4378 - val_mse:  1.6767\n",
            "Epoch 4/50\n",
            "4s - loss:  1.3790 - mse:  1.3788 - val_mse:  1.1812\n",
            "Epoch 5/50\n",
            "4s - loss:  1.1200 - mse:  1.1202 - val_mse:  1.0688\n",
            "Epoch 6/50\n",
            "4s - loss:  1.0489 - mse:  1.0488 - val_mse:  1.0272\n",
            "Epoch 7/50\n",
            "4s - loss:  1.0092 - mse:  1.0093 - val_mse:  0.9977\n",
            "Epoch 8/50\n",
            "4s - loss:  0.9757 - mse:  0.9757 - val_mse:  0.9715\n",
            "Epoch 9/50\n",
            "4s - loss:  0.9454 - mse:  0.9454 - val_mse:  0.9474\n",
            "Epoch 10/50\n",
            "4s - loss:  0.9175 - mse:  0.9175 - val_mse:  0.9255\n",
            "Epoch 11/50\n",
            "4s - loss:  0.8921 - mse:  0.8920 - val_mse:  0.9052\n",
            "Epoch 12/50\n",
            "4s - loss:  0.8690 - mse:  0.8689 - val_mse:  0.8868\n",
            "Epoch 13/50\n",
            "4s - loss:  0.8482 - mse:  0.8483 - val_mse:  0.8704\n",
            "Epoch 14/50\n",
            "4s - loss:  0.8298 - mse:  0.8298 - val_mse:  0.8558\n",
            "Epoch 15/50\n",
            "4s - loss:  0.8137 - mse:  0.8136 - val_mse:  0.8432\n",
            "Epoch 16/50\n",
            "4s - loss:  0.7999 - mse:  0.8000 - val_mse:  0.8329\n",
            "Epoch 17/50\n",
            "4s - loss:  0.7883 - mse:  0.7883 - val_mse:  0.8244\n",
            "Epoch 18/50\n",
            "4s - loss:  0.7787 - mse:  0.7785 - val_mse:  0.8174\n",
            "Epoch 19/50\n",
            "4s - loss:  0.7710 - mse:  0.7710 - val_mse:  0.8121\n",
            "Epoch 20/50\n",
            "4s - loss:  0.7648 - mse:  0.7650 - val_mse:  0.8080\n",
            "Epoch 21/50\n",
            "4s - loss:  0.7600 - mse:  0.7600 - val_mse:  0.8051\n",
            "Epoch 22/50\n",
            "4s - loss:  0.7562 - mse:  0.7562 - val_mse:  0.8033\n",
            "Epoch 23/50\n",
            "4s - loss:  0.7532 - mse:  0.7534 - val_mse:  0.8017\n",
            "Epoch 24/50\n",
            "4s - loss:  0.7509 - mse:  0.7508 - val_mse:  0.8007\n",
            "Epoch 25/50\n",
            "4s - loss:  0.7490 - mse:  0.7489 - val_mse:  0.8001\n",
            "Epoch 26/50\n",
            "4s - loss:  0.7474 - mse:  0.7474 - val_mse:  0.7995\n",
            "Epoch 27/50\n",
            "4s - loss:  0.7463 - mse:  0.7463 - val_mse:  0.7995\n",
            "Epoch 28/50\n",
            "4s - loss:  0.7452 - mse:  0.7452 - val_mse:  0.7992\n",
            "Epoch 29/50\n",
            "4s - loss:  0.7443 - mse:  0.7442 - val_mse:  0.7990\n",
            "Epoch 30/50\n",
            "4s - loss:  0.7433 - mse:  0.7432 - val_mse:  0.7989\n",
            "Epoch 31/50\n",
            "4s - loss:  0.7426 - mse:  0.7426 - val_mse:  0.7990\n",
            "Epoch 32/50\n",
            "4s - loss:  0.7420 - mse:  0.7420 - val_mse:  0.7991\n",
            "Epoch 33/50\n",
            "4s - loss:  0.7415 - mse:  0.7415 - val_mse:  0.7990\n",
            "Epoch 34/50\n",
            "4s - loss:  0.7410 - mse:  0.7409 - val_mse:  0.7990\n",
            "Epoch 35/50\n",
            "4s - loss:  0.7405 - mse:  0.7403 - val_mse:  0.7991\n",
            "Epoch 00035: early stopping\n",
            "LS-PLM Model RMSE: 0.8959\n",
            "LS-PLM Model MAE: 0.7090\n",
            "LS-PLM Model NDCG@5: 0.9361\n",
            "LS-PLM Model NDCG@10: 0.9210\n",
            "LS-PLM Model Precision@5: 0.8552\n",
            "LS-PLM Model Precision@10: 0.8036\n",
            "LS-PLM Execution Time: 156.13 seconds\n",
            "LS-PLM CPU Usage: -0.30%\n",
            "LS-PLM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating MHA...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "7s - loss:  5.1551 - mse:  5.1525 - val_mse:  1.4789\n",
            "Epoch 2/50\n",
            "7s - loss:  1.1350 - mse:  1.1349 - val_mse:  1.0169\n",
            "Epoch 3/50\n",
            "8s - loss:  0.9996 - mse:  0.9997 - val_mse:  0.9544\n",
            "Epoch 4/50\n",
            "7s - loss:  0.9370 - mse:  0.9368 - val_mse:  0.9070\n",
            "Epoch 5/50\n",
            "8s - loss:  0.8889 - mse:  0.8888 - val_mse:  0.8721\n",
            "Epoch 6/50\n",
            "7s - loss:  0.8527 - mse:  0.8527 - val_mse:  0.8466\n",
            "Epoch 7/50\n",
            "7s - loss:  0.8255 - mse:  0.8255 - val_mse:  0.8283\n",
            "Epoch 8/50\n",
            "7s - loss:  0.8051 - mse:  0.8052 - val_mse:  0.8152\n",
            "Epoch 9/50\n",
            "7s - loss:  0.7898 - mse:  0.7898 - val_mse:  0.8063\n",
            "Epoch 10/50\n",
            "7s - loss:  0.7785 - mse:  0.7784 - val_mse:  0.8001\n",
            "Epoch 11/50\n",
            "7s - loss:  0.7698 - mse:  0.7699 - val_mse:  0.7956\n",
            "Epoch 12/50\n",
            "7s - loss:  0.7632 - mse:  0.7632 - val_mse:  0.7929\n",
            "Epoch 13/50\n",
            "7s - loss:  0.7583 - mse:  0.7584 - val_mse:  0.7907\n",
            "Epoch 14/50\n",
            "8s - loss:  0.7543 - mse:  0.7542 - val_mse:  0.7896\n",
            "Epoch 15/50\n",
            "7s - loss:  0.7510 - mse:  0.7510 - val_mse:  0.7890\n",
            "Epoch 16/50\n",
            "7s - loss:  0.7484 - mse:  0.7483 - val_mse:  0.7879\n",
            "Epoch 17/50\n",
            "7s - loss:  0.7464 - mse:  0.7464 - val_mse:  0.7879\n",
            "Epoch 18/50\n",
            "7s - loss:  0.7445 - mse:  0.7447 - val_mse:  0.7882\n",
            "Epoch 19/50\n",
            "7s - loss:  0.7430 - mse:  0.7429 - val_mse:  0.7875\n",
            "Epoch 20/50\n",
            "7s - loss:  0.7417 - mse:  0.7418 - val_mse:  0.7875\n",
            "Epoch 21/50\n",
            "7s - loss:  0.7406 - mse:  0.7406 - val_mse:  0.7877\n",
            "Epoch 22/50\n",
            "7s - loss:  0.7395 - mse:  0.7395 - val_mse:  0.7888\n",
            "Epoch 23/50\n",
            "8s - loss:  0.7385 - mse:  0.7385 - val_mse:  0.7881\n",
            "Epoch 24/50\n",
            "7s - loss:  0.7380 - mse:  0.7379 - val_mse:  0.7882\n",
            "Epoch 00024: early stopping\n",
            "MHA Model RMSE: 0.8895\n",
            "MHA Model MAE: 0.7054\n",
            "MHA Model NDCG@5: 0.9351\n",
            "MHA Model NDCG@10: 0.9227\n",
            "MHA Model Precision@5: 0.8600\n",
            "MHA Model Precision@10: 0.8028\n",
            "MHA Execution Time: 188.92 seconds\n",
            "MHA CPU Usage: 1.50%\n",
            "MHA Memory Usage: 0.00 MB\n",
            "\n",
            "Final Results:\n",
            "AFM - RMSE: 0.8907, MAE: 0.7071,  NDCG@5: 0.9334,  Precision@5: 0.8608, NDCG@10: 0.9216,  Precision@10: 0.8052,  Time: 62.76s,  CPU: 0.80%, Memory: 0.00MB\n",
            "AutoInt - RMSE: 0.9038, MAE: 0.7237,  NDCG@5: 0.9341,  Precision@5: 0.8592, NDCG@10: 0.9217,  Precision@10: 0.8032,  Time: 48.74s,  CPU: 0.40%, Memory: 0.00MB\n",
            "CCPM - RMSE: 0.9293, MAE: 0.7355,  NDCG@5: 0.9269,  Precision@5: 0.8400, NDCG@10: 0.9143,  Precision@10: 0.7780,  Time: 48.54s,  CPU: -0.10%, Memory: 0.00MB\n",
            "DCN - RMSE: 0.8920, MAE: 0.7034,  NDCG@5: 0.9361,  Precision@5: 0.8568, NDCG@10: 0.9224,  Precision@10: 0.8012,  Time: 44.84s,  CPU: -0.20%, Memory: 0.00MB\n",
            "DeepFM - RMSE: 0.8943, MAE: 0.7043,  NDCG@5: 0.9301,  Precision@5: 0.8584, NDCG@10: 0.9206,  Precision@10: 0.8008,  Time: 33.82s,  CPU: 0.10%, Memory: 1.29MB\n",
            "DIFM - RMSE: 0.9001, MAE: 0.7067,  NDCG@5: 0.9311,  Precision@5: 0.8568, NDCG@10: 0.9199,  Precision@10: 0.8044,  Time: 75.47s,  CPU: -0.40%, Memory: 0.00MB\n",
            "FiBiNET - RMSE: 0.8913, MAE: 0.7015,  NDCG@5: 0.9330,  Precision@5: 0.8576, NDCG@10: 0.9209,  Precision@10: 0.8052,  Time: 53.77s,  CPU: -0.20%, Memory: 0.00MB\n",
            "NFM - RMSE: 0.8997, MAE: 0.7178,  NDCG@5: 0.9319,  Precision@5: 0.8536, NDCG@10: 0.9204,  Precision@10: 0.8028,  Time: 55.48s,  CPU: 0.00%, Memory: 0.00MB\n",
            "ONN - RMSE: 0.9843, MAE: 0.7779,  NDCG@5: 0.9150,  Precision@5: 0.8216, NDCG@10: 0.8984,  Precision@10: 0.7612,  Time: 33.35s,  CPU: 2.30%, Memory: 0.00MB\n",
            "PNN - RMSE: 0.9027, MAE: 0.7071,  NDCG@5: 0.9283,  Precision@5: 0.8544, NDCG@10: 0.9189,  Precision@10: 0.8072,  Time: 23.77s,  CPU: -13.80%, Memory: 0.00MB\n",
            "WDL - RMSE: 0.8945, MAE: 0.7042,  NDCG@5: 0.9316,  Precision@5: 0.8600, NDCG@10: 0.9212,  Precision@10: 0.8016,  Time: 32.02s,  CPU: -8.10%, Memory: 0.00MB\n",
            "xDeepFM - RMSE: 0.8911, MAE: 0.7080,  NDCG@5: 0.9331,  Precision@5: 0.8592, NDCG@10: 0.9222,  Precision@10: 0.8112,  Time: 74.11s,  CPU: -0.20%, Memory: 0.26MB\n",
            "IFM - RMSE: 0.8939, MAE: 0.7027,  NDCG@5: 0.9349,  Precision@5: 0.8560, NDCG@10: 0.9208,  Precision@10: 0.8012,  Time: 61.17s,  CPU: 11.00%, Memory: 0.00MB\n",
            "LS-PLM - RMSE: 0.8959, MAE: 0.7090,  NDCG@5: 0.9361,  Precision@5: 0.8552, NDCG@10: 0.9210,  Precision@10: 0.8036,  Time: 156.13s,  CPU: -0.30%, Memory: 0.00MB\n",
            "MHA - RMSE: 0.8895, MAE: 0.7054,  NDCG@5: 0.9351,  Precision@5: 0.8600, NDCG@10: 0.9227,  Precision@10: 0.8028,  Time: 188.92s,  CPU: 1.50%, Memory: 0.00MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MCGRS-SC-D: Running Prediction with criteria, with single context: DayType**"
      ],
      "metadata": {
        "id": "_Dj_P2avDV1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_features = [\n",
        "          'UserID',            # unique user\n",
        "          'GroupID',           # assigned via KMeans\n",
        "          'MovieID',           # unique movie\n",
        "          'Title',             # optional (high-cardinality), usually omit or hash\n",
        "          'UserOccupation',    # categorical occupation\n",
        "          'DayType'           # ['Weekday', 'Weekend']\n",
        "      ]\n",
        "dense_features = [\n",
        "          'UserAge',           # continuous age\n",
        "          'Storyline',         # simulated multi-criteria\n",
        "          'Visuals',           # simulated multi-criteria\n",
        "          'Emotion'           # simulated multi-criteria\n",
        "      ]\n",
        "run(dense_features, sparse_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hB8l121DX35",
        "outputId": "c7ddf472-52a6-426a-8bf7-901bbcc790c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_rating:     UserID  GroupID  MovieID                    Title                  Genres  \\\n",
            "0     196       21      242             Kolya (1996)                  Comedy   \n",
            "1     196       21      393    Mrs. Doubtfire (1993)                  Comedy   \n",
            "2     196       21      381  Muriel's Wedding (1994)          Comedy|Romance   \n",
            "3     196       21      251   Shall We Dance? (1996)                  Comedy   \n",
            "4     196       21      655       Stand by Me (1986)  Adventure|Comedy|Drama   \n",
            "\n",
            "   UserAge  UserOccupation  TimeOfDay  DayType  Season  Storyline   Visuals  \\\n",
            "0       49              20  Afternoon  Weekday  Winter   4.986857  5.000000   \n",
            "1       49              20  Afternoon  Weekday  Winter   3.446943  1.000000   \n",
            "2       49              20  Afternoon  Weekday  Winter   5.000000  5.000000   \n",
            "3       49              20  Afternoon  Weekday  Winter   5.000000  1.000000   \n",
            "4       49              20  Afternoon  Weekday  Winter   4.063386  3.690389   \n",
            "\n",
            "    Emotion  OverallRating  \n",
            "0  5.000000              3  \n",
            "1  3.623087              4  \n",
            "2  1.000000              4  \n",
            "3  1.000000              3  \n",
            "4  3.629397              5  \n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "sparse_features ['UserID', 'GroupID', 'MovieID', 'Title', 'UserOccupation', 'DayType']\n",
            "feat:  UserID\n",
            "feat:  GroupID\n",
            "feat:  MovieID\n",
            "feat:  Title\n",
            "feat:  UserOccupation\n",
            "feat:  DayType\n",
            "feature columns:  [SparseFeat(name='UserID', vocabulary_size=943, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserID', group_name='default_group'), SparseFeat(name='GroupID', vocabulary_size=250, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='GroupID', group_name='default_group'), SparseFeat(name='MovieID', vocabulary_size=1682, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='MovieID', group_name='default_group'), SparseFeat(name='Title', vocabulary_size=1664, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Title', group_name='default_group'), SparseFeat(name='UserOccupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserOccupation', group_name='default_group'), SparseFeat(name='DayType', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='DayType', group_name='default_group'), DenseFeat(name='UserAge', dimension=1, dtype='float32'), DenseFeat(name='Storyline', dimension=1, dtype='float32'), DenseFeat(name='Visuals', dimension=1, dtype='float32'), DenseFeat(name='Emotion', dimension=1, dtype='float32')]\n",
            "\n",
            "Training and evaluating AFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  9.0914 - mse:  9.0872 - val_mse:  5.2992\n",
            "Epoch 2/50\n",
            "2s - loss:  2.6105 - mse:  2.6085 - val_mse:  1.0179\n",
            "Epoch 3/50\n",
            "2s - loss:  0.9997 - mse:  0.9996 - val_mse:  0.9410\n",
            "Epoch 4/50\n",
            "2s - loss:  0.9157 - mse:  0.9156 - val_mse:  0.8698\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8359 - mse:  0.8359 - val_mse:  0.8211\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7903 - mse:  0.7903 - val_mse:  0.8073\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7711 - mse:  0.7710 - val_mse:  0.8014\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7597 - mse:  0.7597 - val_mse:  0.7979\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7506 - mse:  0.7505 - val_mse:  0.7961\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7435 - mse:  0.7436 - val_mse:  0.7937\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7372 - mse:  0.7373 - val_mse:  0.7922\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7312 - mse:  0.7313 - val_mse:  0.7916\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7253 - mse:  0.7252 - val_mse:  0.7904\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7197 - mse:  0.7196 - val_mse:  0.7905\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7142 - mse:  0.7141 - val_mse:  0.7901\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7092 - mse:  0.7092 - val_mse:  0.7906\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7035 - mse:  0.7032 - val_mse:  0.7910\n",
            "Epoch 18/50\n",
            "2s - loss:  0.6983 - mse:  0.6981 - val_mse:  0.7918\n",
            "Epoch 19/50\n",
            "2s - loss:  0.6929 - mse:  0.6929 - val_mse:  0.7921\n",
            "Epoch 20/50\n",
            "2s - loss:  0.6874 - mse:  0.6873 - val_mse:  0.7937\n",
            "Epoch 00020: early stopping\n",
            "AFM Model RMSE: 0.8944\n",
            "AFM Model MAE: 0.7071\n",
            "AFM Model NDCG@5: 0.9346\n",
            "AFM Model NDCG@10: 0.9217\n",
            "AFM Model Precision@5: 0.8544\n",
            "AFM Model Precision@10: 0.8052\n",
            "AFM Execution Time: 56.14 seconds\n",
            "AFM CPU Usage: 0.20%\n",
            "AFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating AutoInt...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.1111 - mse:  2.1096 - val_mse:  0.8118\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7871 - mse:  0.7872 - val_mse:  0.7985\n",
            "Epoch 3/50\n",
            "5s - loss:  0.7676 - mse:  0.7676 - val_mse:  0.7947\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7613 - mse:  0.7613 - val_mse:  0.7911\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7573 - mse:  0.7574 - val_mse:  0.7921\n",
            "Epoch 6/50\n",
            "5s - loss:  0.7551 - mse:  0.7552 - val_mse:  0.7915\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7542 - mse:  0.7543 - val_mse:  0.7890\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7508 - mse:  0.7508 - val_mse:  0.7897\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7503 - mse:  0.7503 - val_mse:  0.7923\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7513 - mse:  0.7512 - val_mse:  0.7892\n",
            "Epoch 11/50\n",
            "4s - loss:  0.7482 - mse:  0.7481 - val_mse:  0.7910\n",
            "Epoch 12/50\n",
            "4s - loss:  0.7449 - mse:  0.7448 - val_mse:  0.8072\n",
            "Epoch 00012: early stopping\n",
            "AutoInt Model RMSE: 0.9034\n",
            "AutoInt Model MAE: 0.7228\n",
            "AutoInt Model NDCG@5: 0.9328\n",
            "AutoInt Model NDCG@10: 0.9198\n",
            "AutoInt Model Precision@5: 0.8616\n",
            "AutoInt Model Precision@10: 0.8028\n",
            "AutoInt Execution Time: 57.34 seconds\n",
            "AutoInt CPU Usage: 0.00%\n",
            "AutoInt Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating CCPM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.1830 - mse:  2.1817 - val_mse:  1.0452\n",
            "Epoch 2/50\n",
            "3s - loss:  0.9265 - mse:  0.9264 - val_mse:  0.8674\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8259 - mse:  0.8259 - val_mse:  0.8393\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7968 - mse:  0.7967 - val_mse:  0.8219\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7755 - mse:  0.7755 - val_mse:  0.8100\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7629 - mse:  0.7629 - val_mse:  0.7981\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7502 - mse:  0.7503 - val_mse:  0.8008\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7398 - mse:  0.7398 - val_mse:  0.7992\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7325 - mse:  0.7324 - val_mse:  0.7904\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7212 - mse:  0.7213 - val_mse:  0.7857\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7100 - mse:  0.7100 - val_mse:  0.7900\n",
            "Epoch 12/50\n",
            "3s - loss:  0.6982 - mse:  0.6982 - val_mse:  0.7919\n",
            "Epoch 13/50\n",
            "3s - loss:  0.6875 - mse:  0.6875 - val_mse:  0.7949\n",
            "Epoch 14/50\n",
            "3s - loss:  0.6720 - mse:  0.6720 - val_mse:  0.7991\n",
            "Epoch 15/50\n",
            "3s - loss:  0.6556 - mse:  0.6556 - val_mse:  0.8164\n",
            "Epoch 00015: early stopping\n",
            "CCPM Model RMSE: 0.9063\n",
            "CCPM Model MAE: 0.7117\n",
            "CCPM Model NDCG@5: 0.9359\n",
            "CCPM Model NDCG@10: 0.9211\n",
            "CCPM Model Precision@5: 0.8472\n",
            "CCPM Model Precision@10: 0.8004\n",
            "CCPM Execution Time: 56.88 seconds\n",
            "CCPM CPU Usage: 14.10%\n",
            "CCPM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DCN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  1.9916 - mse:  1.9901 - val_mse:  0.8108\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7864 - mse:  0.7864 - val_mse:  0.7923\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7670 - mse:  0.7669 - val_mse:  0.7933\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7607 - mse:  0.7606 - val_mse:  0.7912\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7572 - mse:  0.7572 - val_mse:  0.7918\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7551 - mse:  0.7549 - val_mse:  0.7904\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7535 - mse:  0.7535 - val_mse:  0.7928\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7512 - mse:  0.7513 - val_mse:  0.7926\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7492 - mse:  0.7492 - val_mse:  0.7987\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7474 - mse:  0.7474 - val_mse:  0.7874\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7456 - mse:  0.7457 - val_mse:  0.7944\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7429 - mse:  0.7432 - val_mse:  0.7855\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7410 - mse:  0.7411 - val_mse:  0.7923\n",
            "Epoch 14/50\n",
            "3s - loss:  0.7407 - mse:  0.7407 - val_mse:  0.7867\n",
            "Epoch 15/50\n",
            "3s - loss:  0.7367 - mse:  0.7368 - val_mse:  0.7909\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7347 - mse:  0.7346 - val_mse:  0.7988\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7338 - mse:  0.7338 - val_mse:  0.7840\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7300 - mse:  0.7300 - val_mse:  0.7859\n",
            "Epoch 19/50\n",
            "3s - loss:  0.7273 - mse:  0.7273 - val_mse:  0.7967\n",
            "Epoch 20/50\n",
            "3s - loss:  0.7252 - mse:  0.7253 - val_mse:  0.7853\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7194 - mse:  0.7194 - val_mse:  0.7844\n",
            "Epoch 22/50\n",
            "2s - loss:  0.7167 - mse:  0.7168 - val_mse:  0.7854\n",
            "Epoch 00022: early stopping\n",
            "DCN Model RMSE: 0.8922\n",
            "DCN Model MAE: 0.7023\n",
            "DCN Model NDCG@5: 0.9344\n",
            "DCN Model NDCG@10: 0.9197\n",
            "DCN Model Precision@5: 0.8536\n",
            "DCN Model Precision@10: 0.7984\n",
            "DCN Execution Time: 72.04 seconds\n",
            "DCN CPU Usage: -14.70%\n",
            "DCN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0765 - mse:  2.0750 - val_mse:  0.8114\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7880 - mse:  0.7880 - val_mse:  0.7948\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7685 - mse:  0.7683 - val_mse:  0.7910\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7627 - mse:  0.7628 - val_mse:  0.7925\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7597 - mse:  0.7598 - val_mse:  0.7970\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7582 - mse:  0.7582 - val_mse:  0.8002\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7562 - mse:  0.7561 - val_mse:  0.7985\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7554 - mse:  0.7553 - val_mse:  0.7922\n",
            "Epoch 00008: early stopping\n",
            "DeepFM Model RMSE: 0.8941\n",
            "DeepFM Model MAE: 0.7127\n",
            "DeepFM Model NDCG@5: 0.9324\n",
            "DeepFM Model NDCG@10: 0.9209\n",
            "DeepFM Model Precision@5: 0.8568\n",
            "DeepFM Model Precision@10: 0.8056\n",
            "DeepFM Execution Time: 25.19 seconds\n",
            "DeepFM CPU Usage: 0.40%\n",
            "DeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DIFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  3.3597 - mse:  3.3566 - val_mse:  0.9042\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8799 - mse:  0.8800 - val_mse:  0.8742\n",
            "Epoch 3/50\n",
            "4s - loss:  0.8479 - mse:  0.8478 - val_mse:  0.8589\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8258 - mse:  0.8257 - val_mse:  0.8422\n",
            "Epoch 5/50\n",
            "3s - loss:  0.8117 - mse:  0.8115 - val_mse:  0.8334\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7965 - mse:  0.7967 - val_mse:  0.8193\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7837 - mse:  0.7837 - val_mse:  0.8242\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7733 - mse:  0.7733 - val_mse:  0.8042\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7649 - mse:  0.7648 - val_mse:  0.7991\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7582 - mse:  0.7582 - val_mse:  0.7998\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7544 - mse:  0.7544 - val_mse:  0.7984\n",
            "Epoch 12/50\n",
            "4s - loss:  0.7457 - mse:  0.7456 - val_mse:  0.7939\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7396 - mse:  0.7397 - val_mse:  0.7994\n",
            "Epoch 14/50\n",
            "3s - loss:  0.7257 - mse:  0.7257 - val_mse:  0.7916\n",
            "Epoch 15/50\n",
            "3s - loss:  0.7133 - mse:  0.7133 - val_mse:  0.7926\n",
            "Epoch 16/50\n",
            "3s - loss:  0.6976 - mse:  0.6976 - val_mse:  0.7969\n",
            "Epoch 17/50\n",
            "4s - loss:  0.6833 - mse:  0.6831 - val_mse:  0.8047\n",
            "Epoch 18/50\n",
            "3s - loss:  0.6690 - mse:  0.6691 - val_mse:  0.8100\n",
            "Epoch 19/50\n",
            "3s - loss:  0.6548 - mse:  0.6550 - val_mse:  0.8326\n",
            "Epoch 00019: early stopping\n",
            "DIFM Model RMSE: 0.9169\n",
            "DIFM Model MAE: 0.7155\n",
            "DIFM Model NDCG@5: 0.9297\n",
            "DIFM Model NDCG@10: 0.9199\n",
            "DIFM Model Precision@5: 0.8544\n",
            "DIFM Model Precision@10: 0.8024\n",
            "DIFM Execution Time: 74.73 seconds\n",
            "DIFM CPU Usage: -2.10%\n",
            "DIFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating FiBiNET...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.2559 - mse:  2.2543 - val_mse:  0.8234\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7911 - mse:  0.7912 - val_mse:  0.7945\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7658 - mse:  0.7659 - val_mse:  0.7923\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7578 - mse:  0.7578 - val_mse:  0.7879\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7505 - mse:  0.7504 - val_mse:  0.7849\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7432 - mse:  0.7433 - val_mse:  0.7773\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7331 - mse:  0.7332 - val_mse:  0.7786\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7198 - mse:  0.7197 - val_mse:  0.7766\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7078 - mse:  0.7080 - val_mse:  0.7870\n",
            "Epoch 10/50\n",
            "4s - loss:  0.6974 - mse:  0.6974 - val_mse:  0.7855\n",
            "Epoch 11/50\n",
            "4s - loss:  0.6882 - mse:  0.6881 - val_mse:  0.7847\n",
            "Epoch 12/50\n",
            "4s - loss:  0.6751 - mse:  0.6750 - val_mse:  0.7940\n",
            "Epoch 13/50\n",
            "4s - loss:  0.6604 - mse:  0.6604 - val_mse:  0.7914\n",
            "Epoch 00013: early stopping\n",
            "FiBiNET Model RMSE: 0.8900\n",
            "FiBiNET Model MAE: 0.6997\n",
            "FiBiNET Model NDCG@5: 0.9295\n",
            "FiBiNET Model NDCG@10: 0.9199\n",
            "FiBiNET Model Precision@5: 0.8632\n",
            "FiBiNET Model Precision@10: 0.8092\n",
            "FiBiNET Execution Time: 60.06 seconds\n",
            "FiBiNET CPU Usage: -1.00%\n",
            "FiBiNET Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating NFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0294 - mse:  2.0283 - val_mse:  0.8296\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7933 - mse:  0.7933 - val_mse:  0.7946\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7581 - mse:  0.7581 - val_mse:  0.7860\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7418 - mse:  0.7418 - val_mse:  0.7880\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7293 - mse:  0.7293 - val_mse:  0.7839\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7170 - mse:  0.7170 - val_mse:  0.7864\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7064 - mse:  0.7064 - val_mse:  0.7897\n",
            "Epoch 8/50\n",
            "2s - loss:  0.6969 - mse:  0.6972 - val_mse:  0.7917\n",
            "Epoch 9/50\n",
            "2s - loss:  0.6864 - mse:  0.6864 - val_mse:  0.7984\n",
            "Epoch 10/50\n",
            "2s - loss:  0.6792 - mse:  0.6792 - val_mse:  0.8007\n",
            "Epoch 00010: early stopping\n",
            "NFM Model RMSE: 0.8939\n",
            "NFM Model MAE: 0.7031\n",
            "NFM Model NDCG@5: 0.9339\n",
            "NFM Model NDCG@10: 0.9236\n",
            "NFM Model Precision@5: 0.8648\n",
            "NFM Model Precision@10: 0.7992\n",
            "NFM Execution Time: 29.70 seconds\n",
            "NFM CPU Usage: 10.40%\n",
            "NFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating ONN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.0136 - mse:  2.0109 - val_mse:  0.8135\n",
            "Epoch 2/50\n",
            "5s - loss:  0.7584 - mse:  0.7572 - val_mse:  0.8159\n",
            "Epoch 3/50\n",
            "4s - loss:  0.6752 - mse:  0.6740 - val_mse:  0.8589\n",
            "Epoch 4/50\n",
            "4s - loss:  0.6252 - mse:  0.6241 - val_mse:  0.8993\n",
            "Epoch 5/50\n",
            "5s - loss:  0.5941 - mse:  0.5930 - val_mse:  0.9270\n",
            "Epoch 6/50\n",
            "4s - loss:  0.5718 - mse:  0.5706 - val_mse:  0.9522\n",
            "Epoch 00006: early stopping\n",
            "ONN Model RMSE: 0.9753\n",
            "ONN Model MAE: 0.7719\n",
            "ONN Model NDCG@5: 0.9093\n",
            "ONN Model NDCG@10: 0.8976\n",
            "ONN Model Precision@5: 0.8224\n",
            "ONN Model Precision@10: 0.7644\n",
            "ONN Execution Time: 32.01 seconds\n",
            "ONN CPU Usage: -0.10%\n",
            "ONN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating PNN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.1599 - mse:  2.1584 - val_mse:  0.8123\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7869 - mse:  0.7868 - val_mse:  0.7915\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7628 - mse:  0.7629 - val_mse:  0.7879\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7452 - mse:  0.7452 - val_mse:  0.7809\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7274 - mse:  0.7275 - val_mse:  0.7808\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7113 - mse:  0.7113 - val_mse:  0.7874\n",
            "Epoch 7/50\n",
            "2s - loss:  0.6953 - mse:  0.6953 - val_mse:  0.7979\n",
            "Epoch 8/50\n",
            "2s - loss:  0.6804 - mse:  0.6803 - val_mse:  0.8017\n",
            "Epoch 9/50\n",
            "2s - loss:  0.6672 - mse:  0.6673 - val_mse:  0.8110\n",
            "Epoch 10/50\n",
            "2s - loss:  0.6473 - mse:  0.6473 - val_mse:  0.8137\n",
            "Epoch 00010: early stopping\n",
            "PNN Model RMSE: 0.9051\n",
            "PNN Model MAE: 0.7121\n",
            "PNN Model NDCG@5: 0.9298\n",
            "PNN Model NDCG@10: 0.9187\n",
            "PNN Model Precision@5: 0.8520\n",
            "PNN Model Precision@10: 0.8064\n",
            "PNN Execution Time: 25.87 seconds\n",
            "PNN CPU Usage: -0.20%\n",
            "PNN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating WDL...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0824 - mse:  2.0809 - val_mse:  0.8110\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7870 - mse:  0.7869 - val_mse:  0.7938\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7668 - mse:  0.7667 - val_mse:  0.7900\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7610 - mse:  0.7611 - val_mse:  0.7914\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7580 - mse:  0.7580 - val_mse:  0.7961\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7565 - mse:  0.7565 - val_mse:  0.7993\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7547 - mse:  0.7545 - val_mse:  0.7981\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7540 - mse:  0.7540 - val_mse:  0.7915\n",
            "Epoch 00008: early stopping\n",
            "WDL Model RMSE: 0.8937\n",
            "WDL Model MAE: 0.7126\n",
            "WDL Model NDCG@5: 0.9348\n",
            "WDL Model NDCG@10: 0.9226\n",
            "WDL Model Precision@5: 0.8560\n",
            "WDL Model Precision@10: 0.8044\n",
            "WDL Execution Time: 23.90 seconds\n",
            "WDL CPU Usage: 0.20%\n",
            "WDL Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating xDeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  1.8500 - mse:  1.8489 - val_mse:  0.8052\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7825 - mse:  0.7824 - val_mse:  0.7903\n",
            "Epoch 3/50\n",
            "5s - loss:  0.7652 - mse:  0.7651 - val_mse:  0.7897\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7599 - mse:  0.7600 - val_mse:  0.7911\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7577 - mse:  0.7577 - val_mse:  0.7890\n",
            "Epoch 6/50\n",
            "5s - loss:  0.7535 - mse:  0.7534 - val_mse:  0.7868\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7495 - mse:  0.7496 - val_mse:  0.7886\n",
            "Epoch 8/50\n",
            "5s - loss:  0.7464 - mse:  0.7465 - val_mse:  0.7993\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7418 - mse:  0.7418 - val_mse:  0.7873\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7392 - mse:  0.7393 - val_mse:  0.7932\n",
            "Epoch 11/50\n",
            "5s - loss:  0.7346 - mse:  0.7345 - val_mse:  0.7832\n",
            "Epoch 12/50\n",
            "4s - loss:  0.7328 - mse:  0.7329 - val_mse:  0.7862\n",
            "Epoch 13/50\n",
            "4s - loss:  0.7302 - mse:  0.7301 - val_mse:  0.7919\n",
            "Epoch 14/50\n",
            "5s - loss:  0.7292 - mse:  0.7293 - val_mse:  0.7911\n",
            "Epoch 15/50\n",
            "5s - loss:  0.7252 - mse:  0.7253 - val_mse:  0.7865\n",
            "Epoch 16/50\n",
            "4s - loss:  0.7221 - mse:  0.7222 - val_mse:  0.7859\n",
            "Epoch 00016: early stopping\n",
            "xDeepFM Model RMSE: 0.8906\n",
            "xDeepFM Model MAE: 0.7070\n",
            "xDeepFM Model NDCG@5: 0.9352\n",
            "xDeepFM Model NDCG@10: 0.9237\n",
            "xDeepFM Model Precision@5: 0.8608\n",
            "xDeepFM Model Precision@10: 0.8076\n",
            "xDeepFM Execution Time: 81.51 seconds\n",
            "xDeepFM CPU Usage: 13.20%\n",
            "xDeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating IFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  5.6734 - mse:  5.6684 - val_mse:  1.1654\n",
            "Epoch 2/50\n",
            "2s - loss:  1.1663 - mse:  1.1664 - val_mse:  1.1358\n",
            "Epoch 3/50\n",
            "2s - loss:  1.0164 - mse:  1.0162 - val_mse:  0.8499\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8172 - mse:  0.8171 - val_mse:  0.8262\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7874 - mse:  0.7875 - val_mse:  0.8119\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7732 - mse:  0.7731 - val_mse:  0.8104\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7668 - mse:  0.7666 - val_mse:  0.8100\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7609 - mse:  0.7609 - val_mse:  0.7999\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7572 - mse:  0.7572 - val_mse:  0.7985\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7534 - mse:  0.7534 - val_mse:  0.7973\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7494 - mse:  0.7495 - val_mse:  0.7954\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7477 - mse:  0.7477 - val_mse:  0.7970\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7447 - mse:  0.7449 - val_mse:  0.7913\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7428 - mse:  0.7429 - val_mse:  0.7913\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7401 - mse:  0.7402 - val_mse:  0.8022\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7348 - mse:  0.7349 - val_mse:  0.7975\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7306 - mse:  0.7305 - val_mse:  0.7897\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7267 - mse:  0.7267 - val_mse:  0.7908\n",
            "Epoch 19/50\n",
            "3s - loss:  0.7224 - mse:  0.7224 - val_mse:  0.7910\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7182 - mse:  0.7182 - val_mse:  0.7877\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7134 - mse:  0.7134 - val_mse:  0.7862\n",
            "Epoch 22/50\n",
            "3s - loss:  0.7087 - mse:  0.7087 - val_mse:  0.7903\n",
            "Epoch 23/50\n",
            "2s - loss:  0.7052 - mse:  0.7051 - val_mse:  0.7887\n",
            "Epoch 24/50\n",
            "2s - loss:  0.7012 - mse:  0.7012 - val_mse:  0.7885\n",
            "Epoch 25/50\n",
            "2s - loss:  0.6954 - mse:  0.6953 - val_mse:  0.7940\n",
            "Epoch 26/50\n",
            "2s - loss:  0.6927 - mse:  0.6927 - val_mse:  0.7945\n",
            "Epoch 00026: early stopping\n",
            "IFM Model RMSE: 0.8918\n",
            "IFM Model MAE: 0.7029\n",
            "IFM Model NDCG@5: 0.9330\n",
            "IFM Model NDCG@10: 0.9211\n",
            "IFM Model Precision@5: 0.8528\n",
            "IFM Model Precision@10: 0.8032\n",
            "IFM Execution Time: 76.92 seconds\n",
            "IFM CPU Usage: 3.50%\n",
            "IFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating LS-PLM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  10.9898 - mse:  10.9862 - val_mse:  8.0259\n",
            "Epoch 2/50\n",
            "4s - loss:  5.5614 - mse:  5.5590 - val_mse:  3.5288\n",
            "Epoch 3/50\n",
            "4s - loss:  2.4390 - mse:  2.4380 - val_mse:  1.6767\n",
            "Epoch 4/50\n",
            "4s - loss:  1.3788 - mse:  1.3785 - val_mse:  1.1811\n",
            "Epoch 5/50\n",
            "3s - loss:  1.1197 - mse:  1.1198 - val_mse:  1.0684\n",
            "Epoch 6/50\n",
            "4s - loss:  1.0487 - mse:  1.0487 - val_mse:  1.0272\n",
            "Epoch 7/50\n",
            "4s - loss:  1.0091 - mse:  1.0092 - val_mse:  0.9977\n",
            "Epoch 8/50\n",
            "4s - loss:  0.9755 - mse:  0.9754 - val_mse:  0.9714\n",
            "Epoch 9/50\n",
            "4s - loss:  0.9452 - mse:  0.9454 - val_mse:  0.9476\n",
            "Epoch 10/50\n",
            "4s - loss:  0.9175 - mse:  0.9175 - val_mse:  0.9256\n",
            "Epoch 11/50\n",
            "4s - loss:  0.8920 - mse:  0.8921 - val_mse:  0.9054\n",
            "Epoch 12/50\n",
            "4s - loss:  0.8689 - mse:  0.8690 - val_mse:  0.8870\n",
            "Epoch 13/50\n",
            "4s - loss:  0.8481 - mse:  0.8482 - val_mse:  0.8705\n",
            "Epoch 14/50\n",
            "4s - loss:  0.8297 - mse:  0.8298 - val_mse:  0.8558\n",
            "Epoch 15/50\n",
            "4s - loss:  0.8135 - mse:  0.8135 - val_mse:  0.8433\n",
            "Epoch 16/50\n",
            "4s - loss:  0.7997 - mse:  0.7997 - val_mse:  0.8328\n",
            "Epoch 17/50\n",
            "4s - loss:  0.7881 - mse:  0.7881 - val_mse:  0.8242\n",
            "Epoch 18/50\n",
            "4s - loss:  0.7786 - mse:  0.7786 - val_mse:  0.8172\n",
            "Epoch 19/50\n",
            "4s - loss:  0.7708 - mse:  0.7708 - val_mse:  0.8121\n",
            "Epoch 20/50\n",
            "4s - loss:  0.7646 - mse:  0.7647 - val_mse:  0.8079\n",
            "Epoch 21/50\n",
            "4s - loss:  0.7598 - mse:  0.7597 - val_mse:  0.8050\n",
            "Epoch 22/50\n",
            "4s - loss:  0.7561 - mse:  0.7562 - val_mse:  0.8029\n",
            "Epoch 23/50\n",
            "4s - loss:  0.7530 - mse:  0.7531 - val_mse:  0.8015\n",
            "Epoch 24/50\n",
            "4s - loss:  0.7507 - mse:  0.7507 - val_mse:  0.8006\n",
            "Epoch 25/50\n",
            "5s - loss:  0.7488 - mse:  0.7488 - val_mse:  0.7998\n",
            "Epoch 26/50\n",
            "4s - loss:  0.7474 - mse:  0.7473 - val_mse:  0.7995\n",
            "Epoch 27/50\n",
            "4s - loss:  0.7461 - mse:  0.7462 - val_mse:  0.7992\n",
            "Epoch 28/50\n",
            "4s - loss:  0.7449 - mse:  0.7448 - val_mse:  0.7993\n",
            "Epoch 29/50\n",
            "4s - loss:  0.7440 - mse:  0.7439 - val_mse:  0.7989\n",
            "Epoch 30/50\n",
            "4s - loss:  0.7432 - mse:  0.7431 - val_mse:  0.7988\n",
            "Epoch 31/50\n",
            "4s - loss:  0.7425 - mse:  0.7426 - val_mse:  0.7990\n",
            "Epoch 32/50\n",
            "4s - loss:  0.7418 - mse:  0.7418 - val_mse:  0.7990\n",
            "Epoch 33/50\n",
            "4s - loss:  0.7413 - mse:  0.7412 - val_mse:  0.7992\n",
            "Epoch 34/50\n",
            "4s - loss:  0.7407 - mse:  0.7408 - val_mse:  0.7990\n",
            "Epoch 35/50\n",
            "4s - loss:  0.7402 - mse:  0.7402 - val_mse:  0.7991\n",
            "Epoch 00035: early stopping\n",
            "LS-PLM Model RMSE: 0.8960\n",
            "LS-PLM Model MAE: 0.7101\n",
            "LS-PLM Model NDCG@5: 0.9351\n",
            "LS-PLM Model NDCG@10: 0.9207\n",
            "LS-PLM Model Precision@5: 0.8536\n",
            "LS-PLM Model Precision@10: 0.8032\n",
            "LS-PLM Execution Time: 155.01 seconds\n",
            "LS-PLM CPU Usage: -0.10%\n",
            "LS-PLM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating MHA...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "8s - loss:  6.2685 - mse:  6.2644 - val_mse:  2.1029\n",
            "Epoch 2/50\n",
            "7s - loss:  1.3112 - mse:  1.3110 - val_mse:  1.0227\n",
            "Epoch 3/50\n",
            "7s - loss:  1.0044 - mse:  1.0044 - val_mse:  0.9578\n",
            "Epoch 4/50\n",
            "7s - loss:  0.9437 - mse:  0.9436 - val_mse:  0.9118\n",
            "Epoch 5/50\n",
            "7s - loss:  0.8963 - mse:  0.8963 - val_mse:  0.8771\n",
            "Epoch 6/50\n",
            "7s - loss:  0.8599 - mse:  0.8597 - val_mse:  0.8515\n",
            "Epoch 7/50\n",
            "7s - loss:  0.8321 - mse:  0.8321 - val_mse:  0.8327\n",
            "Epoch 8/50\n",
            "7s - loss:  0.8111 - mse:  0.8111 - val_mse:  0.8191\n",
            "Epoch 9/50\n",
            "7s - loss:  0.7950 - mse:  0.7950 - val_mse:  0.8092\n",
            "Epoch 10/50\n",
            "7s - loss:  0.7827 - mse:  0.7827 - val_mse:  0.8021\n",
            "Epoch 11/50\n",
            "7s - loss:  0.7732 - mse:  0.7732 - val_mse:  0.7973\n",
            "Epoch 12/50\n",
            "7s - loss:  0.7660 - mse:  0.7658 - val_mse:  0.7940\n",
            "Epoch 13/50\n",
            "8s - loss:  0.7602 - mse:  0.7603 - val_mse:  0.7915\n",
            "Epoch 14/50\n",
            "7s - loss:  0.7556 - mse:  0.7556 - val_mse:  0.7900\n",
            "Epoch 15/50\n",
            "7s - loss:  0.7523 - mse:  0.7523 - val_mse:  0.7887\n",
            "Epoch 16/50\n",
            "7s - loss:  0.7493 - mse:  0.7492 - val_mse:  0.7881\n",
            "Epoch 17/50\n",
            "7s - loss:  0.7469 - mse:  0.7468 - val_mse:  0.7880\n",
            "Epoch 18/50\n",
            "7s - loss:  0.7449 - mse:  0.7448 - val_mse:  0.7873\n",
            "Epoch 19/50\n",
            "7s - loss:  0.7434 - mse:  0.7433 - val_mse:  0.7875\n",
            "Epoch 20/50\n",
            "7s - loss:  0.7419 - mse:  0.7421 - val_mse:  0.7878\n",
            "Epoch 21/50\n",
            "7s - loss:  0.7407 - mse:  0.7406 - val_mse:  0.7874\n",
            "Epoch 22/50\n",
            "8s - loss:  0.7397 - mse:  0.7398 - val_mse:  0.7875\n",
            "Epoch 23/50\n",
            "7s - loss:  0.7388 - mse:  0.7388 - val_mse:  0.7878\n",
            "Epoch 00023: early stopping\n",
            "MHA Model RMSE: 0.8896\n",
            "MHA Model MAE: 0.7060\n",
            "MHA Model NDCG@5: 0.9357\n",
            "MHA Model NDCG@10: 0.9229\n",
            "MHA Model Precision@5: 0.8584\n",
            "MHA Model Precision@10: 0.8036\n",
            "MHA Execution Time: 183.01 seconds\n",
            "MHA CPU Usage: 0.10%\n",
            "MHA Memory Usage: 0.00 MB\n",
            "\n",
            "Final Results:\n",
            "AFM - RMSE: 0.8944, MAE: 0.7071,  NDCG@5: 0.9346,  Precision@5: 0.8544, NDCG@10: 0.9217,  Precision@10: 0.8052,  Time: 56.14s,  CPU: 0.20%, Memory: 0.00MB\n",
            "AutoInt - RMSE: 0.9034, MAE: 0.7228,  NDCG@5: 0.9328,  Precision@5: 0.8616, NDCG@10: 0.9198,  Precision@10: 0.8028,  Time: 57.34s,  CPU: 0.00%, Memory: 0.00MB\n",
            "CCPM - RMSE: 0.9063, MAE: 0.7117,  NDCG@5: 0.9359,  Precision@5: 0.8472, NDCG@10: 0.9211,  Precision@10: 0.8004,  Time: 56.88s,  CPU: 14.10%, Memory: 0.00MB\n",
            "DCN - RMSE: 0.8922, MAE: 0.7023,  NDCG@5: 0.9344,  Precision@5: 0.8536, NDCG@10: 0.9197,  Precision@10: 0.7984,  Time: 72.04s,  CPU: -14.70%, Memory: 0.00MB\n",
            "DeepFM - RMSE: 0.8941, MAE: 0.7127,  NDCG@5: 0.9324,  Precision@5: 0.8568, NDCG@10: 0.9209,  Precision@10: 0.8056,  Time: 25.19s,  CPU: 0.40%, Memory: 0.00MB\n",
            "DIFM - RMSE: 0.9169, MAE: 0.7155,  NDCG@5: 0.9297,  Precision@5: 0.8544, NDCG@10: 0.9199,  Precision@10: 0.8024,  Time: 74.73s,  CPU: -2.10%, Memory: 0.00MB\n",
            "FiBiNET - RMSE: 0.8900, MAE: 0.6997,  NDCG@5: 0.9295,  Precision@5: 0.8632, NDCG@10: 0.9199,  Precision@10: 0.8092,  Time: 60.06s,  CPU: -1.00%, Memory: 0.00MB\n",
            "NFM - RMSE: 0.8939, MAE: 0.7031,  NDCG@5: 0.9339,  Precision@5: 0.8648, NDCG@10: 0.9236,  Precision@10: 0.7992,  Time: 29.70s,  CPU: 10.40%, Memory: 0.00MB\n",
            "ONN - RMSE: 0.9753, MAE: 0.7719,  NDCG@5: 0.9093,  Precision@5: 0.8224, NDCG@10: 0.8976,  Precision@10: 0.7644,  Time: 32.01s,  CPU: -0.10%, Memory: 0.00MB\n",
            "PNN - RMSE: 0.9051, MAE: 0.7121,  NDCG@5: 0.9298,  Precision@5: 0.8520, NDCG@10: 0.9187,  Precision@10: 0.8064,  Time: 25.87s,  CPU: -0.20%, Memory: 0.00MB\n",
            "WDL - RMSE: 0.8937, MAE: 0.7126,  NDCG@5: 0.9348,  Precision@5: 0.8560, NDCG@10: 0.9226,  Precision@10: 0.8044,  Time: 23.90s,  CPU: 0.20%, Memory: 0.00MB\n",
            "xDeepFM - RMSE: 0.8906, MAE: 0.7070,  NDCG@5: 0.9352,  Precision@5: 0.8608, NDCG@10: 0.9237,  Precision@10: 0.8076,  Time: 81.51s,  CPU: 13.20%, Memory: 0.00MB\n",
            "IFM - RMSE: 0.8918, MAE: 0.7029,  NDCG@5: 0.9330,  Precision@5: 0.8528, NDCG@10: 0.9211,  Precision@10: 0.8032,  Time: 76.92s,  CPU: 3.50%, Memory: 0.00MB\n",
            "LS-PLM - RMSE: 0.8960, MAE: 0.7101,  NDCG@5: 0.9351,  Precision@5: 0.8536, NDCG@10: 0.9207,  Precision@10: 0.8032,  Time: 155.01s,  CPU: -0.10%, Memory: 0.00MB\n",
            "MHA - RMSE: 0.8896, MAE: 0.7060,  NDCG@5: 0.9357,  Precision@5: 0.8584, NDCG@10: 0.9229,  Precision@10: 0.8036,  Time: 183.01s,  CPU: 0.10%, Memory: 0.00MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MCGRS-SC-Se: Running Prediction with criteria, with single context: Season**"
      ],
      "metadata": {
        "id": "LuhxsA2HDgTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_features = [\n",
        "          'UserID',            # unique user\n",
        "          'GroupID',           # assigned via KMeans\n",
        "          'MovieID',           # unique movie\n",
        "          'Title',             # optional (high-cardinality), usually omit or hash\n",
        "          'UserOccupation',    # categorical occupation\n",
        "          'Season'             # ['Spring', 'Summer', etc.]\n",
        "      ]\n",
        "dense_features = [\n",
        "          'UserAge',           # continuous age\n",
        "          'Storyline',         # simulated multi-criteria\n",
        "          'Visuals',           # simulated multi-criteria\n",
        "          'Emotion'           # simulated multi-criteria\n",
        "      ]\n",
        "run(dense_features, sparse_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlA3IajZDiag",
        "outputId": "6518424f-0b86-449b-ba23-26aa814fabfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_rating:     UserID  GroupID  MovieID                    Title                  Genres  \\\n",
            "0     196       21      242             Kolya (1996)                  Comedy   \n",
            "1     196       21      393    Mrs. Doubtfire (1993)                  Comedy   \n",
            "2     196       21      381  Muriel's Wedding (1994)          Comedy|Romance   \n",
            "3     196       21      251   Shall We Dance? (1996)                  Comedy   \n",
            "4     196       21      655       Stand by Me (1986)  Adventure|Comedy|Drama   \n",
            "\n",
            "   UserAge  UserOccupation  TimeOfDay  DayType  Season  Storyline   Visuals  \\\n",
            "0       49              20  Afternoon  Weekday  Winter   4.986857  5.000000   \n",
            "1       49              20  Afternoon  Weekday  Winter   3.446943  1.000000   \n",
            "2       49              20  Afternoon  Weekday  Winter   5.000000  5.000000   \n",
            "3       49              20  Afternoon  Weekday  Winter   5.000000  1.000000   \n",
            "4       49              20  Afternoon  Weekday  Winter   4.063386  3.690389   \n",
            "\n",
            "    Emotion  OverallRating  \n",
            "0  5.000000              3  \n",
            "1  3.623087              4  \n",
            "2  1.000000              4  \n",
            "3  1.000000              3  \n",
            "4  3.629397              5  \n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "Rows with NaN values in df_ratings:\n",
            "Empty DataFrame\n",
            "Columns: [UserID, GroupID, MovieID, Title, Genres, UserAge, UserOccupation, TimeOfDay, DayType, Season, Storyline, Visuals, Emotion, OverallRating]\n",
            "Index: []\n",
            "sparse_features ['UserID', 'GroupID', 'MovieID', 'Title', 'UserOccupation', 'Season']\n",
            "feat:  UserID\n",
            "feat:  GroupID\n",
            "feat:  MovieID\n",
            "feat:  Title\n",
            "feat:  UserOccupation\n",
            "feat:  Season\n",
            "feature columns:  [SparseFeat(name='UserID', vocabulary_size=943, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserID', group_name='default_group'), SparseFeat(name='GroupID', vocabulary_size=250, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='GroupID', group_name='default_group'), SparseFeat(name='MovieID', vocabulary_size=1682, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='MovieID', group_name='default_group'), SparseFeat(name='Title', vocabulary_size=1664, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Title', group_name='default_group'), SparseFeat(name='UserOccupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='UserOccupation', group_name='default_group'), SparseFeat(name='Season', vocabulary_size=3, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='Season', group_name='default_group'), DenseFeat(name='UserAge', dimension=1, dtype='float32'), DenseFeat(name='Storyline', dimension=1, dtype='float32'), DenseFeat(name='Visuals', dimension=1, dtype='float32'), DenseFeat(name='Emotion', dimension=1, dtype='float32')]\n",
            "\n",
            "Training and evaluating AFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  8.9633 - mse:  8.9584 - val_mse:  4.8501\n",
            "Epoch 2/50\n",
            "2s - loss:  2.0088 - mse:  2.0077 - val_mse:  1.0169\n",
            "Epoch 3/50\n",
            "3s - loss:  1.0068 - mse:  1.0067 - val_mse:  0.9585\n",
            "Epoch 4/50\n",
            "2s - loss:  0.9461 - mse:  0.9462 - val_mse:  0.9111\n",
            "Epoch 5/50\n",
            "2s - loss:  0.8940 - mse:  0.8938 - val_mse:  0.8716\n",
            "Epoch 6/50\n",
            "2s - loss:  0.8506 - mse:  0.8506 - val_mse:  0.8403\n",
            "Epoch 7/50\n",
            "2s - loss:  0.8165 - mse:  0.8166 - val_mse:  0.8202\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7933 - mse:  0.7934 - val_mse:  0.8076\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7779 - mse:  0.7779 - val_mse:  0.8004\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7674 - mse:  0.7673 - val_mse:  0.7959\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7597 - mse:  0.7596 - val_mse:  0.7934\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7543 - mse:  0.7542 - val_mse:  0.7915\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7499 - mse:  0.7496 - val_mse:  0.7904\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7467 - mse:  0.7465 - val_mse:  0.7895\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7437 - mse:  0.7438 - val_mse:  0.7890\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7415 - mse:  0.7414 - val_mse:  0.7891\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7396 - mse:  0.7397 - val_mse:  0.7885\n",
            "Epoch 18/50\n",
            "2s - loss:  0.7380 - mse:  0.7379 - val_mse:  0.7891\n",
            "Epoch 19/50\n",
            "2s - loss:  0.7365 - mse:  0.7364 - val_mse:  0.7893\n",
            "Epoch 20/50\n",
            "2s - loss:  0.7351 - mse:  0.7350 - val_mse:  0.7891\n",
            "Epoch 21/50\n",
            "2s - loss:  0.7338 - mse:  0.7338 - val_mse:  0.7889\n",
            "Epoch 22/50\n",
            "2s - loss:  0.7326 - mse:  0.7325 - val_mse:  0.7887\n",
            "Epoch 00022: early stopping\n",
            "AFM Model RMSE: 0.8899\n",
            "AFM Model MAE: 0.7042\n",
            "AFM Model NDCG@5: 0.9335\n",
            "AFM Model NDCG@10: 0.9208\n",
            "AFM Model Precision@5: 0.8520\n",
            "AFM Model Precision@10: 0.8036\n",
            "AFM Execution Time: 62.02 seconds\n",
            "AFM CPU Usage: 0.20%\n",
            "AFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating AutoInt...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.0866 - mse:  2.0852 - val_mse:  0.8130\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7874 - mse:  0.7876 - val_mse:  0.7959\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7685 - mse:  0.7686 - val_mse:  0.7914\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7607 - mse:  0.7607 - val_mse:  0.7951\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7584 - mse:  0.7585 - val_mse:  0.7924\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7577 - mse:  0.7576 - val_mse:  0.7900\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7550 - mse:  0.7549 - val_mse:  0.7916\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7525 - mse:  0.7524 - val_mse:  0.8101\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7535 - mse:  0.7533 - val_mse:  0.8086\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7514 - mse:  0.7514 - val_mse:  0.7974\n",
            "Epoch 11/50\n",
            "4s - loss:  0.7499 - mse:  0.7497 - val_mse:  0.7927\n",
            "Epoch 00011: early stopping\n",
            "AutoInt Model RMSE: 0.8924\n",
            "AutoInt Model MAE: 0.7050\n",
            "AutoInt Model NDCG@5: 0.9351\n",
            "AutoInt Model NDCG@10: 0.9221\n",
            "AutoInt Model Precision@5: 0.8544\n",
            "AutoInt Model Precision@10: 0.8040\n",
            "AutoInt Execution Time: 53.40 seconds\n",
            "AutoInt CPU Usage: 14.60%\n",
            "AutoInt Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating CCPM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.0187 - mse:  2.0176 - val_mse:  0.9897\n",
            "Epoch 2/50\n",
            "3s - loss:  0.9016 - mse:  0.9016 - val_mse:  0.8618\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8262 - mse:  0.8262 - val_mse:  0.8456\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7985 - mse:  0.7985 - val_mse:  0.8265\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7812 - mse:  0.7811 - val_mse:  0.8148\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7686 - mse:  0.7687 - val_mse:  0.8101\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7594 - mse:  0.7594 - val_mse:  0.7975\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7512 - mse:  0.7512 - val_mse:  0.7924\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7469 - mse:  0.7469 - val_mse:  0.7905\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7444 - mse:  0.7444 - val_mse:  0.7880\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7419 - mse:  0.7420 - val_mse:  0.7881\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7407 - mse:  0.7408 - val_mse:  0.7885\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7366 - mse:  0.7367 - val_mse:  0.7873\n",
            "Epoch 14/50\n",
            "3s - loss:  0.7397 - mse:  0.7398 - val_mse:  0.7903\n",
            "Epoch 15/50\n",
            "3s - loss:  0.7347 - mse:  0.7348 - val_mse:  0.7991\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7310 - mse:  0.7310 - val_mse:  0.7899\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7294 - mse:  0.7295 - val_mse:  0.7940\n",
            "Epoch 18/50\n",
            "3s - loss:  0.7204 - mse:  0.7206 - val_mse:  0.7873\n",
            "Epoch 00018: early stopping\n",
            "CCPM Model RMSE: 0.8898\n",
            "CCPM Model MAE: 0.7027\n",
            "CCPM Model NDCG@5: 0.9332\n",
            "CCPM Model NDCG@10: 0.9191\n",
            "CCPM Model Precision@5: 0.8536\n",
            "CCPM Model Precision@10: 0.8052\n",
            "CCPM Execution Time: 70.11 seconds\n",
            "CCPM CPU Usage: -14.00%\n",
            "CCPM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DCN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  2.0321 - mse:  2.0308 - val_mse:  0.8068\n",
            "Epoch 2/50\n",
            "3s - loss:  0.7860 - mse:  0.7858 - val_mse:  0.7916\n",
            "Epoch 3/50\n",
            "3s - loss:  0.7676 - mse:  0.7676 - val_mse:  0.7935\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7607 - mse:  0.7608 - val_mse:  0.7941\n",
            "Epoch 5/50\n",
            "3s - loss:  0.7577 - mse:  0.7577 - val_mse:  0.7957\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7559 - mse:  0.7560 - val_mse:  0.7905\n",
            "Epoch 7/50\n",
            "3s - loss:  0.7546 - mse:  0.7547 - val_mse:  0.7992\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7537 - mse:  0.7540 - val_mse:  0.7918\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7531 - mse:  0.7531 - val_mse:  0.7903\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7527 - mse:  0.7526 - val_mse:  0.7924\n",
            "Epoch 11/50\n",
            "3s - loss:  0.7504 - mse:  0.7504 - val_mse:  0.7922\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7497 - mse:  0.7496 - val_mse:  0.7997\n",
            "Epoch 13/50\n",
            "3s - loss:  0.7498 - mse:  0.7498 - val_mse:  0.7896\n",
            "Epoch 14/50\n",
            "3s - loss:  0.7472 - mse:  0.7472 - val_mse:  0.7916\n",
            "Epoch 15/50\n",
            "3s - loss:  0.7453 - mse:  0.7454 - val_mse:  0.8056\n",
            "Epoch 16/50\n",
            "3s - loss:  0.7451 - mse:  0.7452 - val_mse:  0.7914\n",
            "Epoch 17/50\n",
            "3s - loss:  0.7393 - mse:  0.7393 - val_mse:  0.7882\n",
            "Epoch 18/50\n",
            "3s - loss:  0.7374 - mse:  0.7375 - val_mse:  0.7874\n",
            "Epoch 19/50\n",
            "3s - loss:  0.7333 - mse:  0.7333 - val_mse:  0.7842\n",
            "Epoch 20/50\n",
            "3s - loss:  0.7315 - mse:  0.7316 - val_mse:  0.7841\n",
            "Epoch 21/50\n",
            "3s - loss:  0.7263 - mse:  0.7263 - val_mse:  0.7844\n",
            "Epoch 22/50\n",
            "3s - loss:  0.7222 - mse:  0.7222 - val_mse:  0.7880\n",
            "Epoch 23/50\n",
            "3s - loss:  0.7196 - mse:  0.7197 - val_mse:  0.7890\n",
            "Epoch 24/50\n",
            "3s - loss:  0.7122 - mse:  0.7122 - val_mse:  0.7925\n",
            "Epoch 25/50\n",
            "3s - loss:  0.7079 - mse:  0.7080 - val_mse:  0.8128\n",
            "Epoch 00025: early stopping\n",
            "DCN Model RMSE: 0.9031\n",
            "DCN Model MAE: 0.7047\n",
            "DCN Model NDCG@5: 0.9260\n",
            "DCN Model NDCG@10: 0.9162\n",
            "DCN Model Precision@5: 0.8544\n",
            "DCN Model Precision@10: 0.8000\n",
            "DCN Execution Time: 85.43 seconds\n",
            "DCN CPU Usage: -0.10%\n",
            "DCN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0206 - mse:  2.0193 - val_mse:  0.8095\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7878 - mse:  0.7877 - val_mse:  0.7936\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7678 - mse:  0.7677 - val_mse:  0.7947\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7627 - mse:  0.7627 - val_mse:  0.7899\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7596 - mse:  0.7597 - val_mse:  0.7911\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7584 - mse:  0.7584 - val_mse:  0.7928\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7568 - mse:  0.7568 - val_mse:  0.7952\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7551 - mse:  0.7550 - val_mse:  0.7923\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7531 - mse:  0.7531 - val_mse:  0.7954\n",
            "Epoch 00009: early stopping\n",
            "DeepFM Model RMSE: 0.8938\n",
            "DeepFM Model MAE: 0.7047\n",
            "DeepFM Model NDCG@5: 0.9312\n",
            "DeepFM Model NDCG@10: 0.9208\n",
            "DeepFM Model Precision@5: 0.8568\n",
            "DeepFM Model Precision@10: 0.7996\n",
            "DeepFM Execution Time: 28.95 seconds\n",
            "DeepFM CPU Usage: 0.00%\n",
            "DeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating DIFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  3.4620 - mse:  3.4588 - val_mse:  0.9077\n",
            "Epoch 2/50\n",
            "3s - loss:  0.8767 - mse:  0.8769 - val_mse:  0.8791\n",
            "Epoch 3/50\n",
            "3s - loss:  0.8472 - mse:  0.8472 - val_mse:  0.8584\n",
            "Epoch 4/50\n",
            "4s - loss:  0.8247 - mse:  0.8247 - val_mse:  0.8444\n",
            "Epoch 5/50\n",
            "3s - loss:  0.8079 - mse:  0.8078 - val_mse:  0.8296\n",
            "Epoch 6/50\n",
            "3s - loss:  0.7933 - mse:  0.7933 - val_mse:  0.8244\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7815 - mse:  0.7815 - val_mse:  0.8126\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7700 - mse:  0.7700 - val_mse:  0.8033\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7630 - mse:  0.7632 - val_mse:  0.8069\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7506 - mse:  0.7505 - val_mse:  0.7895\n",
            "Epoch 11/50\n",
            "4s - loss:  0.7404 - mse:  0.7404 - val_mse:  0.7832\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7247 - mse:  0.7247 - val_mse:  0.7777\n",
            "Epoch 13/50\n",
            "4s - loss:  0.7079 - mse:  0.7078 - val_mse:  0.7817\n",
            "Epoch 14/50\n",
            "4s - loss:  0.6900 - mse:  0.6901 - val_mse:  0.7815\n",
            "Epoch 15/50\n",
            "3s - loss:  0.6723 - mse:  0.6726 - val_mse:  0.7969\n",
            "Epoch 16/50\n",
            "3s - loss:  0.6599 - mse:  0.6599 - val_mse:  0.7949\n",
            "Epoch 17/50\n",
            "4s - loss:  0.6451 - mse:  0.6451 - val_mse:  0.8040\n",
            "Epoch 00017: early stopping\n",
            "DIFM Model RMSE: 0.9014\n",
            "DIFM Model MAE: 0.7069\n",
            "DIFM Model NDCG@5: 0.9343\n",
            "DIFM Model NDCG@10: 0.9238\n",
            "DIFM Model Precision@5: 0.8560\n",
            "DIFM Model Precision@10: 0.7976\n",
            "DIFM Execution Time: 69.85 seconds\n",
            "DIFM CPU Usage: -0.30%\n",
            "DIFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating FiBiNET...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  2.1530 - mse:  2.1514 - val_mse:  0.8214\n",
            "Epoch 2/50\n",
            "4s - loss:  0.7903 - mse:  0.7905 - val_mse:  0.7916\n",
            "Epoch 3/50\n",
            "4s - loss:  0.7666 - mse:  0.7667 - val_mse:  0.7939\n",
            "Epoch 4/50\n",
            "4s - loss:  0.7584 - mse:  0.7583 - val_mse:  0.7882\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7524 - mse:  0.7526 - val_mse:  0.7957\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7469 - mse:  0.7469 - val_mse:  0.7912\n",
            "Epoch 7/50\n",
            "4s - loss:  0.7425 - mse:  0.7424 - val_mse:  0.7843\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7341 - mse:  0.7341 - val_mse:  0.7953\n",
            "Epoch 9/50\n",
            "4s - loss:  0.7231 - mse:  0.7231 - val_mse:  0.7897\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7082 - mse:  0.7082 - val_mse:  0.8031\n",
            "Epoch 11/50\n",
            "4s - loss:  0.6927 - mse:  0.6927 - val_mse:  0.7979\n",
            "Epoch 12/50\n",
            "4s - loss:  0.6799 - mse:  0.6800 - val_mse:  0.8001\n",
            "Epoch 00012: early stopping\n",
            "FiBiNET Model RMSE: 0.8967\n",
            "FiBiNET Model MAE: 0.7080\n",
            "FiBiNET Model NDCG@5: 0.9338\n",
            "FiBiNET Model NDCG@10: 0.9192\n",
            "FiBiNET Model Precision@5: 0.8528\n",
            "FiBiNET Model Precision@10: 0.8016\n",
            "FiBiNET Execution Time: 56.95 seconds\n",
            "FiBiNET CPU Usage: -0.20%\n",
            "FiBiNET Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating NFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "3s - loss:  1.9984 - mse:  1.9971 - val_mse:  0.8354\n",
            "Epoch 2/50\n",
            "2s - loss:  0.8055 - mse:  0.8054 - val_mse:  0.8016\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7742 - mse:  0.7742 - val_mse:  0.7961\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7649 - mse:  0.7652 - val_mse:  0.7954\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7605 - mse:  0.7605 - val_mse:  0.7955\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7583 - mse:  0.7583 - val_mse:  0.7986\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7563 - mse:  0.7564 - val_mse:  0.7948\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7539 - mse:  0.7540 - val_mse:  0.8008\n",
            "Epoch 9/50\n",
            "3s - loss:  0.7531 - mse:  0.7530 - val_mse:  0.7938\n",
            "Epoch 10/50\n",
            "3s - loss:  0.7509 - mse:  0.7510 - val_mse:  0.7946\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7497 - mse:  0.7497 - val_mse:  0.7966\n",
            "Epoch 12/50\n",
            "2s - loss:  0.7488 - mse:  0.7489 - val_mse:  0.7920\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7482 - mse:  0.7483 - val_mse:  0.7944\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7484 - mse:  0.7485 - val_mse:  0.7947\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7474 - mse:  0.7474 - val_mse:  0.7976\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7458 - mse:  0.7457 - val_mse:  0.7932\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7436 - mse:  0.7436 - val_mse:  0.8006\n",
            "Epoch 00017: early stopping\n",
            "NFM Model RMSE: 0.8999\n",
            "NFM Model MAE: 0.7179\n",
            "NFM Model NDCG@5: 0.9328\n",
            "NFM Model NDCG@10: 0.9211\n",
            "NFM Model Precision@5: 0.8576\n",
            "NFM Model Precision@10: 0.8024\n",
            "NFM Execution Time: 52.19 seconds\n",
            "NFM CPU Usage: 8.80%\n",
            "NFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating ONN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "5s - loss:  2.0214 - mse:  2.0187 - val_mse:  0.8154\n",
            "Epoch 2/50\n",
            "5s - loss:  0.7545 - mse:  0.7532 - val_mse:  0.8231\n",
            "Epoch 3/50\n",
            "4s - loss:  0.6705 - mse:  0.6694 - val_mse:  0.8659\n",
            "Epoch 4/50\n",
            "4s - loss:  0.6189 - mse:  0.6178 - val_mse:  0.9060\n",
            "Epoch 5/50\n",
            "5s - loss:  0.5867 - mse:  0.5857 - val_mse:  0.9343\n",
            "Epoch 6/50\n",
            "5s - loss:  0.5645 - mse:  0.5634 - val_mse:  0.9588\n",
            "Epoch 00006: early stopping\n",
            "ONN Model RMSE: 0.9766\n",
            "ONN Model MAE: 0.7713\n",
            "ONN Model NDCG@5: 0.9198\n",
            "ONN Model NDCG@10: 0.9056\n",
            "ONN Model Precision@5: 0.8296\n",
            "ONN Model Precision@10: 0.7636\n",
            "ONN Execution Time: 34.53 seconds\n",
            "ONN CPU Usage: -8.40%\n",
            "ONN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating PNN...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.2676 - mse:  2.2661 - val_mse:  0.8128\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7874 - mse:  0.7873 - val_mse:  0.7889\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7575 - mse:  0.7573 - val_mse:  0.7836\n",
            "Epoch 4/50\n",
            "2s - loss:  0.7372 - mse:  0.7372 - val_mse:  0.7815\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7216 - mse:  0.7216 - val_mse:  0.7814\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7130 - mse:  0.7130 - val_mse:  0.7877\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7069 - mse:  0.7069 - val_mse:  0.7914\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7023 - mse:  0.7024 - val_mse:  0.7901\n",
            "Epoch 9/50\n",
            "2s - loss:  0.6982 - mse:  0.6982 - val_mse:  0.7913\n",
            "Epoch 10/50\n",
            "2s - loss:  0.6903 - mse:  0.6903 - val_mse:  0.7970\n",
            "Epoch 00010: early stopping\n",
            "PNN Model RMSE: 0.8967\n",
            "PNN Model MAE: 0.7037\n",
            "PNN Model NDCG@5: 0.9311\n",
            "PNN Model NDCG@10: 0.9196\n",
            "PNN Model Precision@5: 0.8448\n",
            "PNN Model Precision@10: 0.8024\n",
            "PNN Execution Time: 26.61 seconds\n",
            "PNN CPU Usage: 1.20%\n",
            "PNN Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating WDL...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  2.0262 - mse:  2.0249 - val_mse:  0.8100\n",
            "Epoch 2/50\n",
            "2s - loss:  0.7873 - mse:  0.7872 - val_mse:  0.7926\n",
            "Epoch 3/50\n",
            "2s - loss:  0.7663 - mse:  0.7661 - val_mse:  0.7936\n",
            "Epoch 4/50\n",
            "3s - loss:  0.7610 - mse:  0.7610 - val_mse:  0.7890\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7580 - mse:  0.7580 - val_mse:  0.7905\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7569 - mse:  0.7569 - val_mse:  0.7918\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7552 - mse:  0.7553 - val_mse:  0.7944\n",
            "Epoch 8/50\n",
            "2s - loss:  0.7539 - mse:  0.7538 - val_mse:  0.7919\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7521 - mse:  0.7521 - val_mse:  0.7956\n",
            "Epoch 00009: early stopping\n",
            "WDL Model RMSE: 0.8939\n",
            "WDL Model MAE: 0.7044\n",
            "WDL Model NDCG@5: 0.9312\n",
            "WDL Model NDCG@10: 0.9207\n",
            "WDL Model Precision@5: 0.8592\n",
            "WDL Model Precision@10: 0.8024\n",
            "WDL Execution Time: 27.71 seconds\n",
            "WDL CPU Usage: -1.90%\n",
            "WDL Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating xDeepFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  1.8039 - mse:  1.8029 - val_mse:  0.8053\n",
            "Epoch 2/50\n",
            "5s - loss:  0.7842 - mse:  0.7841 - val_mse:  0.7905\n",
            "Epoch 3/50\n",
            "5s - loss:  0.7657 - mse:  0.7657 - val_mse:  0.7893\n",
            "Epoch 4/50\n",
            "5s - loss:  0.7594 - mse:  0.7595 - val_mse:  0.7947\n",
            "Epoch 5/50\n",
            "4s - loss:  0.7561 - mse:  0.7561 - val_mse:  0.7899\n",
            "Epoch 6/50\n",
            "4s - loss:  0.7526 - mse:  0.7527 - val_mse:  0.7969\n",
            "Epoch 7/50\n",
            "5s - loss:  0.7485 - mse:  0.7483 - val_mse:  0.7890\n",
            "Epoch 8/50\n",
            "4s - loss:  0.7456 - mse:  0.7456 - val_mse:  0.7865\n",
            "Epoch 9/50\n",
            "5s - loss:  0.7420 - mse:  0.7419 - val_mse:  0.7899\n",
            "Epoch 10/50\n",
            "4s - loss:  0.7400 - mse:  0.7401 - val_mse:  0.7937\n",
            "Epoch 11/50\n",
            "4s - loss:  0.7358 - mse:  0.7358 - val_mse:  0.7853\n",
            "Epoch 12/50\n",
            "5s - loss:  0.7330 - mse:  0.7331 - val_mse:  0.7882\n",
            "Epoch 13/50\n",
            "5s - loss:  0.7333 - mse:  0.7332 - val_mse:  0.7835\n",
            "Epoch 14/50\n",
            "4s - loss:  0.7275 - mse:  0.7274 - val_mse:  0.7820\n",
            "Epoch 15/50\n",
            "4s - loss:  0.7261 - mse:  0.7260 - val_mse:  0.7905\n",
            "Epoch 16/50\n",
            "4s - loss:  0.7232 - mse:  0.7232 - val_mse:  0.7886\n",
            "Epoch 17/50\n",
            "5s - loss:  0.7195 - mse:  0.7194 - val_mse:  0.7895\n",
            "Epoch 18/50\n",
            "4s - loss:  0.7148 - mse:  0.7148 - val_mse:  0.8179\n",
            "Epoch 19/50\n",
            "4s - loss:  0.7122 - mse:  0.7123 - val_mse:  0.7850\n",
            "Epoch 00019: early stopping\n",
            "xDeepFM Model RMSE: 0.8897\n",
            "xDeepFM Model MAE: 0.7028\n",
            "xDeepFM Model NDCG@5: 0.9326\n",
            "xDeepFM Model NDCG@10: 0.9218\n",
            "xDeepFM Model Precision@5: 0.8552\n",
            "xDeepFM Model Precision@10: 0.8048\n",
            "xDeepFM Execution Time: 98.71 seconds\n",
            "xDeepFM CPU Usage: 13.80%\n",
            "xDeepFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating IFM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "2s - loss:  5.6915 - mse:  5.6863 - val_mse:  1.1619\n",
            "Epoch 2/50\n",
            "2s - loss:  1.1655 - mse:  1.1653 - val_mse:  1.1336\n",
            "Epoch 3/50\n",
            "3s - loss:  1.0593 - mse:  1.0589 - val_mse:  0.8653\n",
            "Epoch 4/50\n",
            "3s - loss:  0.8224 - mse:  0.8224 - val_mse:  0.8200\n",
            "Epoch 5/50\n",
            "2s - loss:  0.7871 - mse:  0.7870 - val_mse:  0.8123\n",
            "Epoch 6/50\n",
            "2s - loss:  0.7766 - mse:  0.7766 - val_mse:  0.8078\n",
            "Epoch 7/50\n",
            "2s - loss:  0.7670 - mse:  0.7670 - val_mse:  0.8020\n",
            "Epoch 8/50\n",
            "3s - loss:  0.7612 - mse:  0.7612 - val_mse:  0.8064\n",
            "Epoch 9/50\n",
            "2s - loss:  0.7553 - mse:  0.7555 - val_mse:  0.7974\n",
            "Epoch 10/50\n",
            "2s - loss:  0.7519 - mse:  0.7519 - val_mse:  0.7989\n",
            "Epoch 11/50\n",
            "2s - loss:  0.7493 - mse:  0.7493 - val_mse:  0.8064\n",
            "Epoch 12/50\n",
            "3s - loss:  0.7426 - mse:  0.7427 - val_mse:  0.7950\n",
            "Epoch 13/50\n",
            "2s - loss:  0.7385 - mse:  0.7384 - val_mse:  0.7892\n",
            "Epoch 14/50\n",
            "2s - loss:  0.7346 - mse:  0.7346 - val_mse:  0.7911\n",
            "Epoch 15/50\n",
            "2s - loss:  0.7310 - mse:  0.7310 - val_mse:  0.7919\n",
            "Epoch 16/50\n",
            "2s - loss:  0.7278 - mse:  0.7278 - val_mse:  0.7910\n",
            "Epoch 17/50\n",
            "2s - loss:  0.7238 - mse:  0.7238 - val_mse:  0.7923\n",
            "Epoch 18/50\n",
            "3s - loss:  0.7210 - mse:  0.7211 - val_mse:  0.7968\n",
            "Epoch 00018: early stopping\n",
            "IFM Model RMSE: 0.8940\n",
            "IFM Model MAE: 0.7031\n",
            "IFM Model NDCG@5: 0.9322\n",
            "IFM Model NDCG@10: 0.9188\n",
            "IFM Model Precision@5: 0.8512\n",
            "IFM Model Precision@10: 0.7992\n",
            "IFM Execution Time: 56.68 seconds\n",
            "IFM CPU Usage: -14.50%\n",
            "IFM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating LS-PLM...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "4s - loss:  10.9830 - mse:  10.9797 - val_mse:  8.0192\n",
            "Epoch 2/50\n",
            "4s - loss:  5.5611 - mse:  5.5588 - val_mse:  3.5297\n",
            "Epoch 3/50\n",
            "4s - loss:  2.4426 - mse:  2.4418 - val_mse:  1.6804\n",
            "Epoch 4/50\n",
            "4s - loss:  1.3813 - mse:  1.3809 - val_mse:  1.1827\n",
            "Epoch 5/50\n",
            "4s - loss:  1.1213 - mse:  1.1212 - val_mse:  1.0697\n",
            "Epoch 6/50\n",
            "4s - loss:  1.0502 - mse:  1.0502 - val_mse:  1.0284\n",
            "Epoch 7/50\n",
            "4s - loss:  1.0103 - mse:  1.0102 - val_mse:  0.9988\n",
            "Epoch 8/50\n",
            "4s - loss:  0.9766 - mse:  0.9767 - val_mse:  0.9724\n",
            "Epoch 9/50\n",
            "4s - loss:  0.9461 - mse:  0.9460 - val_mse:  0.9484\n",
            "Epoch 10/50\n",
            "4s - loss:  0.9183 - mse:  0.9184 - val_mse:  0.9262\n",
            "Epoch 11/50\n",
            "4s - loss:  0.8927 - mse:  0.8928 - val_mse:  0.9059\n",
            "Epoch 12/50\n",
            "4s - loss:  0.8695 - mse:  0.8695 - val_mse:  0.8874\n",
            "Epoch 13/50\n",
            "4s - loss:  0.8486 - mse:  0.8486 - val_mse:  0.8708\n",
            "Epoch 14/50\n",
            "4s - loss:  0.8301 - mse:  0.8300 - val_mse:  0.8562\n",
            "Epoch 15/50\n",
            "4s - loss:  0.8139 - mse:  0.8140 - val_mse:  0.8435\n",
            "Epoch 16/50\n",
            "4s - loss:  0.7999 - mse:  0.7999 - val_mse:  0.8331\n",
            "Epoch 17/50\n",
            "4s - loss:  0.7882 - mse:  0.7882 - val_mse:  0.8244\n",
            "Epoch 18/50\n",
            "4s - loss:  0.7786 - mse:  0.7786 - val_mse:  0.8175\n",
            "Epoch 19/50\n",
            "4s - loss:  0.7709 - mse:  0.7710 - val_mse:  0.8123\n",
            "Epoch 20/50\n",
            "4s - loss:  0.7647 - mse:  0.7647 - val_mse:  0.8084\n",
            "Epoch 21/50\n",
            "4s - loss:  0.7599 - mse:  0.7598 - val_mse:  0.8053\n",
            "Epoch 22/50\n",
            "4s - loss:  0.7561 - mse:  0.7562 - val_mse:  0.8035\n",
            "Epoch 23/50\n",
            "4s - loss:  0.7532 - mse:  0.7531 - val_mse:  0.8022\n",
            "Epoch 24/50\n",
            "4s - loss:  0.7508 - mse:  0.7506 - val_mse:  0.8010\n",
            "Epoch 25/50\n",
            "4s - loss:  0.7489 - mse:  0.7490 - val_mse:  0.8003\n",
            "Epoch 26/50\n",
            "4s - loss:  0.7474 - mse:  0.7476 - val_mse:  0.7997\n",
            "Epoch 27/50\n",
            "4s - loss:  0.7462 - mse:  0.7461 - val_mse:  0.7994\n",
            "Epoch 28/50\n",
            "4s - loss:  0.7450 - mse:  0.7450 - val_mse:  0.7995\n",
            "Epoch 29/50\n",
            "4s - loss:  0.7441 - mse:  0.7442 - val_mse:  0.7992\n",
            "Epoch 30/50\n",
            "5s - loss:  0.7433 - mse:  0.7432 - val_mse:  0.7991\n",
            "Epoch 31/50\n",
            "4s - loss:  0.7425 - mse:  0.7424 - val_mse:  0.7992\n",
            "Epoch 32/50\n",
            "4s - loss:  0.7419 - mse:  0.7418 - val_mse:  0.7990\n",
            "Epoch 33/50\n",
            "4s - loss:  0.7414 - mse:  0.7414 - val_mse:  0.7992\n",
            "Epoch 34/50\n",
            "4s - loss:  0.7409 - mse:  0.7409 - val_mse:  0.7991\n",
            "Epoch 35/50\n",
            "4s - loss:  0.7404 - mse:  0.7403 - val_mse:  0.7991\n",
            "Epoch 36/50\n",
            "4s - loss:  0.7398 - mse:  0.7397 - val_mse:  0.7990\n",
            "Epoch 37/50\n",
            "4s - loss:  0.7394 - mse:  0.7394 - val_mse:  0.7992\n",
            "Epoch 38/50\n",
            "4s - loss:  0.7390 - mse:  0.7389 - val_mse:  0.7993\n",
            "Epoch 39/50\n",
            "4s - loss:  0.7385 - mse:  0.7385 - val_mse:  0.7991\n",
            "Epoch 40/50\n",
            "4s - loss:  0.7379 - mse:  0.7378 - val_mse:  0.7988\n",
            "Epoch 41/50\n",
            "4s - loss:  0.7372 - mse:  0.7370 - val_mse:  0.7986\n",
            "Epoch 42/50\n",
            "4s - loss:  0.7362 - mse:  0.7361 - val_mse:  0.7981\n",
            "Epoch 43/50\n",
            "4s - loss:  0.7347 - mse:  0.7348 - val_mse:  0.7976\n",
            "Epoch 44/50\n",
            "4s - loss:  0.7331 - mse:  0.7330 - val_mse:  0.7966\n",
            "Epoch 45/50\n",
            "4s - loss:  0.7309 - mse:  0.7311 - val_mse:  0.7956\n",
            "Epoch 46/50\n",
            "4s - loss:  0.7284 - mse:  0.7284 - val_mse:  0.7947\n",
            "Epoch 47/50\n",
            "4s - loss:  0.7257 - mse:  0.7256 - val_mse:  0.7942\n",
            "Epoch 48/50\n",
            "4s - loss:  0.7232 - mse:  0.7232 - val_mse:  0.7938\n",
            "Epoch 49/50\n",
            "4s - loss:  0.7204 - mse:  0.7206 - val_mse:  0.7936\n",
            "Epoch 50/50\n",
            "4s - loss:  0.7179 - mse:  0.7179 - val_mse:  0.7935\n",
            "LS-PLM Model RMSE: 0.8935\n",
            "LS-PLM Model MAE: 0.7063\n",
            "LS-PLM Model NDCG@5: 0.9310\n",
            "LS-PLM Model NDCG@10: 0.9193\n",
            "LS-PLM Model Precision@5: 0.8504\n",
            "LS-PLM Model Precision@10: 0.8048\n",
            "LS-PLM Execution Time: 226.04 seconds\n",
            "LS-PLM CPU Usage: 0.80%\n",
            "LS-PLM Memory Usage: 0.00 MB\n",
            "\n",
            "Training and evaluating MHA...\n",
            "cpu\n",
            "Train on 56000 samples, validate on 24000 samples, 219 steps per epoch\n",
            "Epoch 1/50\n",
            "8s - loss:  4.6576 - mse:  4.6546 - val_mse:  1.2810\n",
            "Epoch 2/50\n",
            "7s - loss:  1.1013 - mse:  1.1011 - val_mse:  1.0207\n",
            "Epoch 3/50\n",
            "7s - loss:  1.0019 - mse:  1.0018 - val_mse:  0.9571\n",
            "Epoch 4/50\n",
            "7s - loss:  0.9382 - mse:  0.9381 - val_mse:  0.9083\n",
            "Epoch 5/50\n",
            "7s - loss:  0.8891 - mse:  0.8892 - val_mse:  0.8724\n",
            "Epoch 6/50\n",
            "7s - loss:  0.8521 - mse:  0.8522 - val_mse:  0.8462\n",
            "Epoch 7/50\n",
            "7s - loss:  0.8245 - mse:  0.8245 - val_mse:  0.8278\n",
            "Epoch 8/50\n",
            "7s - loss:  0.8041 - mse:  0.8040 - val_mse:  0.8149\n",
            "Epoch 9/50\n",
            "7s - loss:  0.7888 - mse:  0.7889 - val_mse:  0.8056\n",
            "Epoch 10/50\n",
            "7s - loss:  0.7774 - mse:  0.7774 - val_mse:  0.7995\n",
            "Epoch 11/50\n",
            "7s - loss:  0.7691 - mse:  0.7692 - val_mse:  0.7951\n",
            "Epoch 12/50\n",
            "7s - loss:  0.7626 - mse:  0.7625 - val_mse:  0.7924\n",
            "Epoch 13/50\n",
            "7s - loss:  0.7576 - mse:  0.7575 - val_mse:  0.7907\n",
            "Epoch 14/50\n",
            "7s - loss:  0.7537 - mse:  0.7535 - val_mse:  0.7890\n",
            "Epoch 15/50\n",
            "7s - loss:  0.7508 - mse:  0.7507 - val_mse:  0.7885\n",
            "Epoch 16/50\n",
            "7s - loss:  0.7481 - mse:  0.7483 - val_mse:  0.7888\n",
            "Epoch 17/50\n",
            "7s - loss:  0.7460 - mse:  0.7459 - val_mse:  0.7876\n",
            "Epoch 18/50\n",
            "8s - loss:  0.7443 - mse:  0.7443 - val_mse:  0.7875\n",
            "Epoch 19/50\n",
            "7s - loss:  0.7428 - mse:  0.7428 - val_mse:  0.7877\n",
            "Epoch 20/50\n",
            "7s - loss:  0.7414 - mse:  0.7413 - val_mse:  0.7883\n",
            "Epoch 21/50\n",
            "7s - loss:  0.7402 - mse:  0.7401 - val_mse:  0.7877\n",
            "Epoch 22/50\n",
            "7s - loss:  0.7393 - mse:  0.7392 - val_mse:  0.7878\n",
            "Epoch 23/50\n",
            "7s - loss:  0.7374 - mse:  0.7375 - val_mse:  0.7882\n",
            "Epoch 00023: early stopping\n",
            "MHA Model RMSE: 0.8898\n",
            "MHA Model MAE: 0.7067\n",
            "MHA Model NDCG@5: 0.9345\n",
            "MHA Model NDCG@10: 0.9227\n",
            "MHA Model Precision@5: 0.8592\n",
            "MHA Model Precision@10: 0.8032\n",
            "MHA Execution Time: 179.87 seconds\n",
            "MHA CPU Usage: -0.20%\n",
            "MHA Memory Usage: 0.00 MB\n",
            "\n",
            "Final Results:\n",
            "AFM - RMSE: 0.8899, MAE: 0.7042,  NDCG@5: 0.9335,  Precision@5: 0.8520, NDCG@10: 0.9208,  Precision@10: 0.8036,  Time: 62.02s,  CPU: 0.20%, Memory: 0.00MB\n",
            "AutoInt - RMSE: 0.8924, MAE: 0.7050,  NDCG@5: 0.9351,  Precision@5: 0.8544, NDCG@10: 0.9221,  Precision@10: 0.8040,  Time: 53.40s,  CPU: 14.60%, Memory: 0.00MB\n",
            "CCPM - RMSE: 0.8898, MAE: 0.7027,  NDCG@5: 0.9332,  Precision@5: 0.8536, NDCG@10: 0.9191,  Precision@10: 0.8052,  Time: 70.11s,  CPU: -14.00%, Memory: 0.00MB\n",
            "DCN - RMSE: 0.9031, MAE: 0.7047,  NDCG@5: 0.9260,  Precision@5: 0.8544, NDCG@10: 0.9162,  Precision@10: 0.8000,  Time: 85.43s,  CPU: -0.10%, Memory: 0.00MB\n",
            "DeepFM - RMSE: 0.8938, MAE: 0.7047,  NDCG@5: 0.9312,  Precision@5: 0.8568, NDCG@10: 0.9208,  Precision@10: 0.7996,  Time: 28.95s,  CPU: 0.00%, Memory: 0.00MB\n",
            "DIFM - RMSE: 0.9014, MAE: 0.7069,  NDCG@5: 0.9343,  Precision@5: 0.8560, NDCG@10: 0.9238,  Precision@10: 0.7976,  Time: 69.85s,  CPU: -0.30%, Memory: 0.00MB\n",
            "FiBiNET - RMSE: 0.8967, MAE: 0.7080,  NDCG@5: 0.9338,  Precision@5: 0.8528, NDCG@10: 0.9192,  Precision@10: 0.8016,  Time: 56.95s,  CPU: -0.20%, Memory: 0.00MB\n",
            "NFM - RMSE: 0.8999, MAE: 0.7179,  NDCG@5: 0.9328,  Precision@5: 0.8576, NDCG@10: 0.9211,  Precision@10: 0.8024,  Time: 52.19s,  CPU: 8.80%, Memory: 0.00MB\n",
            "ONN - RMSE: 0.9766, MAE: 0.7713,  NDCG@5: 0.9198,  Precision@5: 0.8296, NDCG@10: 0.9056,  Precision@10: 0.7636,  Time: 34.53s,  CPU: -8.40%, Memory: 0.00MB\n",
            "PNN - RMSE: 0.8967, MAE: 0.7037,  NDCG@5: 0.9311,  Precision@5: 0.8448, NDCG@10: 0.9196,  Precision@10: 0.8024,  Time: 26.61s,  CPU: 1.20%, Memory: 0.00MB\n",
            "WDL - RMSE: 0.8939, MAE: 0.7044,  NDCG@5: 0.9312,  Precision@5: 0.8592, NDCG@10: 0.9207,  Precision@10: 0.8024,  Time: 27.71s,  CPU: -1.90%, Memory: 0.00MB\n",
            "xDeepFM - RMSE: 0.8897, MAE: 0.7028,  NDCG@5: 0.9326,  Precision@5: 0.8552, NDCG@10: 0.9218,  Precision@10: 0.8048,  Time: 98.71s,  CPU: 13.80%, Memory: 0.00MB\n",
            "IFM - RMSE: 0.8940, MAE: 0.7031,  NDCG@5: 0.9322,  Precision@5: 0.8512, NDCG@10: 0.9188,  Precision@10: 0.7992,  Time: 56.68s,  CPU: -14.50%, Memory: 0.00MB\n",
            "LS-PLM - RMSE: 0.8935, MAE: 0.7063,  NDCG@5: 0.9310,  Precision@5: 0.8504, NDCG@10: 0.9193,  Precision@10: 0.8048,  Time: 226.04s,  CPU: 0.80%, Memory: 0.00MB\n",
            "MHA - RMSE: 0.8898, MAE: 0.7067,  NDCG@5: 0.9345,  Precision@5: 0.8592, NDCG@10: 0.9227,  Precision@10: 0.8032,  Time: 179.87s,  CPU: -0.20%, Memory: 0.00MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import psutil\n",
        "import optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection   import train_test_split\n",
        "from sklearn.metrics           import mean_squared_error, mean_absolute_error\n",
        "\n",
        "from deepctr_torch.callbacks import EarlyStopping\n",
        "from deepctr_torch.inputs    import SparseFeat, DenseFeat, get_feature_names\n",
        "from mha_model               import MultiHeadAttentionModel\n",
        "\n",
        "# ----------------------------\n",
        "# Step 0: Configuration\n",
        "# ----------------------------\n",
        "DATA_PATH       = \"./427_final_ml1m_user_context_criteria.csv\"\n",
        "TARGET_COLUMN   = \"OverallRating\"\n",
        "SPARSE_FEATURES = [\n",
        "    'UserID','GroupID','MovieID','Title','Genres',\n",
        "    'UserOccupation','TimeOfDay','DayType','Season'\n",
        "]\n",
        "DENSE_FEATURES  = ['UserAge','Storyline','Visuals','Emotion']\n",
        "DEVICE          = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "N_TRIALS        = 30\n",
        "RANDOM_SEED     = 42\n",
        "\n",
        "# Fix random seeds\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# ----------------------------\n",
        "# Step 1: Load & Preprocess\n",
        "# ----------------------------\n",
        "df = pd.read_csv(DATA_PATH).dropna()\n",
        "\n",
        "# Encode categorical features\n",
        "for feat in SPARSE_FEATURES:\n",
        "    encoder = LabelEncoder()\n",
        "    df[feat] = encoder.fit_transform(df[feat].astype(str))\n",
        "\n",
        "# Scale continuous features to [0,1]\n",
        "scaler = MinMaxScaler()\n",
        "df[DENSE_FEATURES] = scaler.fit_transform(df[DENSE_FEATURES])\n",
        "\n",
        "# Split into train & test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "# ----------------------------\n",
        "# Step 2: Build DeepCTR Inputs\n",
        "# ----------------------------\n",
        "sparse_columns = [\n",
        "    SparseFeat(feat, vocabulary_size=df[feat].nunique(), embedding_dim=8)\n",
        "    for feat in SPARSE_FEATURES\n",
        "]\n",
        "dense_columns = [DenseFeat(feat, 1) for feat in DENSE_FEATURES]\n",
        "feature_columns = sparse_columns + dense_columns\n",
        "feature_names   = get_feature_names(feature_columns)\n",
        "\n",
        "def build_input(df_):\n",
        "    \"\"\"Convert DataFrame to DeepCTR input dict.\"\"\"\n",
        "    model_input = {name: df_[name].values for name in feature_names}\n",
        "    for name in feature_names:\n",
        "        if name in SPARSE_FEATURES:\n",
        "            model_input[name] = model_input[name].astype(int)\n",
        "        else:\n",
        "            model_input[name] = model_input[name].astype(float)\n",
        "    return model_input\n",
        "\n",
        "train_input = build_input(train_df)\n",
        "test_input  = build_input(test_df)\n",
        "\n",
        "# ----------------------------\n",
        "# Step 3: Ranking Metrics\n",
        "# ----------------------------\n",
        "def ndcg_at_k(ratings, k):\n",
        "    r = np.asanyarray(ratings, dtype=float)[:k]\n",
        "    if r.size == 0:\n",
        "        return 0.0\n",
        "    dcg = np.sum((2**r - 1) / np.log2(np.arange(2, r.size + 2)))\n",
        "    ideal = np.sort(r)[::-1]\n",
        "    idcg = np.sum((2**ideal - 1) / np.log2(np.arange(2, ideal.size + 2)))\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def precision_at_k(y_true, y_pred, k, threshold=3.7):\n",
        "    idx = np.argsort(y_pred)[::-1][:k]\n",
        "    return np.sum(np.array(y_true)[idx] >= threshold) / k\n",
        "\n",
        "# ----------------------------\n",
        "# Step 4: Optuna Objective\n",
        "# ----------------------------\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    num_heads   = trial.suggest_categorical(\"num_heads\",      [2, 4, 8])\n",
        "    dnn_units   = trial.suggest_categorical(\"dnn_hidden_units\", [\n",
        "                    (128,64,32), (256,128,64,32), (512,256)\n",
        "                  ])\n",
        "    dropout     = trial.suggest_float(\"dnn_dropout\", 0.2, 0.6)\n",
        "    l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
        "    lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n",
        "    batch_size  = trial.suggest_categorical(\"batch_size\", [128, 256, 512])\n",
        "    patience    = trial.suggest_int(\"patience\", 3, 7)\n",
        "\n",
        "    # Build model\n",
        "    model = MultiHeadAttentionModel(\n",
        "        linear_feature_columns=feature_columns,\n",
        "        dnn_feature_columns   =feature_columns,\n",
        "        num_heads             =num_heads,\n",
        "        dnn_hidden_units      =dnn_units,\n",
        "        dnn_dropout           =dropout,\n",
        "        l2_reg_dnn            =l2_reg,\n",
        "        task                  ='regression',\n",
        "        device                =DEVICE\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
        "\n",
        "    # Train with early stopping\n",
        "    stopper = EarlyStopping(monitor=\"val_loss\", patience=patience, verbose=0)\n",
        "    history = model.fit(\n",
        "        train_input, train_df[[TARGET_COLUMN]].values,\n",
        "        batch_size     =batch_size,\n",
        "        epochs         =50,\n",
        "        verbose        =0,\n",
        "        validation_split=0.2,\n",
        "        callbacks      =[stopper]\n",
        "    )\n",
        "\n",
        "    # Return the final validation MSE\n",
        "    return history.history[\"val_mse\"][-1]\n",
        "\n",
        "# ----------------------------\n",
        "# Step 5: Run Hyperparameter Search\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED))\n",
        "    study.optimize(objective, n_trials=N_TRIALS)\n",
        "\n",
        "    print(f\"\\n▶ Best val_mse: {study.best_value:.6f}\")\n",
        "    print(\"▶ Best hyperparameters:\")\n",
        "    for key, val in study.best_params.items():\n",
        "        print(f\"   • {key} = {val}\")\n",
        "\n",
        "    # Save best parameters\n",
        "    with open(\"best_mha_params.json\", \"w\") as f:\n",
        "        json.dump(study.best_params, f, indent=2)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Step 6: Retrain & Final Evaluate\n",
        "    # ----------------------------\n",
        "    best = study.best_params\n",
        "    # Rebuild model with best params\n",
        "    final_model = MultiHeadAttentionModel(\n",
        "        linear_feature_columns=feature_columns,\n",
        "        dnn_feature_columns   =feature_columns,\n",
        "        num_heads             =best[\"num_heads\"],\n",
        "        dnn_hidden_units      =tuple(best[\"dnn_hidden_units\"]),\n",
        "        dnn_dropout           =best[\"dnn_dropout\"],\n",
        "        l2_reg_dnn            =best[\"l2_reg_dnn\"],\n",
        "        task                  ='regression',\n",
        "        device                =DEVICE\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(final_model.parameters(), lr=best[\"lr\"])\n",
        "    final_model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\",\"mae\"])\n",
        "\n",
        "    stopper = EarlyStopping(monitor=\"val_loss\", patience=best[\"patience\"], verbose=1)\n",
        "    final_model.fit(\n",
        "        train_input, train_df[[TARGET_COLUMN]].values,\n",
        "        batch_size     =best[\"batch_size\"],\n",
        "        epochs         =50,\n",
        "        verbose        =2,\n",
        "        validation_split=0.1,\n",
        "        callbacks      =[stopper]\n",
        "    )\n",
        "\n",
        "    # Predict on test set\n",
        "    preds = final_model.predict(test_input, batch_size=best[\"batch_size\"])\n",
        "    rmse  = np.sqrt(mean_squared_error(test_df[[TARGET_COLUMN]].values, preds))\n",
        "    mae   = mean_absolute_error(test_df[[TARGET_COLUMN]].values, preds)\n",
        "\n",
        "    # Compute ranking metrics group-wise\n",
        "    ndcg5_list, prec5_list = [], []\n",
        "    test_df[\"pred\"] = preds\n",
        "    for _, group in test_df.groupby(\"GroupID\"):\n",
        "        true = group[TARGET_COLUMN].values\n",
        "        score = group[\"pred\"].values\n",
        "        ndcg5_list.append(ndcg_at_k(true[np.argsort(score)[::-1]], 5))\n",
        "        prec5_list.append(precision_at_k(true, score, 5))\n",
        "\n",
        "    print(f\"\\n▶ Test RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "    print(f\"  Test NDCG@5: {np.mean(ndcg5_list):.4f}, Precision@5: {np.mean(prec5_list):.4f}\")\n",
        "\n",
        "    # Save final model weights\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "    torch.save(final_model.state_dict(), \"outputs/best_mha_model.pth\")\n",
        "    print(\"\\n✔ Saved best model to outputs/best_mha_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmCTZxOC8dFr",
        "outputId": "baa221be-1af0-46cb-9603-7e6a0370f9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 07:48:05,570] A new study created in memory with name: no-name-046e9b52-d9db-45ff-a12d-4bd72dd739e4\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 1251 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 08:57:43,192] Trial 0 finished with value: 0.7510999151725549 and parameters: {'num_heads': 4, 'dnn_hidden_units': (128, 64, 32), 'dnn_dropout': 0.2232334448672798, 'l2_reg_dnn': 5.39948440978744e-05, 'lr': 0.0015930522616241021, 'batch_size': 512, 'patience': 7}. Best is trial 0 with value: 0.7510999151725549.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 1251 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 09:39:47,672] Trial 1 finished with value: 0.7925401473319653 and parameters: {'num_heads': 2, 'dnn_hidden_units': (256, 128, 64, 32), 'dnn_dropout': 0.31649165607921675, 'l2_reg_dnn': 1.6738085788752145e-05, 'lr': 0.00019010245319870352, 'batch_size': 512, 'patience': 6}. Best is trial 0 with value: 0.7510999151725549.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 5002 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 14:04:36,458] Trial 2 finished with value: 0.7381910644655824 and parameters: {'num_heads': 8, 'dnn_hidden_units': (256, 128, 64, 32), 'dnn_dropout': 0.2260206371941118, 'l2_reg_dnn': 7.902619549708236e-05, 'lr': 0.00853618986286683, 'batch_size': 128, 'patience': 6}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 1251 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 15:25:21,065] Trial 3 finished with value: 0.7660933834167624 and parameters: {'num_heads': 8, 'dnn_hidden_units': (256, 128, 64, 32), 'dnn_dropout': 0.46500891374159276, 'l2_reg_dnn': 4.201672054372532e-06, 'lr': 0.001096821720752952, 'batch_size': 512, 'patience': 6}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 2501 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 16:22:09,220] Trial 4 finished with value: 0.7543421722414496 and parameters: {'num_heads': 2, 'dnn_hidden_units': (128, 64, 32), 'dnn_dropout': 0.21809091556421523, 'l2_reg_dnn': 4.473636174621267e-06, 'lr': 0.0005989003672254305, 'batch_size': 256, 'patience': 4}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 1251 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 17:49:03,604] Trial 5 finished with value: 0.7765016124158293 and parameters: {'num_heads': 8, 'dnn_hidden_units': (256, 128, 64, 32), 'dnn_dropout': 0.279486272613669, 'l2_reg_dnn': 1.0257563974185657e-06, 'lr': 0.004274869455295219, 'batch_size': 512, 'patience': 3}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 2501 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 19:30:55,923] Trial 6 finished with value: 0.7530638742958968 and parameters: {'num_heads': 8, 'dnn_hidden_units': (128, 64, 32), 'dnn_dropout': 0.3243929286862649, 'l2_reg_dnn': 4.470608546778493e-06, 'lr': 0.002878805718308925, 'batch_size': 256, 'patience': 3}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 2501 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 20:34:45,475] Trial 7 finished with value: 0.7448723564791501 and parameters: {'num_heads': 4, 'dnn_hidden_units': (128, 64, 32), 'dnn_dropout': 0.37101640734341984, 'l2_reg_dnn': 1.1241862095793055e-06, 'lr': 0.00016435497475111326, 'batch_size': 256, 'patience': 5}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 1251 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 21:39:46,339] Trial 8 finished with value: 0.7588643183483214 and parameters: {'num_heads': 2, 'dnn_hidden_units': (128, 64, 32), 'dnn_dropout': 0.31590058116550723, 'l2_reg_dnn': 2.101079931010356e-06, 'lr': 0.007234279845665418, 'batch_size': 512, 'patience': 7}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 2501 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-09 23:01:26,460] Trial 9 finished with value: 0.7731546024243036 and parameters: {'num_heads': 4, 'dnn_hidden_units': (256, 128, 64, 32), 'dnn_dropout': 0.2440207698110707, 'l2_reg_dnn': 2.856737429847189e-06, 'lr': 0.0007148510793512986, 'batch_size': 256, 'patience': 5}. Best is trial 2 with value: 0.7381910644655824.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 5002 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "[I 2025-05-10 06:18:36,960] Trial 10 finished with value: 0.7084596257198429 and parameters: {'num_heads': 8, 'dnn_hidden_units': (512, 256), 'dnn_dropout': 0.5878148443151463, 'l2_reg_dnn': 8.13372824372842e-05, 'lr': 0.009285225829404777, 'batch_size': 128, 'patience': 6}. Best is trial 10 with value: 0.7084596257198429.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 128, 64, 32) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (512, 256) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-6-b0b7e50d9418>:102: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  l2_reg      = trial.suggest_loguniform(\"l2_reg_dnn\", 1e-6, 1e-4)\n",
            "<ipython-input-6-b0b7e50d9418>:103: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr          = trial.suggest_loguniform(\"lr\",       1e-4, 1e-2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Train on 640133 samples, validate on 160034 samples, 5002 steps per epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,val_mse\n"
          ]
        }
      ]
    }
  ]
}